#!/usr/bin/env python3
"""
æ‰¹é‡è¿‡æ»¤æœªå®¡æ ¸æ¶ˆæ¯çš„è„šæœ¬
ä½¿ç”¨æ–°çš„æ™ºèƒ½å°¾éƒ¨è¿‡æ»¤å™¨å¤„ç†æ•°æ®åº“ä¸­çš„æ‰€æœ‰æœªå®¡æ ¸æ¶ˆæ¯
"""

import asyncio
import logging
from datetime import datetime
from sqlalchemy import select, and_, or_, func
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import AsyncSessionLocal, Message
from app.services.intelligent_tail_filter import intelligent_tail_filter
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FilterReport:
    """è¿‡æ»¤æŠ¥å‘Šç»Ÿè®¡"""
    def __init__(self):
        self.total_messages = 0
        self.filtered_messages = 0
        self.total_chars_removed = 0
        self.messages_details = []
        self.new_patterns_learned = set()
        self.start_time = datetime.now()
        
    def add_result(self, message_id, original_len, filtered_len, has_tail, tail_content):
        """æ·»åŠ ä¸€æ¡è¿‡æ»¤ç»“æœ"""
        self.total_messages += 1
        if has_tail:
            self.filtered_messages += 1
            chars_removed = original_len - filtered_len
            self.total_chars_removed += chars_removed
            self.messages_details.append({
                'id': message_id,
                'original_len': original_len,
                'filtered_len': filtered_len,
                'removed_chars': chars_removed,
                'tail_preview': tail_content[:100] if tail_content else ''
            })
            # è®°å½•æ–°å­¦ä¹ çš„æ¨¡å¼
            if tail_content and len(tail_content) > 20:
                self.new_patterns_learned.add(tail_content[:50])
    
    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds()
        
        report = {
            'summary': {
                'total_messages': self.total_messages,
                'filtered_messages': self.filtered_messages,
                'filter_rate': f"{(self.filtered_messages/self.total_messages*100):.1f}%" if self.total_messages > 0 else "0%",
                'total_chars_removed': self.total_chars_removed,
                'avg_chars_removed': self.total_chars_removed // self.filtered_messages if self.filtered_messages > 0 else 0,
                'new_patterns_learned': len(self.new_patterns_learned),
                'processing_time': f"{duration:.2f}ç§’",
                'processing_speed': f"{self.total_messages/duration:.1f}æ¡/ç§’" if duration > 0 else "N/A"
            },
            'details': {
                'top_filtered': self.messages_details[:10],  # å‰10æ¡è¿‡æ»¤æœ€å¤šçš„
                'patterns_learned': list(self.new_patterns_learned)[:20]  # å‰20ä¸ªæ–°å­¦ä¹ çš„æ¨¡å¼
            },
            'model_stats': intelligent_tail_filter.get_statistics()
        }
        
        return report

async def batch_filter_messages():
    """æ‰¹é‡è¿‡æ»¤æœªå®¡æ ¸çš„æ¶ˆæ¯"""
    report = FilterReport()
    
    async with AsyncSessionLocal() as db:
        try:
            # æŸ¥è¯¢æ‰€æœ‰æœªå®¡æ ¸çš„æ¶ˆæ¯ï¼ˆstatus = 'pending'ï¼‰
            logger.info("æ­£åœ¨æŸ¥è¯¢æœªå®¡æ ¸çš„æ¶ˆæ¯...")
            query = select(Message).where(
                and_(
                    Message.status == 'pending',
                    Message.content.isnot(None),
                    Message.content != ''
                )
            ).order_by(Message.created_at.desc())
            
            result = await db.execute(query)
            messages = result.scalars().all()
            
            logger.info(f"æ‰¾åˆ° {len(messages)} æ¡æœªå®¡æ ¸æ¶ˆæ¯")
            
            # è·å–è¿‡æ»¤å‰çš„æ¨¡å‹çŠ¶æ€
            initial_stats = intelligent_tail_filter.get_statistics()
            logger.info(f"åˆå§‹æ¨¡å‹çŠ¶æ€: æ ·æœ¬æ•°={initial_stats['total_samples']}, å…³é”®è¯={initial_stats['learned_keywords']}")
            
            # å¤„ç†æ¯æ¡æ¶ˆæ¯
            batch_size = 50
            for i in range(0, len(messages), batch_size):
                batch = messages[i:i+batch_size]
                logger.info(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(messages)-1)//batch_size + 1}")
                
                for message in batch:
                    try:
                        # ä½¿ç”¨æ™ºèƒ½è¿‡æ»¤å™¨å¤„ç†
                        original_content = message.content
                        filtered_content, has_tail, tail_content = intelligent_tail_filter.filter_message(original_content)
                        
                        # è®°å½•ç»“æœ
                        report.add_result(
                            message.id,
                            len(original_content),
                            len(filtered_content),
                            has_tail,
                            tail_content
                        )
                        
                        # å¦‚æœæ£€æµ‹åˆ°å°¾éƒ¨ï¼Œæ›´æ–°æ•°æ®åº“
                        if has_tail:
                            message.filtered_content = filtered_content
                            
                            # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè°ƒç”¨add_training_sampleï¼Œå› ä¸ºä¼šå¯¼è‡´é‡å¤é‡è½½
                            # è€Œæ˜¯æ”¶é›†æ‰€æœ‰æ–°æ ·æœ¬ï¼Œæœ€åä¸€æ¬¡æ€§ä¿å­˜
                            
                            logger.debug(f"æ¶ˆæ¯ {message.id}: ç§»é™¤äº† {len(tail_content)} ä¸ªå­—ç¬¦")
                        else:
                            # æ²¡æœ‰å°¾éƒ¨ï¼Œä¿æŒåŸæ ·
                            message.filtered_content = original_content
                    
                    except Exception as e:
                        logger.error(f"å¤„ç†æ¶ˆæ¯ {message.id} æ—¶å‡ºé”™: {e}")
                        continue
                
                # æ‰¹é‡æäº¤æ›´æ”¹
                await db.commit()
                logger.info(f"å·²ä¿å­˜æ‰¹æ¬¡ {i//batch_size + 1} çš„æ›´æ”¹")
            
            # è·å–è¿‡æ»¤åçš„æ¨¡å‹çŠ¶æ€
            final_stats = intelligent_tail_filter.get_statistics()
            logger.info(f"æœ€ç»ˆæ¨¡å‹çŠ¶æ€: æ ·æœ¬æ•°={final_stats['total_samples']}, å…³é”®è¯={final_stats['learned_keywords']}")
            
            # ç”ŸæˆæŠ¥å‘Š
            filter_report = report.generate_report()
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_file = f"filter_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(filter_report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"è¿‡æ»¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
            # æ‰“å°æŠ¥å‘Šæ‘˜è¦
            print("\n" + "="*60)
            print("ğŸ“Š æ™ºèƒ½å°¾éƒ¨è¿‡æ»¤æŠ¥å‘Š")
            print("="*60)
            print(f"ğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
            print(f"  â€¢ æ€»æ¶ˆæ¯æ•°: {filter_report['summary']['total_messages']}")
            print(f"  â€¢ è¿‡æ»¤æ¶ˆæ¯æ•°: {filter_report['summary']['filtered_messages']}")
            print(f"  â€¢ è¿‡æ»¤ç‡: {filter_report['summary']['filter_rate']}")
            print(f"  â€¢ æ€»ç§»é™¤å­—ç¬¦: {filter_report['summary']['total_chars_removed']}")
            print(f"  â€¢ å¹³å‡æ¯æ¡ç§»é™¤: {filter_report['summary']['avg_chars_removed']} å­—ç¬¦")
            print(f"\nğŸ§  æ¨¡å‹å­¦ä¹ :")
            print(f"  â€¢ æ–°å­¦ä¹ æ¨¡å¼: {filter_report['summary']['new_patterns_learned']} ä¸ª")
            print(f"  â€¢ å½“å‰æ€»æ ·æœ¬: {final_stats['total_samples']}")
            print(f"  â€¢ å­¦ä¹ å…³é”®è¯: {final_stats['learned_keywords']}")
            print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
            print(f"  â€¢ å¤„ç†æ—¶é—´: {filter_report['summary']['processing_time']}")
            print(f"  â€¢ å¤„ç†é€Ÿåº¦: {filter_report['summary']['processing_speed']}")
            
            if filter_report['details']['top_filtered']:
                print(f"\nğŸ“ è¿‡æ»¤æœ€å¤šçš„æ¶ˆæ¯ (å‰5æ¡):")
                for msg in filter_report['details']['top_filtered'][:5]:
                    print(f"  â€¢ æ¶ˆæ¯ #{msg['id']}: ç§»é™¤ {msg['removed_chars']} å­—ç¬¦")
                    if msg['tail_preview']:
                        preview = msg['tail_preview'][:50]
                        print(f"    å°¾éƒ¨é¢„è§ˆ: {preview}...")
            
            print("\n" + "="*60)
            print("âœ… æ‰¹é‡è¿‡æ»¤å®Œæˆï¼")
            print("="*60)
            
            return filter_report
            
        except Exception as e:
            logger.error(f"æ‰¹é‡è¿‡æ»¤å¤±è´¥: {e}")
            raise

async def main():
    """ä¸»å‡½æ•°"""
    try:
        report = await batch_filter_messages()
        return report
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    asyncio.run(main())