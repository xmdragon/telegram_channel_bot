#!/usr/bin/env python3
"""
å°†æ™ºèƒ½è¿‡æ»¤å™¨å†…å­˜ä¸­å­¦ä¹ çš„æ ·æœ¬ä¿å­˜åˆ°æ–‡ä»¶
"""

import json
from datetime import datetime
from app.services.intelligent_tail_filter import intelligent_tail_filter
from app.core.training_config import TrainingDataConfig

def save_learned_samples():
    """ä¿å­˜å†…å­˜ä¸­å­¦ä¹ çš„æ ·æœ¬åˆ°æ–‡ä»¶"""
    
    # è¯»å–ç°æœ‰æ–‡ä»¶æ•°æ®
    tail_file = TrainingDataConfig.TAIL_FILTER_SAMPLES_FILE
    with open(tail_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
        existing_samples = data.get('samples', [])
    
    print(f"æ–‡ä»¶ä¸­ç°æœ‰æ ·æœ¬: {len(existing_samples)} ä¸ª")
    
    # è·å–å†…å­˜ä¸­çš„æ‰€æœ‰æ ·æœ¬
    memory_samples = intelligent_tail_filter.tail_samples
    print(f"å†…å­˜ä¸­æ€»æ ·æœ¬: {len(memory_samples)} ä¸ª")
    
    # æ‰¾å‡ºæ–°å¢çš„æ ·æœ¬ï¼ˆä¸åœ¨æ–‡ä»¶ä¸­çš„ï¼‰
    existing_tails = {s.get('tail_part', '').strip() for s in existing_samples if s.get('tail_part')}
    
    new_samples = []
    sample_id = len(existing_samples) + 1
    
    for tail in memory_samples:
        tail_stripped = tail.strip()
        if tail_stripped and tail_stripped not in existing_tails:
            new_samples.append({
                "id": sample_id,
                "tail_part": tail,
                "created_at": datetime.now().isoformat(),
                "source": "batch_filter_learning"  # æ ‡è®°æ¥æº
            })
            existing_tails.add(tail_stripped)
            sample_id += 1
    
    print(f"æ–°å¢æ ·æœ¬: {len(new_samples)} ä¸ª")
    
    if new_samples:
        # åˆå¹¶æ ·æœ¬
        all_samples = existing_samples + new_samples
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(tail_file, 'w', encoding='utf-8') as f:
            json.dump({"samples": all_samples}, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æˆåŠŸä¿å­˜ {len(all_samples)} ä¸ªæ ·æœ¬åˆ°æ–‡ä»¶")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = intelligent_tail_filter.get_statistics()
        print(f"\nğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
        print(f"  â€¢ æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"  â€¢ å­¦ä¹ å…³é”®è¯: {stats['learned_keywords']}")
        print(f"  â€¢ ç‰¹å¾æ•°é‡: {stats['feature_count']}")
    else:
        print("âœ… æ²¡æœ‰æ–°æ ·æœ¬éœ€è¦ä¿å­˜")
    
    return len(all_samples) if new_samples else len(existing_samples)

if __name__ == "__main__":
    total = save_learned_samples()
    print(f"\næœ€ç»ˆæ–‡ä»¶ä¸­æ ·æœ¬æ€»æ•°: {total}")