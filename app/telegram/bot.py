"""
Telegramå®¢æˆ·ç«¯æ ¸å¿ƒåŠŸèƒ½ - é‡æ„ç‰ˆæœ¬
ä½¿ç”¨ç»„ä»¶åŒ–æ¶æ„ï¼Œä¿æŒå‘åå…¼å®¹
"""
import logging
import asyncio
import os
from typing import List, Optional
from datetime import datetime, timezone
from telethon.tl.types import Message as TLMessage
from sqlalchemy.orm import sessionmaker
from sqlalchemy import select

from app.core.config import db_settings
from app.core.database import AsyncSessionLocal, Message
from app.services.message_processor import MessageProcessor
from app.services.content_filter import ContentFilter
from app.services.system_monitor import system_monitor
from app.services.media_handler import media_handler
from app.services.message_grouper import message_grouper
from app.services.config_manager import ConfigManager
from app.services.channel_manager import channel_manager

# æ–°çš„ç»„ä»¶åŒ–æ¨¡å—
from app.telegram.client_manager import client_manager
from app.telegram.message_event_handler import message_event_handler
from app.telegram.message_forwarder import message_forwarder
from app.telegram.history_collector import history_collector

logger = logging.getLogger(__name__)

class TelegramBot:
    """Telegramæœºå™¨äººç®¡ç†ç±» - é‡æ„ç‰ˆæœ¬ï¼Œä¿æŒå‘åå…¼å®¹"""
    
    def __init__(self):
        # ä¿æŒåŸæœ‰å±æ€§ä»¥ç¡®ä¿å‘åå…¼å®¹
        self.client = None
        self.message_processor = MessageProcessor()
        self.content_filter = ContentFilter()
        self.is_running = False
        self.monitor_task = None
        self.auto_collection_done = False
        self.config_manager = ConfigManager()
        self.event_loop_task = None
        
        # è®¾ç½®ç»„ä»¶é—´çš„å›è°ƒå…³ç³»
        self._setup_component_callbacks()
        
    def _setup_component_callbacks(self):
        """è®¾ç½®å„ç»„ä»¶é—´çš„å›è°ƒå…³ç³»"""
        # è®¾ç½®äº‹ä»¶å¤„ç†å™¨çš„æ¶ˆæ¯å¤„ç†å™¨
        message_event_handler.set_message_processor(self._handle_message_from_event)
        message_event_handler.set_callback_processor(self._handle_callback)
        
        # è®¾ç½®å†å²é‡‡é›†å™¨çš„æ¶ˆæ¯å¤„ç†å™¨
        history_collector.set_message_processor(self._process_and_save_message)
        
        # è®¾ç½®å®¢æˆ·ç«¯ç®¡ç†å™¨çš„å›è°ƒ
        client_manager.add_connection_callback(self._on_client_connected)
        client_manager.add_disconnection_callback(self._on_client_disconnected)
    
    async def start(self):
        """å¯åŠ¨Telegramå®¢æˆ·ç«¯å’Œç›‘æ§"""
        # å¯åŠ¨ç³»ç»Ÿç›‘æ§
        await system_monitor.start()
        logger.info("ç³»ç»Ÿç›‘æ§å·²å¯åŠ¨")
        
        # å¯åŠ¨å®¢æˆ·ç«¯ç›‘æ§å¾ªç¯
        self.monitor_task = asyncio.create_task(self._monitoring_loop())
    
    async def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯ - æŒç»­æ£€æŸ¥ç³»ç»ŸçŠ¶æ€å¹¶å°è¯•è¿æ¥"""
        while True:
            try:
                if not self.is_running:
                    # å°è¯•è¿æ¥å®¢æˆ·ç«¯
                    if await client_manager.connect():
                        self.client = await client_manager.get_client()  # ä¿æŒå‘åå…¼å®¹
                        self.is_running = True
                        
                await asyncio.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(10)
    
    async def _on_client_connected(self, client):
        """å®¢æˆ·ç«¯è¿æ¥æˆåŠŸæ—¶çš„å›è°ƒ"""
        try:
            # ä¿æŒå‘åå…¼å®¹
            self.client = client
            
            # åŠ è½½å¹¿å‘Šå…³é”®è¯åˆ°å†…å­˜
            await self.content_filter.load_keywords_from_db()
            
            # å¯åŠ¨åª’ä½“å¤„ç†å™¨
            await media_handler.start()
            
            # æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
            await message_event_handler.register_event_handlers(client)
            
            # è§£æç¼ºå¤±çš„é¢‘é“ID
            await self._resolve_missing_channel_ids()
            
            # é¦–æ¬¡è¿æ¥æ—¶è¿›è¡Œå†å²æ¶ˆæ¯é‡‡é›†
            if not self.auto_collection_done:
                await self._auto_collect_history(client)
                self.auto_collection_done = True
            
            # åˆ›å»ºå¹¶å¯åŠ¨äº‹ä»¶å¾ªç¯ä»»åŠ¡
            logger.info("å¯åŠ¨äº‹ä»¶å¾ªç¯...")
            self.event_loop_task = asyncio.create_task(self._run_event_loop(client))
            
        except Exception as e:
            logger.error(f"å®¢æˆ·ç«¯è¿æ¥å›è°ƒå¤±è´¥: {e}")
    
    async def _on_client_disconnected(self):
        """å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶çš„å›è°ƒ"""
        self.is_running = False
        self.client = None
        
        if self.event_loop_task:
            self.event_loop_task.cancel()
    
    async def _run_event_loop(self, client):
        """è¿è¡Œå®¢æˆ·ç«¯äº‹ä»¶å¾ªç¯"""
        try:
            logger.info("å¼€å§‹ç›‘å¬æ¶ˆæ¯...")
            await client.run_until_disconnected()
            logger.info("å®¢æˆ·ç«¯äº‹ä»¶å¾ªç¯å·²ç»“æŸ")
        except Exception as e:
            logger.error(f"å®¢æˆ·ç«¯è¿è¡Œå‡ºé”™: {e}")
        finally:
            self.is_running = False
    
    async def _handle_message_from_event(self, message: TLMessage, chat, chat_info: dict, message_type: str):
        """å¤„ç†æ¥è‡ªäº‹ä»¶å¤„ç†å™¨çš„æ¶ˆæ¯"""
        try:
            if message_type == "source_channel":
                logger.info(f"æ¶ˆæ¯æ¥è‡ªç›‘å¬çš„æºé¢‘é“: {chat_info['title']}")
                await self.process_source_message(message, chat)
            elif message_type == "review_group":
                logger.info(f"æ¶ˆæ¯æ¥è‡ªå®¡æ ¸ç¾¤: {chat_info['title']}")
                await self.process_review_message(message, chat)
            else:
                logger.debug(f"æ¶ˆæ¯æ¥è‡ªæœªç›‘å¬çš„é¢‘é“/ç¾¤ç»„: {chat_info['title']} (ID: {chat_info['formatted_id']})")
                
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def _common_message_processing(self, message: TLMessage, channel_id: str, is_history: bool = False):
        """
        é€šç”¨æ¶ˆæ¯å¤„ç†é€»è¾‘
        
        Args:
            message: Telegramæ¶ˆæ¯å¯¹è±¡
            channel_id: é¢‘é“IDï¼ˆå·²æ ¼å¼åŒ–ï¼‰
            is_history: æ˜¯å¦ä¸ºå†å²æ¶ˆæ¯
            
        Returns:
            å¤„ç†åçš„æ¶ˆæ¯æ•°æ®å­—å…¸ï¼Œå¦‚æœæ¶ˆæ¯è¢«è¿‡æ»¤åˆ™è¿”å›None
        """
        try:
            # æå–æ¶ˆæ¯å†…å®¹
            content = message.text or message.raw_text or message.message or ""
            media_type = None
            media_url = None
            media_info = None
            
            # å¤„ç†åª’ä½“æ¶ˆæ¯ - åŒæ­¥ä¸‹è½½åˆ°æœ¬åœ°
            if message.media:
                if hasattr(message.media, 'photo'):
                    media_type = "photo"
                elif hasattr(message.media, 'document'):
                    media_type = "document"
                    
                # ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘120ç§’ï¼Œå›¾ç‰‡30ç§’ï¼‰
                try:
                    # æ ¹æ®åª’ä½“ç±»å‹è®¾ç½®è¶…æ—¶æ—¶é—´
                    if media_type == "photo":
                        timeout = 30.0  # å›¾ç‰‡30ç§’
                    elif media_type == "document" and hasattr(message.media, 'document'):
                        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘
                        document = message.media.document
                        mime_type = document.mime_type or ""
                        if mime_type.startswith("video/"):
                            timeout = 120.0  # è§†é¢‘120ç§’
                        else:
                            timeout = 60.0  # å…¶ä»–æ–‡æ¡£60ç§’
                    else:
                        timeout = 60.0  # é»˜è®¤60ç§’
                    
                    media_info = await media_handler.download_media(self.client, message, message.id, timeout=timeout)
                    
                    if media_info:
                        media_type = media_info['media_type']
                        media_url = media_info['file_path']
                        logger.info(f"âœ… åª’ä½“ä¸‹è½½æˆåŠŸ: {media_url}")
                    elif message.media and hasattr(message.media, 'document'):
                        # media_info ä¸º None è¡¨ç¤ºæ–‡ä»¶è¢«æ‹’ç»ï¼ˆå¯èƒ½æ˜¯å±é™©æ–‡ä»¶ï¼‰
                        document = message.media.document
                        mime_type = document.mime_type or "application/octet-stream"
                        # æ£€æŸ¥æ˜¯å¦ä¸ºå±é™©æ–‡ä»¶
                        dangerous_extensions = ['.exe', '.bat', '.cmd', '.com', '.pif', '.scr', '.vbs', '.js', '.jar', '.msi', '.dll', '.bin']
                        is_dangerous = False
                        for attr in document.attributes:
                            if hasattr(attr, 'file_name') and attr.file_name:
                                if any(attr.file_name.lower().endswith(ext) for ext in dangerous_extensions):
                                    is_dangerous = True
                                    break
                        
                        if is_dangerous:
                            logger.warning(f"ğŸš« æ¶ˆæ¯åŒ…å«å±é™©æ–‡ä»¶ï¼Œè‡ªåŠ¨è¿‡æ»¤")
                            return None
                        else:
                            # ä¸æ˜¯å±é™©æ–‡ä»¶ï¼Œåªæ˜¯ä¸‹è½½è¶…æ—¶ï¼Œåˆ›å»ºå ä½ä¿¡æ¯
                            logger.warning(f"â³ åª’ä½“ä¸‹è½½è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œåˆ›å»ºå ä½ä¿¡æ¯ (message_id={message.id})")
                            media_info = {
                                'message_id': message.id,
                                'media_type': media_type or "document",
                                'file_path': None,
                                'file_size': 0,
                                'download_failed': True,
                                'timeout': timeout
                            }
                    else:
                        # å…¶ä»–ä¸‹è½½å¤±è´¥æƒ…å†µï¼Œåˆ›å»ºå ä½ä¿¡æ¯
                        logger.warning(f"â³ åª’ä½“ä¸‹è½½å¤±è´¥ï¼ˆè¶…æ—¶{timeout}ç§’ï¼‰ (message_id={message.id})")
                        media_info = {
                            'message_id': message.id,
                            'media_type': media_type,
                            'file_path': None,
                            'file_size': 0,
                            'download_failed': True,
                            'timeout': timeout
                        }
                except Exception as e:
                    logger.error(f"ä¸‹è½½åª’ä½“å¼‚å¸¸ (message_id={message.id}): {e}")
                    # åˆ›å»ºå ä½ä¿¡æ¯
                    media_info = {
                        'message_id': message.id,
                        'media_type': media_type,
                        'file_path': None,
                        'file_size': 0,
                        'download_failed': True,
                        'error': str(e)
                    }
            
            # å†…å®¹è¿‡æ»¤ï¼ˆåŒ…å«æ™ºèƒ½å»å°¾éƒ¨ï¼‰
            logger.info(f"ğŸ“ å¼€å§‹å†…å®¹è¿‡æ»¤ï¼ŒåŸå§‹å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            is_ad, filtered_content, filter_reason = self.content_filter.filter_message(content)
            
            # è®°å½•è¿‡æ»¤ç»“æœå’ŒåŸå› 
            if filter_reason == "tail_only":
                logger.info(f"ğŸ“ å†…å®¹è¿‡æ»¤å®Œæˆï¼šæ–‡æœ¬å®Œå…¨æ˜¯å°¾éƒ¨æ¨å¹¿ï¼Œå·²è¿‡æ»¤")
            elif filter_reason == "ad_filtered":
                logger.info(f"ğŸ“ å†…å®¹è¿‡æ»¤å®Œæˆï¼šæ£€æµ‹åˆ°å¹¿å‘Šå†…å®¹")
            elif filter_reason == "normal":
                logger.info(f"ğŸ“ å†…å®¹è¿‡æ»¤å®Œæˆï¼Œè¿‡æ»¤åé•¿åº¦: {len(filtered_content)} å­—ç¬¦ï¼Œå‡å°‘: {len(content) - len(filtered_content)} å­—ç¬¦")
            else:
                logger.info(f"ğŸ“ å†…å®¹è¿‡æ»¤å®Œæˆï¼Œé•¿åº¦æ— å˜åŒ–: {len(filtered_content)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯å¹¿å‘Šï¼ˆæ— æ–°é—»ä»·å€¼ï¼‰
            if self.content_filter.is_pure_advertisement(content):
                logger.warning(f"ğŸš« æ£€æµ‹åˆ°çº¯å¹¿å‘Šï¼Œè‡ªåŠ¨æ‹’ç»: {content[:50]}...")
                if media_info and media_info.get('file_path'):
                    await media_handler.cleanup_file(media_info['file_path'])
                return None
            
            # å¤„ç†æ–‡æœ¬è¢«å®Œå…¨è¿‡æ»¤çš„æƒ…å†µ
            if content and not filtered_content:
                if filter_reason == "tail_only":
                    # æ–‡æœ¬å®Œå…¨æ˜¯å°¾éƒ¨æ¨å¹¿
                    if media_info:
                        # æœ‰åª’ä½“ï¼Œä¿ç•™åª’ä½“ï¼Œæ–‡æœ¬ä¸ºç©º
                        logger.info(f"â„¹ï¸ åª’ä½“æ¶ˆæ¯çš„æ–‡æœ¬ä¸ºçº¯å°¾éƒ¨æ¨å¹¿ï¼Œå·²è¿‡æ»¤ï¼Œä¿ç•™åª’ä½“")
                        filtered_content = ""  # æ–‡æœ¬ä¸ºç©ºï¼Œä½†ä¿ç•™åª’ä½“
                        # ç»§ç»­å¤„ç†ï¼Œä¸è¿”å›None
                    else:
                        # çº¯æ–‡æœ¬ä¸”å®Œå…¨æ˜¯å°¾éƒ¨ï¼Œå¯èƒ½æ˜¯åªå‘äº†æ¨å¹¿ä¿¡æ¯
                        logger.info(f"â„¹ï¸ çº¯æ–‡æœ¬æ¶ˆæ¯å®Œå…¨æ˜¯å°¾éƒ¨æ¨å¹¿ï¼Œå·²è¿‡æ»¤")
                        # è¿™ç§æƒ…å†µé€šå¸¸ä¸éœ€è¦é‡‡é›†ï¼Œä½†ä¸æ˜¯å¹¿å‘Š
                        return None
                else:
                    # å…¶ä»–åŸå› å¯¼è‡´æ–‡æœ¬ä¸ºç©ºï¼ˆå¦‚å¹¿å‘Šè¿‡æ»¤ï¼‰
                    logger.warning(f"ğŸš« æ–‡æœ¬è¢«å®Œå…¨è¿‡æ»¤ï¼ˆåŸå› : {filter_reason}ï¼‰ï¼Œæ‹’ç»æ¶ˆæ¯")
                    if media_info and media_info.get('file_path'):
                        await media_handler.cleanup_file(media_info['file_path'])
                    return None
            
            # å¦‚æœæ˜¯å¹¿å‘Šä¸”é…ç½®äº†è‡ªåŠ¨è¿‡æ»¤ï¼Œåˆ™è·³è¿‡
            auto_filter_ads = await db_settings.get_auto_filter_ads()
            if is_ad and auto_filter_ads:
                logger.info(f"è‡ªåŠ¨è¿‡æ»¤å¹¿å‘Šæ¶ˆæ¯: {content[:50]}...")
                if media_info and media_info.get('file_path'):
                    await media_handler.cleanup_file(media_info['file_path'])
                return None
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ¶ˆæ¯ï¼ˆæ²¡æœ‰å†…å®¹ä¹Ÿæ²¡æœ‰åª’ä½“ï¼‰
            if not filtered_content and not media_info:
                logger.warning(f"ğŸš« æ¶ˆæ¯æ— å†…å®¹ä¹Ÿæ— åª’ä½“ï¼Œè‡ªåŠ¨è·³è¿‡")
                return None
            
            # è¿”å›å¤„ç†åçš„æ¶ˆæ¯æ•°æ®
            return {
                'message': message,
                'content': content,
                'filtered_content': filtered_content,
                'is_ad': is_ad,
                'media_info': media_info,
                'channel_id': channel_id
            }
            
        except Exception as e:
            logger.error(f"é€šç”¨æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            # æ¸…ç†å¯èƒ½å·²ä¸‹è½½çš„åª’ä½“
            if 'media_info' in locals() and media_info and media_info.get('file_path'):
                await media_handler.cleanup_file(media_info['file_path'])
            return None
    
    async def process_source_message(self, message: TLMessage, chat):
        """å¤„ç†æºé¢‘é“æ¶ˆæ¯ - ä¿æŒåŸæœ‰æ¥å£"""
        try:
            
            # è·å–æ ¼å¼åŒ–çš„é¢‘é“ID
            raw_chat_id = chat.id
            if raw_chat_id > 0:
                channel_id = f"-100{raw_chat_id}"
            else:
                channel_id = str(raw_chat_id)
            
            # ä½¿ç”¨é€šç”¨å¤„ç†é€»è¾‘
            processed_data = await self._common_message_processing(message, channel_id, is_history=False)
            if not processed_data:
                return  # æ¶ˆæ¯è¢«è¿‡æ»¤
            
            # æå–å¤„ç†åçš„æ•°æ®
            content = processed_data['content']
            filtered_content = processed_data['filtered_content']
            is_ad = processed_data['is_ad']
            media_info = processed_data['media_info']
            
            # ä½¿ç”¨message_grouperå¤„ç†å¯èƒ½çš„ç»„åˆæ¶ˆæ¯
            combined_message = await message_grouper.process_message(
                message, channel_id, media_info, 
                filtered_content=filtered_content, 
                is_ad=is_ad
            )
            
            # å¦‚æœè¿”å›Noneï¼Œè¯´æ˜æ¶ˆæ¯è¿˜åœ¨ç­‰å¾…ç»„åˆï¼Œæš‚æ—¶ä¸å¤„ç†
            if combined_message is None:
                logger.info(f"æ¶ˆæ¯ {message.id} æ­£åœ¨ç­‰å¾…ç»„åˆ...")
                return
            
            # å¦‚æœæ˜¯ç»„åˆæ¶ˆæ¯ï¼Œmessage_grouperå·²ç»å¤„ç†äº†ä¿å­˜å’Œè½¬å‘
            if combined_message.get('is_combined'):
                logger.info(f"ç»„åˆæ¶ˆæ¯ {combined_message['grouped_id']} å·²ç”±message_grouperå¤„ç†")
                return
            
            # å¤„ç†å•ç‹¬æ¶ˆæ¯
            # æå–åª’ä½“ç±»å‹å’ŒURL
            media_type = media_info.get('media_type') if media_info else None
            media_url = media_info.get('file_path') if media_info else None
            
            # æå–è§†è§‰å“ˆå¸Œï¼ˆå¦‚æœæœ‰ï¼‰
            visual_hash = None
            media_hash = None
            if media_info:
                if media_info.get('visual_hashes'):
                    visual_hash = str(media_info['visual_hashes'])  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å­˜å‚¨
                media_hash = media_info.get('hash')  # SHA256å“ˆå¸Œ
            
            async with AsyncSessionLocal() as db:
                db_message = Message(
                    source_channel=channel_id,
                    message_id=message.id,
                    content=content,  # ä¿å­˜åŸå§‹å†…å®¹
                    media_type=media_type,
                    media_url=media_url,
                    media_hash=media_hash,
                    visual_hash=visual_hash,
                    is_ad=is_ad,
                    filtered_content=filtered_content,  # ä¿å­˜è¿‡æ»¤åå†…å®¹
                    grouped_id=str(message.grouped_id) if hasattr(message, 'grouped_id') and message.grouped_id else None,
                    is_combined=False
                )
                db.add(db_message)
                await db.commit()
                await db.refresh(db_message)
                
                # è½¬å‘åˆ°å®¡æ ¸ç¾¤
                await self.forward_to_review(db_message)
                
                # å¹¿æ’­æ–°æ¶ˆæ¯åˆ°WebSocketå®¢æˆ·ç«¯
                await self._broadcast_new_message(db_message)
                
        except Exception as e:
            logger.error(f"å¤„ç†æºé¢‘é“æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def process_review_message(self, message: TLMessage, chat):
        """å¤„ç†å®¡æ ¸ç¾¤ä¸­çš„æ¶ˆæ¯ - ä¿æŒåŸæœ‰æ¥å£"""
        try:
            text = message.text or ""
            
            # å¤„ç†å‘½ä»¤
            if text.startswith('/approve_'):
                message_id = int(text.split('_')[1])
                await self.approve_message(message_id, message.sender.username)
            elif text.startswith('/reject_'):
                message_id = int(text.split('_')[1])
                await self.reject_message(message_id, message.sender.username)
            elif text.startswith('/edit_'):
                message_id = int(text.split('_')[1])
                await self.edit_message(message_id)
            elif text.startswith('/detail_'):
                message_id = int(text.split('_')[1])
                await self.show_message_detail(message_id)
                
        except Exception as e:
            logger.error(f"å¤„ç†å®¡æ ¸ç¾¤æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def _handle_callback(self, event):
        """å¤„ç†å›è°ƒæŒ‰é’® - ä¿æŒåŸæœ‰æ¥å£"""
        try:
            data = event.data.decode()
            action, message_id = data.split('_', 1)
            message_id = int(message_id)
            
            if action == "approve":
                await self.approve_message(message_id, event.sender.username)
            elif action == "reject":
                await self.reject_message(message_id, event.sender.username)
            elif action == "edit":
                await self.edit_message(message_id)
            elif action == "detail":
                await self.show_message_detail(message_id)
                
        except Exception as e:
            logger.error(f"å¤„ç†å›è°ƒæ—¶å‡ºé”™: {e}")
    
    # ä¿æŒæ‰€æœ‰åŸæœ‰çš„å…¬å¼€æ–¹æ³•æ¥å£ä¸å˜
    async def forward_to_review(self, db_message: Message):
        """è½¬å‘æ¶ˆæ¯åˆ°å®¡æ ¸ç¾¤ - å§”æ‰˜ç»™è½¬å‘å™¨"""
        if self.client:
            await message_forwarder.forward_to_review(self.client, db_message)
        else:
            logger.error("å®¢æˆ·ç«¯æœªè¿æ¥ï¼Œæ— æ³•è½¬å‘æ¶ˆæ¯")
    
    async def forward_to_target(self, message: Message):
        """é‡æ–°å‘å¸ƒåˆ°ç›®æ ‡é¢‘é“ - å§”æ‰˜ç»™è½¬å‘å™¨"""
        if self.client:
            await message_forwarder.forward_to_target(self.client, message)
        else:
            logger.error("å®¢æˆ·ç«¯æœªè¿æ¥ï¼Œæ— æ³•è½¬å‘æ¶ˆæ¯")
    
    async def update_review_message(self, message: Message):
        """æ›´æ–°å®¡æ ¸ç¾¤ä¸­çš„æ¶ˆæ¯å†…å®¹ - å§”æ‰˜ç»™è½¬å‘å™¨"""
        if self.client:
            await message_forwarder.update_review_message(self.client, message)
        else:
            logger.error("å®¢æˆ·ç«¯æœªè¿æ¥ï¼Œæ— æ³•æ›´æ–°æ¶ˆæ¯")
    
    async def delete_review_message(self, review_message_id: int):
        """åˆ é™¤å®¡æ ¸ç¾¤çš„æ¶ˆæ¯ - å§”æ‰˜ç»™è½¬å‘å™¨"""
        if self.client:
            await message_forwarder.delete_review_message(self.client, review_message_id)
        else:
            logger.error("å®¢æˆ·ç«¯æœªè¿æ¥ï¼Œæ— æ³•åˆ é™¤æ¶ˆæ¯")
    
    async def approve_message(self, message_id: int, reviewer: str):
        """æ‰¹å‡†æ¶ˆæ¯ - ä¿æŒåŸæœ‰æ¥å£"""
        try:
            async with AsyncSessionLocal() as db:
                result = await db.execute(
                    select(Message).where(Message.id == message_id)
                )
                message = result.scalar_one()
                
                # æ›´æ–°çŠ¶æ€
                message.status = "approved"
                message.reviewed_by = reviewer
                message.review_time = datetime.now()
                
                # è½¬å‘åˆ°ç›®æ ‡é¢‘é“
                await self.forward_to_target(message)
                
                await db.commit()
                
        except Exception as e:
            logger.error(f"æ‰¹å‡†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def reject_message(self, message_id: int, reviewer: str):
        """æ‹’ç»æ¶ˆæ¯ - ä¿æŒåŸæœ‰æ¥å£"""
        try:
            async with AsyncSessionLocal() as db:
                result = await db.execute(
                    select(Message).where(Message.id == message_id)
                )
                message = result.scalar_one()
                
                # åˆ é™¤å®¡æ ¸ç¾¤çš„æ¶ˆæ¯
                if message.review_message_id:
                    await self.delete_review_message(message.review_message_id)
                
                # æ›´æ–°çŠ¶æ€
                message.status = "rejected"
                message.reviewed_by = reviewer
                message.review_time = datetime.now()
                
                await db.commit()
                
                # æ¸…ç†åª’ä½“æ–‡ä»¶
                await self._cleanup_message_files(message)
                
        except Exception as e:
            logger.error(f"æ‹’ç»æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def edit_message(self, message_id: int):
        """ç¼–è¾‘æ¶ˆæ¯ï¼ˆé¢„ç•™åŠŸèƒ½ï¼‰"""
        pass
    
    async def show_message_detail(self, message_id: int):
        """æ˜¾ç¤ºæ¶ˆæ¯è¯¦æƒ…ï¼ˆé¢„ç•™åŠŸèƒ½ï¼‰"""
        pass
    
    async def get_chat_info(self, chat_id: str):
        """è·å–èŠå¤©ä¿¡æ¯ - å§”æ‰˜ç»™å®¢æˆ·ç«¯ç®¡ç†å™¨"""
        return await client_manager.get_chat_info(chat_id)
    
    async def stop(self):
        """åœæ­¢å®¢æˆ·ç«¯ - ä¿æŒåŸæœ‰æ¥å£"""
        self.is_running = False
        
        # åœæ­¢ç›‘æ§ä»»åŠ¡
        if self.monitor_task:
            self.monitor_task.cancel()
        
        # åœæ­¢äº‹ä»¶å¾ªç¯ä»»åŠ¡
        if self.event_loop_task:
            self.event_loop_task.cancel()
            
        # åœæ­¢ç³»ç»Ÿç›‘æ§
        await system_monitor.stop()
        
        # åœæ­¢å†å²é‡‡é›†
        from app.services.history_collector import history_collector as old_history_collector
        await old_history_collector.stop_all_collections()
        
        # åœæ­¢åª’ä½“å¤„ç†å™¨
        await media_handler.stop()
        
        # æ–­å¼€å®¢æˆ·ç«¯è¿æ¥
        await client_manager.disconnect()
        self.client = None
        
        logger.info("Telegramå®¢æˆ·ç«¯å·²åœæ­¢")
    
    # ä»¥ä¸‹ä¸ºå†…éƒ¨æ–¹æ³•ï¼Œä¿æŒåŸæœ‰é€»è¾‘
    async def _broadcast_new_message(self, db_message: Message):
        """å¹¿æ’­æ–°æ¶ˆæ¯åˆ°WebSocketå®¢æˆ·ç«¯"""
        try:
            from app.api.websocket import websocket_manager
            
            # å‡†å¤‡æ¶ˆæ¯æ•°æ®
            message_data = {
                "id": db_message.id,
                "source_channel": db_message.source_channel,
                "content": db_message.content,
                "filtered_content": db_message.filtered_content,
                "media_type": db_message.media_type,
                "media_url": db_message.media_url,
                "is_ad": db_message.is_ad,
                "status": db_message.status,
                "created_at": db_message.created_at.isoformat() if db_message.created_at else None,
                "is_combined": db_message.is_combined,
                "media_group_display": self._prepare_media_group_display(db_message)
            }
            
            # å¹¿æ’­åˆ°æ‰€æœ‰WebSocketå®¢æˆ·ç«¯
            await websocket_manager.broadcast_new_message(message_data)
            
        except Exception as e:
            logger.error(f"å¹¿æ’­æ–°æ¶ˆæ¯åˆ°WebSocketæ—¶å‡ºé”™: {e}")
    
    def _prepare_media_group_display(self, db_message: Message):
        """å‡†å¤‡åª’ä½“ç»„æ˜¾ç¤ºæ•°æ®"""
        try:
            if not db_message.is_combined or not db_message.media_group:
                return None
                
            media_display = []
            for media_item in db_message.media_group:
                # è½¬æ¢æœ¬åœ°æ–‡ä»¶è·¯å¾„ä¸ºwebè®¿é—®è·¯å¾„
                file_path = media_item.get('file_path', '')
                if file_path.startswith('./temp_media/'):
                    web_path = file_path.replace('./temp_media/', '/media/')
                else:
                    web_path = file_path
                    
                media_display.append({
                    'media_type': media_item.get('media_type'),
                    'url': web_path,
                    'file_size': media_item.get('file_size'),
                    'mime_type': media_item.get('mime_type')
                })
            
            return media_display
            
        except Exception as e:
            logger.error(f"å‡†å¤‡åª’ä½“ç»„æ˜¾ç¤ºæ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    async def _resolve_missing_channel_ids(self):
        """è§£æç¼ºå¤±çš„é¢‘é“ID"""
        try:
            logger.info("æ£€æŸ¥å¹¶è§£æç¼ºå¤±çš„é¢‘é“ID...")
            resolved_count = await channel_manager.resolve_missing_channel_ids()
            if resolved_count > 0:
                logger.info(f"æˆåŠŸè§£æ {resolved_count} ä¸ªé¢‘é“ID")
            else:
                logger.info("æ‰€æœ‰é¢‘é“IDéƒ½å·²è§£ææˆ–æ— éœ€è§£æ")
        except Exception as e:
            logger.error(f"è§£æé¢‘é“IDå¤±è´¥: {e}")
    
    async def _auto_collect_history(self, client):
        """è‡ªåŠ¨é‡‡é›†é¢‘é“å†å²æ¶ˆæ¯"""
        try:
            logger.info("å¼€å§‹é‡‡é›†é¢‘é“å†å²æ¶ˆæ¯...")
            await history_collector.collect_channel_history(client)
        except Exception as e:
            logger.error(f"è‡ªåŠ¨é‡‡é›†å†å²æ¶ˆæ¯å¤±è´¥: {e}")
    
    async def _process_and_save_message(self, message, channel_id: str, is_history: bool = False):
        """å¤„ç†å¹¶ä¿å­˜æ¶ˆæ¯ï¼ˆç”¨äºå†å²æ¶ˆæ¯é‡‡é›†ï¼‰"""
        try:
            # ä½¿ç”¨é€šç”¨å¤„ç†é€»è¾‘
            processed_data = await self._common_message_processing(message, channel_id, is_history=True)
            if not processed_data:
                return  # æ¶ˆæ¯è¢«è¿‡æ»¤
            
            # æå–å¤„ç†åçš„æ•°æ®
            content = processed_data['content']
            filtered_content = processed_data['filtered_content']
            is_ad = processed_data['is_ad']
            media_info = processed_data['media_info']
            
            # ä½¿ç”¨æ¶ˆæ¯ç»„åˆå™¨å¤„ç†æ¶ˆæ¯ï¼Œä¼ é€’è¿‡æ»¤åçš„å†…å®¹
            # å†å²æ¶ˆæ¯é‡‡é›†ä½¿ç”¨æ‰¹é‡æ¨¡å¼
            combined_message = await message_grouper.process_message(
                message, channel_id, media_info,
                filtered_content=filtered_content,
                is_ad=is_ad,
                is_batch=is_history  # å†å²æ¶ˆæ¯ä½¿ç”¨æ‰¹é‡æ¨¡å¼
            )
            
            # å¦‚æœè¿”å›Noneï¼Œè¯´æ˜æ¶ˆæ¯æ­£åœ¨ç­‰å¾…ç»„åˆï¼Œæš‚æ—¶ä¸å¤„ç†
            if combined_message is None:
                logger.debug(f"æ¶ˆæ¯ {message.id} æ­£åœ¨ç­‰å¾…ç»„åˆ")
                return
            
            # å¤„ç†å®Œæ•´çš„æ¶ˆæ¯ï¼ˆå•ç‹¬æ¶ˆæ¯æˆ–ç»„åˆæ¶ˆæ¯ï¼‰
            await self._save_processed_message(combined_message, channel_id, is_history)
                    
        except Exception as e:
            logger.error(f"å¤„ç†å¹¶ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")
            # å‡ºé”™æ—¶æ¸…ç†åª’ä½“æ–‡ä»¶
            if media_info:
                await media_handler.cleanup_file(media_info['file_path'])
    
    async def _save_processed_message(self, message_data: dict, channel_id: str, is_history: bool = False):
        """ä¿å­˜å¤„ç†åçš„æ¶ˆæ¯"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è¿‡æ»¤åçš„å†…å®¹ï¼ˆä»message_grouperä¼ é€’è¿‡æ¥çš„ï¼‰
            if 'filtered_content' in message_data:
                # å·²ç»è¿‡æ»¤è¿‡äº†ï¼Œç›´æ¥ä½¿ç”¨
                filtered_content = message_data['filtered_content']
                is_ad = message_data.get('is_ad', False)
                logger.info(f"ğŸ“ ä½¿ç”¨é¢„è¿‡æ»¤å†…å®¹ï¼Œé•¿åº¦: {len(filtered_content)} å­—ç¬¦")
            else:
                # æœªè¿‡æ»¤ï¼Œè¿›è¡Œè¿‡æ»¤ï¼ˆå…¼å®¹æ—§çš„è°ƒç”¨æ–¹å¼ï¼‰
                logger.info(f"ğŸ“ å¼€å§‹å†…å®¹è¿‡æ»¤ï¼ŒåŸå§‹å†…å®¹é•¿åº¦: {len(message_data.get('content', ''))} å­—ç¬¦")
                if message_data.get('content'):
                    logger.info(f"ğŸ“ å†…å®¹é¢„è§ˆ: {message_data['content'][:100]}...")
                
                # å†…å®¹è¿‡æ»¤
                is_ad, filtered_content, filter_reason = self.content_filter.filter_message(message_data['content'])
                
                # å¯¹äºç»„åˆæ¶ˆæ¯ï¼Œå¦‚æœæ–‡æœ¬è¢«åˆ¤å®šä¸ºå¹¿å‘Šï¼Œä¿ç•™åŸå§‹å†…å®¹ä¾›å®¡æ ¸
                # é¿å…å‡ºç°åªæœ‰åª’ä½“æ²¡æœ‰æ–‡æœ¬çš„æƒ…å†µ
                if message_data.get('is_combined') and is_ad and not filtered_content:
                    logger.info(f"ğŸ“ ç»„åˆæ¶ˆæ¯è¢«åˆ¤å®šä¸ºå¹¿å‘Šï¼Œä¿ç•™åŸå§‹æ–‡æœ¬ä¾›å®¡æ ¸")
                    filtered_content = message_data['content']  # ä¿ç•™åŸå§‹å†…å®¹
                
                # æ·»åŠ è¿‡æ»¤åçš„æ—¥å¿—
                if message_data.get('content') != filtered_content:
                    logger.info(f"ğŸ“ å†…å®¹è¿‡æ»¤å®Œæˆï¼Œé•¿åº¦å˜åŒ–: {len(message_data.get('content', ''))} -> {len(filtered_content)} å­—ç¬¦")
                else:
                    logger.info(f"ğŸ“ å†…å®¹è¿‡æ»¤å®Œæˆï¼Œé•¿åº¦æ— å˜åŒ–: {len(filtered_content)} å­—ç¬¦")
            
            # åˆå§‹åŒ–åª’ä½“å“ˆå¸Œå˜é‡
            media_hash = None
            combined_media_hash = None
            
            # å¦‚æœæ˜¯å¹¿å‘Šä¸”é…ç½®äº†è‡ªåŠ¨è¿‡æ»¤ï¼Œåˆ™è·³è¿‡
            auto_filter_ads = await db_settings.get_auto_filter_ads()
            if is_ad and auto_filter_ads:
                logger.info(f"{'å†å²' if is_history else 'å®æ—¶'}æ¶ˆæ¯ï¼šè‡ªåŠ¨è¿‡æ»¤å¹¿å‘Šæ¶ˆæ¯: {message_data.get('content', '')[:50]}...")
                
                # æ¸…ç†å·²ä¸‹è½½çš„åª’ä½“æ–‡ä»¶
                if message_data.get('media_url') and os.path.exists(message_data['media_url']):
                    await media_handler.cleanup_file(message_data['media_url'])
                
                # å¯¹äºç»„åˆæ¶ˆæ¯ï¼Œæ¸…ç†æ‰€æœ‰åª’ä½“æ–‡ä»¶
                if message_data.get('is_combined') and message_data.get('combined_messages'):
                    for msg in message_data['combined_messages']:
                        if msg.get('media_info') and msg['media_info'].get('file_path'):
                            if os.path.exists(msg['media_info']['file_path']):
                                await media_handler.cleanup_file(msg['media_info']['file_path'])
                
                # å¯¹äºåª’ä½“ç»„ï¼Œæ¸…ç†æ‰€æœ‰åª’ä½“æ–‡ä»¶
                if message_data.get('media_group'):
                    for media_item in message_data['media_group']:
                        if media_item.get('file_path') and os.path.exists(media_item['file_path']):
                            await media_handler.cleanup_file(media_item['file_path'])
                
                return
            
            # è®¡ç®—åª’ä½“å“ˆå¸Œï¼ˆå…ˆè®¡ç®—ï¼Œå†æ£€æŸ¥é‡å¤ï¼‰
            logger.info(f"ğŸ“Š å¼€å§‹è®¡ç®—åª’ä½“å“ˆå¸Œ: is_combined={message_data.get('is_combined')}, media_type={message_data.get('media_type')}, media_url={message_data.get('media_url')}")
            
            # åˆå§‹åŒ–è§†è§‰å“ˆå¸Œ
            visual_hash = None
            combined_visual_hashes = []
            
            # å•ä¸ªåª’ä½“å“ˆå¸Œå’Œè§†è§‰å“ˆå¸Œ
            if message_data.get('media_type') and message_data.get('media_url'):
                # ä»æ–‡ä»¶è®¡ç®—å“ˆå¸Œ
                media_hash = await media_handler._calculate_file_hash(message_data['media_url'])
                logger.info(f"ğŸ“Š å•ä¸ªåª’ä½“å“ˆå¸Œè®¡ç®—å®Œæˆ: {media_hash}")
                
                # è®¡ç®—è§†è§‰å“ˆå¸Œï¼ˆä»…å¯¹å›¾ç‰‡ï¼‰
                if message_data.get('media_type') in ['photo', 'animation']:
                    try:
                        from app.services.visual_similarity import visual_detector
                        if visual_detector and os.path.exists(message_data['media_url']):
                            with open(message_data['media_url'], 'rb') as f:
                                image_data = f.read()
                            visual_hashes = visual_detector.calculate_perceptual_hashes(image_data)
                            visual_hash = str(visual_hashes)
                            logger.info(f"ğŸ“Š å•ä¸ªåª’ä½“è§†è§‰å“ˆå¸Œè®¡ç®—å®Œæˆ")
                    except Exception as e:
                        logger.debug(f"è®¡ç®—è§†è§‰å“ˆå¸Œå¤±è´¥: {e}")
            
            # ç»„åˆåª’ä½“å“ˆå¸Œ
            if message_data.get('is_combined'):
                combined_media_list = []
                
                # ä¼˜å…ˆä»media_groupè·å–ï¼ˆæ–°æ ¼å¼ï¼‰
                if message_data.get('media_group'):
                    logger.info(f"ğŸ“Š å¤„ç†åª’ä½“ç»„: {len(message_data['media_group'])} ä¸ªæ–‡ä»¶")
                    for i, media_item in enumerate(message_data['media_group']):
                        if media_item.get('file_path'):
                            # è®¡ç®—æ¯ä¸ªåª’ä½“æ–‡ä»¶çš„å“ˆå¸Œ
                            file_hash = await media_handler._calculate_file_hash(media_item['file_path'])
                            logger.info(f"ğŸ“Š åª’ä½“{i+1}å“ˆå¸Œ: {file_hash} (æ–‡ä»¶: {media_item.get('file_path')})")
                            if file_hash:
                                combined_media_list.append({
                                    'hash': file_hash,
                                    'message_id': media_item.get('message_id', 0)
                                })
                            
                            # è®¡ç®—è§†è§‰å“ˆå¸Œï¼ˆä»…å¯¹å›¾ç‰‡ï¼‰
                            if media_item.get('media_type') in ['photo', 'animation']:
                                try:
                                    from app.services.visual_similarity import visual_detector
                                    if visual_detector and os.path.exists(media_item['file_path']):
                                        with open(media_item['file_path'], 'rb') as f:
                                            image_data = f.read()
                                        item_visual_hash = visual_detector.calculate_perceptual_hashes(image_data)
                                        combined_visual_hashes.append(item_visual_hash)
                                        logger.info(f"ğŸ“Š åª’ä½“{i+1}è§†è§‰å“ˆå¸Œè®¡ç®—å®Œæˆ")
                                except Exception as e:
                                    logger.debug(f"è®¡ç®—åª’ä½“{i+1}è§†è§‰å“ˆå¸Œå¤±è´¥: {e}")
                # å…¼å®¹æ—§æ ¼å¼combined_messages
                elif message_data.get('combined_messages'):
                    logger.info(f"ğŸ“Š å¤„ç†æ—§æ ¼å¼ç»„åˆæ¶ˆæ¯: {len(message_data['combined_messages'])} ä¸ª")
                    for msg in message_data['combined_messages']:
                        if msg.get('media_info') and msg['media_info'].get('file_path'):
                            # è®¡ç®—æ¯ä¸ªåª’ä½“æ–‡ä»¶çš„å“ˆå¸Œ
                            file_hash = await media_handler._calculate_file_hash(msg['media_info']['file_path'])
                            if file_hash:
                                combined_media_list.append({
                                    'hash': file_hash,
                                    'message_id': msg.get('message_id', 0)
                                })
                
                if combined_media_list:
                    combined_media_hash = await media_handler.process_media_group(combined_media_list)
                    logger.info(f"ğŸ“Š ç»„åˆåª’ä½“å“ˆå¸Œè®¡ç®—å®Œæˆ: {combined_media_hash}")
                else:
                    logger.warning("ğŸ“Š æ²¡æœ‰æœ‰æ•ˆçš„åª’ä½“æ–‡ä»¶ç”¨äºè®¡ç®—ç»„åˆå“ˆå¸Œ")
                
                # ç»„åˆè§†è§‰å“ˆå¸Œåˆ—è¡¨ä¸ºå­—ç¬¦ä¸²
                if combined_visual_hashes:
                    visual_hash = str(combined_visual_hashes)
                    logger.info(f"ğŸ“Š ç»„åˆåª’ä½“åŒ…å« {len(combined_visual_hashes)} ä¸ªè§†è§‰å“ˆå¸Œ")
            
            # ä½¿ç”¨æ•´åˆçš„é‡å¤æ£€æµ‹å™¨ï¼ˆå†å²æ¶ˆæ¯å’Œå®æ—¶æ¶ˆæ¯éƒ½éœ€è¦æ£€æµ‹é‡å¤ï¼‰
            from app.services.duplicate_detector import DuplicateDetector
            duplicate_detector = DuplicateDetector()
            
            async with AsyncSessionLocal() as check_db:
                # æ‰§è¡Œæ•´åˆçš„é‡å¤æ£€æµ‹ï¼ˆåŒ…æ‹¬è§†è§‰ç›¸ä¼¼åº¦ï¼‰
                visual_hashes_dict = None
                if visual_hash:
                    try:
                        # å°è¯•è§£æè§†è§‰å“ˆå¸Œå­—ç¬¦ä¸²
                        visual_hashes_dict = eval(visual_hash) if isinstance(visual_hash, str) else visual_hash
                        # å¦‚æœæ˜¯åˆ—è¡¨ï¼ˆç»„åˆåª’ä½“ï¼‰ï¼Œå–ç¬¬ä¸€ä¸ª
                        if isinstance(visual_hashes_dict, list) and visual_hashes_dict:
                            visual_hashes_dict = visual_hashes_dict[0]
                    except:
                        pass
                
                is_duplicate, original_msg_id, duplicate_type = await duplicate_detector.is_duplicate_message(
                    source_channel=channel_id,
                    media_hash=media_hash,
                    combined_media_hash=combined_media_hash,
                    content=message_data.get('content'),
                    message_time=message_data.get('date') or datetime.now(),
                    visual_hashes=visual_hashes_dict,
                    db=check_db
                )
                
                if is_duplicate:
                    logger.info(f"{'å†å²' if is_history else 'å®æ—¶'}æ¶ˆæ¯ï¼šå‘ç°é‡å¤æ¶ˆæ¯ï¼ˆ{duplicate_type}ï¼‰ï¼ŒåŸå§‹æ¶ˆæ¯ID: {original_msg_id}ï¼Œè·³è¿‡å¤„ç†")
                    # æ¸…ç†å·²ä¸‹è½½çš„åª’ä½“æ–‡ä»¶
                    if message_data.get('media_url') and os.path.exists(message_data['media_url']):
                        await media_handler.cleanup_file(message_data['media_url'])
                    # æ¸…ç†ç»„åˆæ¶ˆæ¯çš„åª’ä½“æ–‡ä»¶
                    if message_data.get('media_group'):
                        for media_item in message_data['media_group']:
                            if media_item.get('file_path') and os.path.exists(media_item['file_path']):
                                await media_handler.cleanup_file(media_item['file_path'])
                    return
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            async with AsyncSessionLocal() as db:
                db_message = Message(
                    source_channel=channel_id,
                    message_id=message_data['message_id'],
                    content=message_data['content'],
                    media_type=message_data.get('media_type'),
                    media_url=message_data.get('media_url'),
                    grouped_id=str(message_data.get('grouped_id')) if message_data.get('grouped_id') else None,
                    is_combined=message_data.get('is_combined', False),
                    combined_messages=message_data.get('combined_messages'),
                    # æ·»åŠ åª’ä½“å“ˆå¸Œå­—æ®µ
                    media_hash=media_hash,
                    combined_media_hash=combined_media_hash,
                    visual_hash=visual_hash,  # æ·»åŠ è§†è§‰å“ˆå¸Œ
                    media_group=message_data.get('media_group'),
                    is_ad=is_ad,
                    filtered_content=filtered_content,
                    status='pending' if not is_history else 'auto_forwarded',
                    created_at=message_data.get('date').replace(tzinfo=None) if message_data.get('date') and hasattr(message_data.get('date'), 'tzinfo') else (message_data.get('date') or datetime.now())
                )
                db.add(db_message)
                await db.commit()
                await db.refresh(db_message)
                
                # è½¬å‘åˆ°å®¡æ ¸ç¾¤ï¼ˆå†å²æ¶ˆæ¯å’Œå®æ—¶æ¶ˆæ¯éƒ½éœ€è¦å®¡æ ¸ï¼‰
                await self.forward_to_review(db_message)
                
                # å¹¿æ’­æ–°æ¶ˆæ¯åˆ°WebSocketå®¢æˆ·ç«¯
                await self._broadcast_new_message(db_message)
                    
        except Exception as e:
            logger.error(f"ä¿å­˜å¤„ç†åçš„æ¶ˆæ¯å¤±è´¥: {e}")
            # å‡ºé”™æ—¶æ¸…ç†åª’ä½“æ–‡ä»¶
            if message_data.get('media_url') and os.path.exists(message_data['media_url']):
                await media_handler.cleanup_file(message_data['media_url'])
    
    async def _cleanup_message_files(self, message: Message):
        """æ¸…ç†æ¶ˆæ¯ç›¸å…³çš„åª’ä½“æ–‡ä»¶"""
        try:
            if message.is_combined and message.media_group:
                # æ¸…ç†ç»„åˆæ¶ˆæ¯çš„æ‰€æœ‰åª’ä½“æ–‡ä»¶
                for media_item in message.media_group:
                    file_path = media_item['file_path']
                    if os.path.exists(file_path):
                        await media_handler.cleanup_file(file_path)
            elif message.media_url and os.path.exists(message.media_url):
                # æ¸…ç†å•ä¸ªåª’ä½“æ–‡ä»¶
                await media_handler.cleanup_file(message.media_url)
        except Exception as e:
            logger.error(f"æ¸…ç†æ¶ˆæ¯æ–‡ä»¶æ—¶å‡ºé”™: {e}")

# å…¨å±€botå®ä¾‹ï¼Œä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
telegram_bot = None