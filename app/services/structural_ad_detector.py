"""
ç»“æ„åŒ–å¹¿å‘Šæ£€æµ‹å™¨
æ£€æµ‹Telegramæ¶ˆæ¯ç»“æ„ä¸­çš„éšè—å¹¿å‘Šï¼ˆæŒ‰é’®ã€å®ä½“é“¾æ¥ç­‰ï¼‰
"""
import logging
import re
from typing import List, Dict, Tuple, Optional, Any
from app.services.ad_detector import ad_detector

logger = logging.getLogger(__name__)


class StructuralAdDetector:
    """ç»“æ„åŒ–å¹¿å‘Šæ£€æµ‹å™¨"""
    
    def __init__(self):
        self.ad_detector = ad_detector
        
    async def detect_structural_ads(self, message: Any) -> Dict:
        """
        æ£€æµ‹æ¶ˆæ¯ç»“æ„ä¸­çš„å¹¿å‘Š
        
        Args:
            message: Telegramæ¶ˆæ¯å¯¹è±¡
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        result = {
            'has_structural_ad': False,
            'confidence': 0.0,
            'ad_type': None,
            'suspicious_buttons': [],
            'suspicious_entities': [],
            'clean_text': message.text or '',
            'removed_elements': []
        }
        
        # æå–æ¶ˆæ¯ç»„ä»¶
        components = self._extract_message_components(message)
        
        # 1. æ–°å¢ï¼šæ¨å¹¿å®ä½“æ¨¡å¼æ£€æµ‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        entity_pattern_result = self._detect_promotional_entity_patterns(message, components)
        if entity_pattern_result['has_ad']:
            result['has_structural_ad'] = True
            result['confidence'] = max(result['confidence'], entity_pattern_result['confidence'])
            result['ad_type'] = entity_pattern_result['ad_type']
            result['suspicious_entities'].extend(entity_pattern_result['suspicious_entities'])
            result['removed_elements'].extend(entity_pattern_result['removed_elements'])
            result['clean_text'] = entity_pattern_result['clean_text']
            logger.info(f"æ£€æµ‹åˆ°æ¨å¹¿å®ä½“æ¨¡å¼: {entity_pattern_result['ad_type']}")
        
        # 2. åˆ†ææŒ‰é’®å¹¿å‘Š
        if components['buttons']:
            button_analysis = self._analyze_buttons(
                message.text,
                components['buttons']
            )
            if button_analysis['has_ad']:
                result['has_structural_ad'] = True
                result['confidence'] = max(result['confidence'], button_analysis['confidence'])
                result['suspicious_buttons'] = button_analysis['suspicious_buttons']
                result['removed_elements'].extend([
                    {'type': 'button', 'content': btn} 
                    for btn in button_analysis['suspicious_buttons']
                ])
                if not result['ad_type']:
                    result['ad_type'] = 'button_ads'
        
        # 3. åˆ†æéšè—é“¾æ¥ï¼ˆå¦‚æœæ¨å¹¿æ¨¡å¼æ£€æµ‹æ²¡æœ‰å®Œå…¨å¤„ç†ï¼‰
        if components['entities'] and not entity_pattern_result['has_ad']:
            entity_analysis = self._analyze_entities(
                message.text,
                components['entities']
            )
            if entity_analysis['has_ad']:
                result['has_structural_ad'] = True
                result['confidence'] = max(result['confidence'], entity_analysis['confidence'])
                result['suspicious_entities'] = entity_analysis['suspicious_entities']
                result['removed_elements'].extend([
                    {'type': 'entity', 'content': ent}
                    for ent in entity_analysis['suspicious_entities']
                ])
                if not result['ad_type']:
                    result['ad_type'] = 'hidden_links'
        
        # 4. ç”Ÿæˆæ¸…ç†åçš„æ–‡æœ¬ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è¢«æ¨å¹¿æ¨¡å¼æ£€æµ‹å¤„ç†ï¼‰
        if result['has_structural_ad'] and not entity_pattern_result['has_ad']:
            result['clean_text'] = self._clean_text_from_ads(
                message.text,
                result['suspicious_entities']
            )
        
        return result
    
    def _extract_message_components(self, message: Any) -> Dict:
        """æå–æ¶ˆæ¯çš„ç»“æ„åŒ–ç»„ä»¶"""
        components = {
            'buttons': [],
            'entities': [],
            'media': None
        }
        
        try:
            # æå–æŒ‰é’®
            if hasattr(message, 'reply_markup') and message.reply_markup:
                if hasattr(message.reply_markup, 'rows'):
                    for row in message.reply_markup.rows:
                        for button in row.buttons:
                            button_info = {
                                'text': getattr(button, 'text', ''),
                                'url': getattr(button, 'url', None),
                                'data': getattr(button, 'data', None)
                            }
                            components['buttons'].append(button_info)
            
            # æå–å®ä½“ï¼ˆéšè—é“¾æ¥ç­‰ï¼‰
            if hasattr(message, 'entities') and message.entities:
                for entity in message.entities:
                    entity_info = {
                        'type': entity.__class__.__name__,
                        'offset': getattr(entity, 'offset', 0),
                        'length': getattr(entity, 'length', 0),
                        'url': getattr(entity, 'url', None)
                    }
                    
                    # æå–å®ä½“å¯¹åº”çš„æ–‡æœ¬
                    if message.text and entity_info['offset'] is not None and entity_info['length']:
                        start = entity_info['offset']
                        end = start + entity_info['length']
                        entity_info['text'] = message.text[start:end]
                    
                    components['entities'].append(entity_info)
            
            # æå–åª’ä½“ä¿¡æ¯
            if hasattr(message, 'media') and message.media:
                components['media'] = {
                    'type': message.media.__class__.__name__,
                    'has_webpage': hasattr(message.media, 'webpage')
                }
        
        except Exception as e:
            logger.error(f"æå–æ¶ˆæ¯ç»„ä»¶å¤±è´¥: {e}")
        
        return components
    
    def _detect_promotional_entity_patterns(self, message: Any, components: Dict) -> Dict:
        """
        æ£€æµ‹æ¨å¹¿å®ä½“æ¨¡å¼ - åŸºäºTelegramæ¶ˆæ¯å®ä½“ç»“æ„
        
        Args:
            message: Telegramæ¶ˆæ¯å¯¹è±¡
            components: æå–çš„æ¶ˆæ¯ç»„ä»¶
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        result = {
            'has_ad': False,
            'confidence': 0.0,
            'ad_type': None,
            'suspicious_entities': [],
            'removed_elements': [],
            'clean_text': message.text or ''
        }
        
        if not message.text or not components['entities']:
            return result
        
        text = message.text
        entities = components['entities']
        
        # 1. æ£€æµ‹"æœ¬é¢‘é“æ¨è"æ ‡è®°
        channel_promo_detected = self._detect_channel_promotion_marker(text)
        
        # 2. åˆ†æå®ä½“å¯†åº¦å’Œåˆ†å¸ƒ
        entity_analysis = self._analyze_entity_density_and_distribution(text, entities)
        
        # 3. æ£€æµ‹ä»£ç å—ä¸­çš„æ¨å¹¿å†…å®¹
        code_block_analysis = self._detect_promotional_code_blocks(text, entities)
        
        # 4. æ£€æµ‹å®ä½“ç»„åˆæ¨¡å¼
        pattern_analysis = self._detect_entity_combination_patterns(text, entities)
        
        # ç»¼åˆåˆ¤å®š
        confidence_scores = []
        ad_types = []
        
        if channel_promo_detected['detected']:
            confidence_scores.append(0.9)  # é«˜ç½®ä¿¡åº¦
            ad_types.append('channel_promotion')
            result['suspicious_entities'].extend(channel_promo_detected.get('entities', []))
        
        if code_block_analysis['has_promotional_content']:
            confidence_scores.append(code_block_analysis['confidence'])
            ad_types.append('code_block_promotion')
            result['suspicious_entities'].extend(code_block_analysis['suspicious_entities'])
        
        if entity_analysis['is_promotional']:
            confidence_scores.append(entity_analysis['confidence'])
            ad_types.append('entity_density_anomaly')
        
        if pattern_analysis['has_promotional_pattern']:
            confidence_scores.append(pattern_analysis['confidence'])
            ad_types.append('promotional_entity_pattern')
            result['suspicious_entities'].extend(pattern_analysis['suspicious_entities'])
        
        # ç»¼åˆåˆ¤å®šç»“æœ
        if confidence_scores:
            result['has_ad'] = True
            result['confidence'] = max(confidence_scores)
            result['ad_type'] = ad_types[confidence_scores.index(max(confidence_scores))]
            
            # åŸºäºå®ä½“çš„å†…å®¹åˆ†åŒºå’Œæ¸…ç†
            result['clean_text'] = self._partition_and_clean_content(
                text, entities, result['suspicious_entities'], channel_promo_detected
            )
            
            logger.info(f"æ¨å¹¿å®ä½“æ¨¡å¼æ£€æµ‹: {result['ad_type']}, ç½®ä¿¡åº¦: {result['confidence']:.2f}")
        
        return result
    
    def _detect_channel_promotion_marker(self, text: str) -> Dict:
        """æ£€æµ‹"æœ¬é¢‘é“æ¨è"æ ‡è®°"""
        result = {'detected': False, 'position': -1, 'entities': []}
        
        # æ£€æµ‹"æœ¬é¢‘é“æ¨è"æ¨¡å¼ï¼ˆæ”¯æŒè¡¨æƒ…ç¬¦å·åŒ…å›´ï¼‰
        channel_promo_patterns = [
            r'[ğŸ˜†ğŸ‰ğŸ”¥â­âœ¨]*\s*æœ¬é¢‘é“æ¨è\s*[ğŸ˜†ğŸ‰ğŸ”¥â­âœ¨]*',
            r'[ğŸ¾ğŸ¯ğŸ’°ğŸ†âš¡]*\s*æœ¬é¢‘é“æ¨è\s*[ğŸ¾ğŸ¯ğŸ’°ğŸ†âš¡]*',
            r'\*+\s*æœ¬é¢‘é“æ¨è\s*\*+',
            r'#+\s*æœ¬é¢‘é“æ¨è\s*#+',
        ]
        
        for pattern in channel_promo_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                result['detected'] = True
                result['position'] = match.start()
                logger.debug(f"æ£€æµ‹åˆ°é¢‘é“æ¨èæ ‡è®°: {match.group()}")
                break
        
        return result
    
    def _analyze_entity_density_and_distribution(self, text: str, entities: List[Dict]) -> Dict:
        """åˆ†æå®ä½“å¯†åº¦å’Œåˆ†å¸ƒ"""
        result = {
            'is_promotional': False,
            'confidence': 0.0,
            'entity_density': 0.0,
            'formatting_ratio': 0.0
        }
        
        if not entities or not text:
            return result
        
        text_length = len(text)
        total_entities = len(entities)
        
        # è®¡ç®—å®ä½“å¯†åº¦ï¼ˆæ¯100å­—ç¬¦çš„å®ä½“æ•°ï¼‰
        entity_density = (total_entities * 100) / text_length
        result['entity_density'] = entity_density
        
        # ç»Ÿè®¡æ ¼å¼åŒ–å®ä½“ï¼ˆBold, Italic, Codeç­‰ï¼‰
        formatting_entities = 0
        for entity in entities:
            entity_type = entity.get('type', '')
            if entity_type in ['MessageEntityBold', 'MessageEntityItalic', 
                              'MessageEntityCode', 'MessageEntityPre',
                              'MessageEntityStrikethrough', 'MessageEntityUnderline']:
                formatting_entities += 1
        
        formatting_ratio = formatting_entities / total_entities if total_entities > 0 else 0
        result['formatting_ratio'] = formatting_ratio
        
        # æ¨å¹¿åˆ¤å®šé€»è¾‘
        # 1. å®ä½“å¯†åº¦è¿‡é«˜ï¼ˆæ¯100å­—ç¬¦è¶…è¿‡8ä¸ªå®ä½“ï¼‰
        if entity_density > 8.0:
            result['is_promotional'] = True
            result['confidence'] = min(0.8, entity_density / 15.0)
        
        # 2. æ ¼å¼åŒ–å®ä½“æ¯”ä¾‹è¿‡é«˜ï¼ˆè¶…è¿‡60%ï¼‰
        elif formatting_ratio > 0.6 and total_entities > 5:
            result['is_promotional'] = True
            result['confidence'] = min(0.7, formatting_ratio)
        
        # 3. ä¸­ç­‰å¯†åº¦ä½†åˆ†å¸ƒå¼‚å¸¸ï¼ˆå®ä½“é›†ä¸­åœ¨ååŠéƒ¨åˆ†ï¼Œå…¸å‹çš„æ¨å¹¿æ¨¡å¼ï¼‰
        elif entity_density > 4.0 and self._is_entity_distribution_suspicious(text, entities):
            result['is_promotional'] = True
            result['confidence'] = 0.6
        
        return result
    
    def _detect_promotional_code_blocks(self, text: str, entities: List[Dict]) -> Dict:
        """æ£€æµ‹ä»£ç å—å®ä½“ä¸­çš„æ¨å¹¿å†…å®¹"""
        result = {
            'has_promotional_content': False,
            'confidence': 0.0,
            'suspicious_entities': []
        }
        
        # æŸ¥æ‰¾ä»£ç å—å®ä½“
        code_block_entities = [
            entity for entity in entities 
            if entity.get('type') == 'MessageEntityPre'
        ]
        
        if not code_block_entities:
            return result
        
        # æ£€æŸ¥æ¯ä¸ªä»£ç å—çš„å†…å®¹
        for entity in code_block_entities:
            offset = entity.get('offset', 0)
            length = entity.get('length', 0)
            
            if offset + length <= len(text):
                code_content = text[offset:offset + length]
                
                # æ£€æµ‹ä»£ç å—ä¸­çš„æ¨å¹¿å…³é”®è¯
                promotional_keywords = [
                    'åç¡•ç§‘æŠ€', 'å¸ç›˜', 'EX', 'äº¤æ˜“æ‰€', 'åŒ…ç½‘',
                    'é“¶æ²³å›½é™…', 'ä¸“å±å›é¦ˆ', 'ç°å·²ä¸Šçº¿',
                    'è®¢é˜…é¢‘é“', 'æŠ•ç¨¿çˆ†æ–™', 'è”ç³»', '@yefan11',
                    'åšè‹¥ç£çŸ³', 'å…¨å¤©åœ¨çº¿', 'è¿å’¨è¯¢'
                ]
                
                promo_keyword_count = 0
                for keyword in promotional_keywords:
                    if keyword in code_content:
                        promo_keyword_count += 1
                
                # å¦‚æœä»£ç å—åŒ…å«å¤šä¸ªæ¨å¹¿å…³é”®è¯ï¼Œåˆ¤å®šä¸ºæ¨å¹¿å†…å®¹
                if promo_keyword_count >= 2:
                    result['has_promotional_content'] = True
                    result['confidence'] = min(0.9, 0.5 + (promo_keyword_count * 0.1))
                    result['suspicious_entities'].append(entity)
                    logger.info(f"ä»£ç å—æ¨å¹¿å†…å®¹: åŒ…å«{promo_keyword_count}ä¸ªå…³é”®è¯")
        
        return result
    
    def _detect_entity_combination_patterns(self, text: str, entities: List[Dict]) -> Dict:
        """æ£€æµ‹å®ä½“ç»„åˆæ¨¡å¼"""
        result = {
            'has_promotional_pattern': False,
            'confidence': 0.0,
            'suspicious_entities': []
        }
        
        if len(entities) < 3:
            return result
        
        # æŒ‰åç§»é‡æ’åºå®ä½“
        sorted_entities = sorted(entities, key=lambda x: x.get('offset', 0))
        
        # æ£€æµ‹æ¨å¹¿æ¨¡å¼ï¼šBold + Code/Pre + URL/Mention çš„ç»„åˆ
        entity_types = [entity.get('type', '') for entity in sorted_entities]
        
        # æ¨¡å¼1ï¼šè¿ç»­çš„Boldå®ä½“ï¼ˆè£…é¥°æ€§æ ¼å¼åŒ–ï¼‰
        consecutive_bold_count = 0
        max_consecutive_bold = 0
        for entity_type in entity_types:
            if entity_type == 'MessageEntityBold':
                consecutive_bold_count += 1
                max_consecutive_bold = max(max_consecutive_bold, consecutive_bold_count)
            else:
                consecutive_bold_count = 0
        
        if max_consecutive_bold >= 3:
            result['has_promotional_pattern'] = True
            result['confidence'] = min(0.8, 0.5 + (max_consecutive_bold * 0.1))
            result['suspicious_entities'] = [
                entity for entity in sorted_entities 
                if entity.get('type') == 'MessageEntityBold'
            ]
        
        # æ¨¡å¼2ï¼šPre + å¤šä¸ªURLçš„ç»„åˆ
        has_pre = 'MessageEntityPre' in entity_types
        url_count = entity_types.count('MessageEntityUrl') + entity_types.count('MessageEntityTextUrl')
        
        if has_pre and url_count >= 2:
            result['has_promotional_pattern'] = True
            result['confidence'] = max(result['confidence'], 0.75)
            for entity in sorted_entities:
                if entity.get('type') in ['MessageEntityPre', 'MessageEntityUrl', 'MessageEntityTextUrl']:
                    result['suspicious_entities'].append(entity)
        
        # æ¨¡å¼3ï¼šå®ä½“ç±»å‹å¤šæ ·æ€§å¼‚å¸¸ï¼ˆæ¨å¹¿æ¶ˆæ¯é€šå¸¸åŒ…å«å¤šç§æ ¼å¼åŒ–ï¼‰
        unique_types = set(entity_types)
        if len(unique_types) >= 5 and len(entities) <= 15:  # ç±»å‹å¤šä½†æ€»æ•°ä¸å¤šï¼Œå…¸å‹æ¨å¹¿ç‰¹å¾
            result['has_promotional_pattern'] = True
            result['confidence'] = max(result['confidence'], 0.65)
        
        return result
    
    def _is_entity_distribution_suspicious(self, text: str, entities: List[Dict]) -> bool:
        """æ£€æµ‹å®ä½“åˆ†å¸ƒæ˜¯å¦å¯ç–‘ï¼ˆé›†ä¸­åœ¨ååŠéƒ¨åˆ†ï¼‰"""
        if len(entities) < 5:
            return False
        
        text_length = len(text)
        second_half_start = text_length // 2
        
        entities_in_second_half = sum(
            1 for entity in entities 
            if entity.get('offset', 0) >= second_half_start
        )
        
        # å¦‚æœè¶…è¿‡70%çš„å®ä½“åœ¨ååŠéƒ¨åˆ†ï¼Œè®¤ä¸ºåˆ†å¸ƒå¯ç–‘
        return (entities_in_second_half / len(entities)) > 0.7
    
    def _partition_and_clean_content(self, text: str, entities: List[Dict], 
                                   suspicious_entities: List[Dict], 
                                   channel_promo_info: Dict) -> str:
        """åŸºäºå®ä½“çš„å†…å®¹åˆ†åŒºå’Œæ¸…ç†"""
        if not text:
            return text
        
        # å¦‚æœæ£€æµ‹åˆ°"æœ¬é¢‘é“æ¨è"ï¼Œä»è¯¥ä½ç½®å¼€å§‹åˆ é™¤åç»­å†…å®¹
        if channel_promo_info['detected']:
            promo_position = channel_promo_info['position']
            # ä¿ç•™æ¨èæ ‡è®°ä¹‹å‰çš„å†…å®¹
            clean_text = text[:promo_position].strip()
            logger.info(f"åŸºäºé¢‘é“æ¨èæ ‡è®°åˆ†åŒºï¼Œä¿ç•™å‰ {promo_position} ä¸ªå­—ç¬¦")
            return clean_text
        
        # å¦åˆ™ï¼Œç§»é™¤å¯ç–‘å®ä½“å¯¹åº”çš„å†…å®¹
        if suspicious_entities:
            clean_text = text
            # æŒ‰åç§»é‡å€’åºæ’åºï¼Œä»åå¾€å‰åˆ é™¤
            sorted_entities = sorted(
                suspicious_entities,
                key=lambda x: x.get('offset', 0),
                reverse=True
            )
            
            for entity in sorted_entities:
                offset = entity.get('offset')
                length = entity.get('length')
                if offset is not None and length and offset + length <= len(clean_text):
                    clean_text = clean_text[:offset] + clean_text[offset + length:]
            
            # æ¸…ç†å¤šä½™ç©ºç™½
            clean_text = re.sub(r'\n{3,}', '\n\n', clean_text).strip()
            return clean_text
        
        return text
    
    def _analyze_buttons(self, text: str, buttons: List[Dict]) -> Dict:
        """åˆ†ææŒ‰é’®æ˜¯å¦ä¸ºå¹¿å‘Š"""
        result = {
            'has_ad': False,
            'confidence': 0.0,
            'suspicious_buttons': []
        }
        
        if not buttons:
            return result
        
        # æå–æŒ‰é’®æ–‡æœ¬
        button_texts = [btn.get('text', '') for btn in buttons if btn.get('text')]
        
        if not button_texts or not text:
            return result
        
        # ä½¿ç”¨è¯­ä¹‰æ£€æµ‹å™¨æ£€æŸ¥ç›¸å…³æ€§
        coherence = self.ad_detector.check_semantic_coherence(text, button_texts)
        
        # ä½ç›¸å…³æ€§è¡¨ç¤ºå¯èƒ½æ˜¯å¹¿å‘Š
        if coherence < 0.35:  # é˜ˆå€¼å¯è°ƒ
            result['has_ad'] = True
            result['confidence'] = 1.0 - coherence
            result['suspicious_buttons'] = buttons
            logger.info(f"æ£€æµ‹åˆ°å¯ç–‘å¹¿å‘ŠæŒ‰é’®ï¼Œè¯­ä¹‰ç›¸å…³æ€§: {coherence:.3f}")
        
        # é¢å¤–æ£€æŸ¥ï¼šURLæ¨¡å¼åˆ†æ
        for button in buttons:
            url = button.get('url', '')
            if url:
                # æ£€æŸ¥çŸ­é“¾æ¥ï¼ˆå¸¸ç”¨äºè¿½è¸ªï¼‰
                if self._is_suspicious_url(url):
                    if button not in result['suspicious_buttons']:
                        result['suspicious_buttons'].append(button)
                        result['has_ad'] = True
                        result['confidence'] = max(result['confidence'], 0.8)
        
        return result
    
    def _analyze_entities(self, text: str, entities: List[Dict]) -> Dict:
        """åˆ†æå®ä½“é“¾æ¥æ˜¯å¦ä¸ºå¹¿å‘Š"""
        result = {
            'has_ad': False,
            'confidence': 0.0,
            'suspicious_entities': []
        }
        
        if not entities or not text:
            return result
        
        for entity in entities:
            if entity.get('url'):
                entity_text = entity.get('text', '')
                
                # æ£€æŸ¥é“¾æ¥æ–‡æœ¬ä¸æ­£æ–‡çš„ç›¸å…³æ€§
                if entity_text:
                    coherence = self.ad_detector.check_semantic_coherence(text, [entity_text])
                    
                    if coherence < 0.4:  # é˜ˆå€¼å¯è°ƒ
                        result['suspicious_entities'].append(entity)
                        result['has_ad'] = True
                        result['confidence'] = max(result['confidence'], 1.0 - coherence)
                        logger.info(f"æ£€æµ‹åˆ°å¯ç–‘éšè—é“¾æ¥: {entity_text[:50]}")
                
                # æ£€æŸ¥URLæœ¬èº«
                if self._is_suspicious_url(entity['url']):
                    if entity not in result['suspicious_entities']:
                        result['suspicious_entities'].append(entity)
                        result['has_ad'] = True
                        result['confidence'] = max(result['confidence'], 0.75)
        
        return result
    
    def _is_suspicious_url(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦å¯ç–‘ï¼ˆä½¿ç”¨æ™ºèƒ½æ¨¡å¼åŒ¹é…è€Œéç¡¬ç¼–ç ï¼‰"""
        if not url:
            return False
        
        url_lower = url.lower()
        
        # çŸ­é“¾æ¥æœåŠ¡ï¼ˆå¸¸ç”¨äºè¿½è¸ªå’Œéšè—çœŸå®URLï¼‰
        short_url_patterns = [
            r'bit\.ly', r'tinyurl\.com', r'goo\.gl', r'ow\.ly',
            r't\.co', r'short\.link', r'tiny\.cc'
        ]
        
        for pattern in short_url_patterns:
            if re.search(pattern, url_lower):
                logger.debug(f"æ£€æµ‹åˆ°çŸ­é“¾æ¥: {url}")
                return True
        
        # Telegramé‚€è¯·é“¾æ¥ï¼ˆå¸¸ç”¨äºæ¨å¹¿ç¾¤ç»„ï¼‰
        if 't.me/+' in url or 't.me/joinchat/' in url:
            logger.debug(f"æ£€æµ‹åˆ°Telegramé‚€è¯·é“¾æ¥: {url}")
            return True
        
        return False
    
    def _clean_text_from_ads(self, text: str, suspicious_entities: List[Dict]) -> str:
        """ä»æ–‡æœ¬ä¸­æ¸…ç†å¹¿å‘Šå®ä½“"""
        if not text or not suspicious_entities:
            return text
        
        clean_text = text
        
        # æŒ‰åç§»é‡é™åºæ’åºï¼Œä»åå¾€å‰åˆ é™¤ï¼Œé¿å…åç§»é‡å˜åŒ–
        sorted_entities = sorted(
            suspicious_entities,
            key=lambda x: x.get('offset', 0),
            reverse=True
        )
        
        for entity in sorted_entities:
            offset = entity.get('offset')
            length = entity.get('length')
            
            if offset is not None and length:
                # åˆ é™¤å®ä½“æ–‡æœ¬
                start = offset
                end = start + length
                
                if 0 <= start < len(clean_text) and end <= len(clean_text):
                    clean_text = clean_text[:start] + clean_text[end:]
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        return clean_text
    
    def extract_button_data(self, message: Any) -> List[Dict]:
        """æå–æ¶ˆæ¯ä¸­çš„æŒ‰é’®æ•°æ®ç”¨äºå­˜å‚¨"""
        buttons = []
        
        try:
            if hasattr(message, 'reply_markup') and message.reply_markup:
                if hasattr(message.reply_markup, 'rows'):
                    for row_idx, row in enumerate(message.reply_markup.rows):
                        for col_idx, button in enumerate(row.buttons):
                            button_data = {
                                'row': row_idx,
                                'col': col_idx,
                                'text': getattr(button, 'text', ''),
                                'url': getattr(button, 'url', None),
                                'callback_data': getattr(button, 'data', None)
                            }
                            buttons.append(button_data)
        except Exception as e:
            logger.error(f"æå–æŒ‰é’®æ•°æ®å¤±è´¥: {e}")
        
        return buttons
    
    def extract_entity_data(self, message: Any) -> List[Dict]:
        """æå–æ¶ˆæ¯ä¸­çš„å®ä½“æ•°æ®ç”¨äºå­˜å‚¨"""
        entities = []
        
        try:
            if hasattr(message, 'entities') and message.entities:
                for entity in message.entities:
                    entity_data = {
                        'type': entity.__class__.__name__,
                        'offset': getattr(entity, 'offset', 0),
                        'length': getattr(entity, 'length', 0),
                        'url': getattr(entity, 'url', None)
                    }
                    
                    # æå–å®ä½“æ–‡æœ¬
                    if message.text and entity_data['offset'] is not None and entity_data['length']:
                        start = entity_data['offset']
                        end = start + entity_data['length']
                        if 0 <= start < len(message.text) and end <= len(message.text):
                            entity_data['text'] = message.text[start:end]
                    
                    # æ ‡è®°éšè—é“¾æ¥
                    if entity_data['type'] == 'MessageEntityTextUrl' and entity_data['url']:
                        entity_data['is_hidden_link'] = True
                    else:
                        entity_data['is_hidden_link'] = False
                    
                    entities.append(entity_data)
        except Exception as e:
            logger.error(f"æå–å®ä½“æ•°æ®å¤±è´¥: {e}")
        
        return entities
    
    def remove_hidden_links(self, message: Any) -> tuple:
        """
        ç§»é™¤æ¶ˆæ¯ä¸­çš„éšè—é“¾æ¥ï¼ˆMessageEntityTextUrlï¼‰
        
        Args:
            message: Telegramæ¶ˆæ¯å¯¹è±¡
            
        Returns:
            tuple: (å¤„ç†åçš„å®ä½“åˆ—è¡¨, è¢«ç§»é™¤çš„éšè—é“¾æ¥åˆ—è¡¨)
        """
        clean_entities = []
        removed_links = []
        
        try:
            if hasattr(message, 'entities') and message.entities:
                for entity in message.entities:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºéšè—é“¾æ¥
                    if entity.__class__.__name__ == 'MessageEntityTextUrl':
                        # è®°å½•è¢«ç§»é™¤çš„é“¾æ¥
                        removed_link_info = {
                            'text': '',
                            'url': getattr(entity, 'url', ''),
                            'offset': getattr(entity, 'offset', 0),
                            'length': getattr(entity, 'length', 0)
                        }
                        
                        # æå–é“¾æ¥æ–‡æœ¬
                        if message.text and removed_link_info['offset'] is not None and removed_link_info['length']:
                            start = removed_link_info['offset']
                            end = start + removed_link_info['length']
                            if 0 <= start < len(message.text) and end <= len(message.text):
                                removed_link_info['text'] = message.text[start:end]
                        
                        removed_links.append(removed_link_info)
                        logger.info(f"ç§»é™¤éšè—é“¾æ¥: {removed_link_info['text']} -> {removed_link_info['url']}")
                    else:
                        # ä¿ç•™å…¶ä»–ç±»å‹çš„å®ä½“ï¼ˆå¦‚ç²—ä½“ã€æ–œä½“ç­‰ï¼‰
                        clean_entities.append(entity)
            
            if removed_links:
                logger.info(f"å…±ç§»é™¤ {len(removed_links)} ä¸ªéšè—é“¾æ¥")
        
        except Exception as e:
            logger.error(f"ç§»é™¤éšè—é“¾æ¥å¤±è´¥: {e}")
            # å‡ºé”™æ—¶è¿”å›åŸå§‹å®ä½“
            return (message.entities if hasattr(message, 'entities') else [], [])
        
        return clean_entities, removed_links


# å…¨å±€å®ä¾‹
structural_detector = StructuralAdDetector()