"""
å¹¿å‘Šå›¾ç‰‡æ£€æµ‹å™¨
ä½¿ç”¨è§†è§‰å“ˆå¸ŒæŠ€æœ¯è¯†åˆ«å·²çŸ¥çš„å¹¿å‘Šå›¾ç‰‡
"""
import json
import logging
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import asyncio
from PIL import Image

from app.services.visual_similarity import VisualSimilarityDetector

logger = logging.getLogger(__name__)

class AdImageDetector:
    """å¹¿å‘Šå›¾ç‰‡æ£€æµ‹å™¨ - åŸºäºè§†è§‰å“ˆå¸Œçš„å›¾ç‰‡å¹¿å‘Šè¯†åˆ«"""
    
    def __init__(self):
        self.visual_detector = VisualSimilarityDetector()
        self.ad_image_hashes = {}  # {file_hash: {visual_hashes, metadata}}
        self.hash_index = {  # åå‘ç´¢å¼•ï¼šå“ˆå¸Œå€¼ -> æ–‡ä»¶åˆ—è¡¨
            'phash': {},
            'dhash': {},
            'ahash': {}
        }
        self.training_data_dir = Path("data/ad_training_data")
        self.index_file = self.training_data_dir / "ad_image_hashes.json"
        self.metadata_file = self.training_data_dir / "media_metadata.json"
        
        # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆæ±‰æ˜è·ç¦»ï¼‰
        self.phash_threshold = 10  # pHashå·®å¼‚é˜ˆå€¼
        self.dhash_threshold = 12  # dHashå·®å¼‚é˜ˆå€¼
        self.ahash_threshold = 12  # aHashå·®å¼‚é˜ˆå€¼
        
        # åŠ è½½å·²æœ‰çš„å“ˆå¸Œç´¢å¼•
        self.load_ad_image_hashes()
    
    def load_ad_image_hashes(self) -> None:
        """åŠ è½½å¹¿å‘Šå›¾ç‰‡çš„è§†è§‰å“ˆå¸Œç´¢å¼•"""
        try:
            # ä¼˜å…ˆä»ç´¢å¼•æ–‡ä»¶åŠ è½½
            if self.index_file.exists():
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.ad_image_hashes = data.get('ad_images', {})
                    self._rebuild_hash_index()
                    logger.info(f"âœ… ä»ç´¢å¼•æ–‡ä»¶åŠ è½½äº† {len(self.ad_image_hashes)} ä¸ªå¹¿å‘Šå›¾ç‰‡å“ˆå¸Œ")
                    return
            
            # å¦‚æœæ²¡æœ‰ç´¢å¼•æ–‡ä»¶ï¼Œä»åª’ä½“å…ƒæ•°æ®æ„å»º
            if self.metadata_file.exists():
                logger.info("ğŸ“¦ å¼€å§‹æ„å»ºå¹¿å‘Šå›¾ç‰‡å“ˆå¸Œç´¢å¼•...")
                self.build_hash_index_from_metadata()
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼Œå¹¿å‘Šå›¾ç‰‡æ£€æµ‹åŠŸèƒ½æš‚ä¸å¯ç”¨")
                
        except Exception as e:
            logger.error(f"åŠ è½½å¹¿å‘Šå›¾ç‰‡å“ˆå¸Œå¤±è´¥: {e}")
    
    def build_hash_index_from_metadata(self) -> None:
        """ä»åª’ä½“å…ƒæ•°æ®æ–‡ä»¶æ„å»ºå“ˆå¸Œç´¢å¼•"""
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            media_files = metadata.get('media_files', {})
            ad_count = 0
            
            for file_hash, file_info in media_files.items():
                # è·å–åª’ä½“ç±»å‹
                media_type = file_info.get('media_type', '')
                
                # åªå¤„ç†å›¾ç‰‡æ–‡ä»¶
                if not media_type or not media_type.startswith('image'):
                    # å¦‚æœæ²¡æœ‰media_typeï¼Œé€šè¿‡æ–‡ä»¶æ‰©å±•ååˆ¤æ–­
                    path = file_info.get('path', '')
                    if not path.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
                        continue
                
                # è·å–æˆ–è®¡ç®—è§†è§‰å“ˆå¸Œ
                visual_hashes = file_info.get('visual_hashes')
                if not visual_hashes:
                    # å°è¯•è®¡ç®—è§†è§‰å“ˆå¸Œ
                    file_path = self.training_data_dir / file_info.get('path', '')
                    if file_path.exists():
                        try:
                            with open(file_path, 'rb') as f:
                                image_data = f.read()
                            visual_hashes = self.visual_detector.calculate_perceptual_hashes(image_data)
                            file_info['visual_hashes'] = visual_hashes
                        except Exception as e:
                            logger.debug(f"è®¡ç®—è§†è§‰å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
                            continue
                
                if visual_hashes:
                    self.ad_image_hashes[file_hash] = {
                        'visual_hashes': visual_hashes,
                        'path': file_info.get('path'),
                        'message_id': file_info.get('message_id'),
                        'added_at': file_info.get('added_at'),
                        'channel_id': file_info.get('channel_id')
                    }
                    ad_count += 1
            
            if ad_count > 0:
                self._rebuild_hash_index()
                self.save_hash_index()
                logger.info(f"âœ… æ„å»ºå®Œæˆï¼šå‘ç° {ad_count} ä¸ªå¹¿å‘Šå›¾ç‰‡")
            else:
                logger.warning("âš ï¸ æœªå‘ç°å¹¿å‘Šå›¾ç‰‡è®­ç»ƒæ ·æœ¬")
                
        except Exception as e:
            logger.error(f"æ„å»ºå“ˆå¸Œç´¢å¼•å¤±è´¥: {e}")
    
    def _rebuild_hash_index(self) -> None:
        """é‡å»ºåå‘å“ˆå¸Œç´¢å¼•"""
        self.hash_index = {
            'phash': {},
            'dhash': {},
            'ahash': {}
        }
        
        for file_hash, data in self.ad_image_hashes.items():
            visual_hashes = data.get('visual_hashes', {})
            
            # å»ºç«‹åå‘ç´¢å¼•
            for hash_type in ['phash', 'dhash', 'ahash']:
                if hash_type in visual_hashes:
                    hash_value = visual_hashes[hash_type]
                    if hash_value not in self.hash_index[hash_type]:
                        self.hash_index[hash_type][hash_value] = []
                    self.hash_index[hash_type][hash_value].append(file_hash)
    
    def save_hash_index(self) -> None:
        """ä¿å­˜å“ˆå¸Œç´¢å¼•åˆ°æ–‡ä»¶"""
        try:
            self.training_data_dir.mkdir(parents=True, exist_ok=True)
            
            data = {
                'ad_images': self.ad_image_hashes,
                'updated_at': datetime.now().isoformat()
            }
            
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ å“ˆå¸Œç´¢å¼•å·²ä¿å­˜: {len(self.ad_image_hashes)} ä¸ªå¹¿å‘Šå›¾ç‰‡")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å“ˆå¸Œç´¢å¼•å¤±è´¥: {e}")
    
    async def is_known_ad(self, visual_hashes: Dict) -> Tuple[bool, float, Optional[str]]:
        """
        æ£€æŸ¥å›¾ç‰‡æ˜¯å¦ä¸ºå·²çŸ¥çš„å¹¿å‘Šå›¾ç‰‡
        
        Args:
            visual_hashes: å›¾ç‰‡çš„è§†è§‰å“ˆå¸Œå€¼
            
        Returns:
            (æ˜¯å¦ä¸ºå¹¿å‘Š, ç›¸ä¼¼åº¦, åŒ¹é…çš„å¹¿å‘ŠID)
        """
        if not visual_hashes or not self.ad_image_hashes:
            return False, 0.0, None
        
        try:
            best_match = None
            best_similarity = 0.0
            
            # å¿«é€Ÿæ£€æŸ¥å®Œå…¨åŒ¹é…ï¼ˆSHA256ï¼‰
            if 'sha256' in visual_hashes:
                sha256 = visual_hashes['sha256']
                for file_hash, data in self.ad_image_hashes.items():
                    ad_hashes = data.get('visual_hashes', {})
                    if ad_hashes.get('sha256') == sha256:
                        logger.info(f"ğŸ¯ å®Œå…¨åŒ¹é…å¹¿å‘Šå›¾ç‰‡: {file_hash}")
                        return True, 100.0, file_hash
            
            # ä½¿ç”¨pHashè¿›è¡Œç›¸ä¼¼åº¦åŒ¹é…ï¼ˆæœ€å‡†ç¡®ï¼‰
            if 'phash' in visual_hashes:
                phash = visual_hashes['phash']
                
                # éå†æ‰€æœ‰å¹¿å‘Šå›¾ç‰‡
                for file_hash, data in self.ad_image_hashes.items():
                    ad_hashes = data.get('visual_hashes', {})
                    if 'phash' not in ad_hashes:
                        continue
                    
                    # è®¡ç®—æ±‰æ˜è·ç¦»
                    distance = self.visual_detector.calculate_hash_distance(
                        phash, ad_hashes['phash']
                    )
                    
                    if distance <= self.phash_threshold:
                        similarity = 100 * (1 - distance / 64)  # 64ä½å“ˆå¸Œ
                        if similarity > best_similarity:
                            best_similarity = similarity
                            best_match = file_hash
            
            # å¦‚æœpHashæ²¡æœ‰åŒ¹é…ï¼Œå°è¯•dHash
            if not best_match and 'dhash' in visual_hashes:
                dhash = visual_hashes['dhash']
                
                for file_hash, data in self.ad_image_hashes.items():
                    ad_hashes = data.get('visual_hashes', {})
                    if 'dhash' not in ad_hashes:
                        continue
                    
                    distance = self.visual_detector.calculate_hash_distance(
                        dhash, ad_hashes['dhash']
                    )
                    
                    if distance <= self.dhash_threshold:
                        similarity = 100 * (1 - distance / 64)
                        if similarity > best_similarity:
                            best_similarity = similarity
                            best_match = file_hash
            
            if best_match:
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å¹¿å‘Šå›¾ç‰‡ï¼Œç›¸ä¼¼åº¦: {best_similarity:.1f}%ï¼ŒåŒ¹é…: {best_match}")
                return True, best_similarity, best_match
            
            return False, 0.0, None
            
        except Exception as e:
            logger.error(f"å¹¿å‘Šå›¾ç‰‡æ£€æµ‹å¤±è´¥: {e}")
            return False, 0.0, None
    
    async def add_ad_image(self, image_path: str, metadata: Dict = None) -> bool:
        """
        æ·»åŠ æ–°çš„å¹¿å‘Šå›¾ç‰‡åˆ°ç´¢å¼•
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            metadata: å›¾ç‰‡å…ƒæ•°æ®
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            if not os.path.exists(image_path):
                logger.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return False
            
            # è®¡ç®—è§†è§‰å“ˆå¸Œ
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            visual_hashes = self.visual_detector.calculate_perceptual_hashes(image_data)
            
            # ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œä½œä¸ºID
            import hashlib
            file_hash = hashlib.md5(image_data).hexdigest()
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if file_hash in self.ad_image_hashes:
                logger.info(f"å¹¿å‘Šå›¾ç‰‡å·²å­˜åœ¨: {file_hash}")
                return True
            
            # æ·»åŠ åˆ°ç´¢å¼•
            self.ad_image_hashes[file_hash] = {
                'visual_hashes': visual_hashes,
                'path': os.path.basename(image_path),
                'added_at': datetime.now().isoformat(),
                **(metadata or {})
            }
            
            # æ›´æ–°åå‘ç´¢å¼•
            self._rebuild_hash_index()
            
            # ä¿å­˜ç´¢å¼•
            self.save_hash_index()
            
            logger.info(f"âœ… æ–°å¢å¹¿å‘Šå›¾ç‰‡åˆ°ç´¢å¼•: {file_hash}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ å¹¿å‘Šå›¾ç‰‡å¤±è´¥: {e}")
            return False
    
    async def remove_ad_image(self, file_hash: str) -> bool:
        """
        ä»ç´¢å¼•ä¸­ç§»é™¤å¹¿å‘Šå›¾ç‰‡
        
        Args:
            file_hash: æ–‡ä»¶å“ˆå¸ŒID
            
        Returns:
            æ˜¯å¦ç§»é™¤æˆåŠŸ
        """
        try:
            if file_hash not in self.ad_image_hashes:
                logger.warning(f"å¹¿å‘Šå›¾ç‰‡ä¸å­˜åœ¨: {file_hash}")
                return False
            
            # ä»ç´¢å¼•ä¸­ç§»é™¤
            del self.ad_image_hashes[file_hash]
            
            # æ›´æ–°åå‘ç´¢å¼•
            self._rebuild_hash_index()
            
            # ä¿å­˜ç´¢å¼•
            self.save_hash_index()
            
            logger.info(f"âœ… ä»ç´¢å¼•ç§»é™¤å¹¿å‘Šå›¾ç‰‡: {file_hash}")
            return True
            
        except Exception as e:
            logger.error(f"ç§»é™¤å¹¿å‘Šå›¾ç‰‡å¤±è´¥: {e}")
            return False
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_ad_images': len(self.ad_image_hashes),
            'phash_indexed': len(set().union(*self.hash_index['phash'].values())) if self.hash_index['phash'] else 0,
            'dhash_indexed': len(set().union(*self.hash_index['dhash'].values())) if self.hash_index['dhash'] else 0,
            'ahash_indexed': len(set().union(*self.hash_index['ahash'].values())) if self.hash_index['ahash'] else 0,
            'index_file': str(self.index_file),
            'index_exists': self.index_file.exists()
        }
        return stats

# å…¨å±€å®ä¾‹
ad_image_detector = AdImageDetector()