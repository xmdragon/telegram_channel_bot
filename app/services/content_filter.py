"""
ä¼˜åŒ–çš„å†…å®¹è¿‡æ»¤å™¨
ç²¾å‡†è¯†åˆ«å¹¶åˆ é™¤æ¨å¹¿å†…å®¹ï¼Œä¸ä¾èµ–ä½ç½®åˆ¤æ–­
"""
import re
import logging
import asyncio
import json
from typing import Tuple, List, Set, Any
from app.services.ai_filter import ai_filter
from app.services.config_manager import config_manager
from app.services.message_structure_analyzer import message_structure_analyzer

logger = logging.getLogger(__name__)

class ContentFilter:
    """å†…å®¹è¿‡æ»¤å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¿‡æ»¤å™¨"""
        # AIè¿‡æ»¤å™¨å®ä¾‹
        self.ai_filter = ai_filter
        self._compiled_patterns = {}  # ç¼“å­˜ç¼–è¯‘åçš„æ­£åˆ™è¡¨è¾¾å¼
        self._compiled_protectors = []  # ç¼“å­˜ä¿æŠ¤å™¨æ­£åˆ™
        self._trained_tail_patterns = []  # è®­ç»ƒçš„å°¾éƒ¨è¿‡æ»¤æ¨¡å¼
        
        # åŠ è½½è®­ç»ƒæ•°æ®
        self._load_trained_patterns()
        
        # æ¨å¹¿å†…å®¹ç‰¹å¾æ¨¡å¼
        self.promo_patterns = [
            # === æ˜ç¡®çš„å¹¿å‘Š/èµåŠ©å•†æ ‡è¯†ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ ===
            (r'(é¢‘é“|é »é“).*(å¹¿å‘Š|å»£å‘Š|èµåŠ©|è´ŠåŠ©|æ¨å¹¿|æ¨å»£)', 10),
            (r'(å¹¿å‘Š|å»£å‘Š|èµåŠ©|è´ŠåŠ©|æ¨å¹¿|æ¨å»£).*(é¢‘é“|é »é“)', 10),
            (r'èµåŠ©å•†|è´ŠåŠ©å•†|sponsor|Sponsor|SPONSOR', 10),
            
            # === å•†ä¸šä¿¡æ¯æ ‡è¯†ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ ===
            (r'(è¥ä¸šæ—¶é—´|ç‡Ÿæ¥­æ™‚é–“|è¥ä¸šä¸­|ç‡Ÿæ¥­ä¸­|è¥ä¸šçŠ¶æ€|ç‡Ÿæ¥­ç‹€æ…‹)', 10),
            (r'(åº—é“ºåœ°å€|åº—é‹ªåœ°å€|é—¨åº—åœ°å€|é–€åº—åœ°å€|åœ°å€ï¼š)', 10),
            (r'(ç»è¥é¡¹ç›®|ç¶“ç‡Ÿé …ç›®|ä¸»è¥|ä¸»ç‡Ÿ|ä¸šåŠ¡èŒƒå›´|æ¥­å‹™ç¯„åœ)', 10),
            (r'(ä¼˜æƒ |å„ªæƒ |æŠ˜æ‰£|æ‰“æŠ˜|ç‰¹ä»·|ç‰¹åƒ¹|ä¿ƒé”€|ä¿ƒéŠ·)', 9),
            (r'(æ¥å•|æ¥å–®|ä¸‹å•|ä¸‹å–®|è®¢è´­|è¨‚è³¼|å’¨è¯¢|è«®è©¢)', 9),
            (r'(å¾®ä¿¡[:ï¼š]|WeChat[:ï¼š])', 9),
            (r'(ç”µè¯[:ï¼š]|é›»è©±[:ï¼š]|æ‰‹æœº[:ï¼š]|æ‰‹æ©Ÿ[:ï¼š]|è”ç³»[:ï¼š]|è¯ç¹«[:ï¼š])', 9),
            
            # === åšå½©/èµŒåšç›¸å…³ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ ===
            (r'(åšå½©|ä½“è‚²|è¶³çƒ|ç¯®çƒ|å½©ç¥¨|æ£‹ç‰Œ|å¨±ä¹åŸ|èµŒåœº|casino|Casino)', 10),
            (r'(Uå­˜Uæ|USDT|æ³°è¾¾å¸|è™šæ‹Ÿå¸|ææ¬¾|å‡ºæ¬¾|å……å€¼|ä¸‹æ³¨|æŠ•æ³¨)', 10),
            (r'(çº¿ä¸Š|ç·šä¸Š).*(åšå½©|å¹³å°|å¨±ä¹|å¨›æ¨‚)', 10),
            (r'(æ— éœ€å®å|ç„¡éœ€å¯¦å|ä¸é™.*ip|ä¸é™.*IP|ç»‘å®š.*é“¶è¡Œ|ç¶å®š.*éŠ€è¡Œ)', 10),
            (r'(å¤§é¢|å¤§é¡).*(å‡ºæ¬¾|ææ¬¾)', 10),
            
            # === éTelegramçš„HTTPé“¾æ¥ï¼ˆèµŒåšç½‘ç«™ç­‰ï¼‰ ===
            (r'\bhttps?://(?!(?:t\.me|telegram\.me|telegra\.ph))[a-zA-Z0-9\-._~:/?#\[\]@!$&\'()*+,;=]+', 10),
            
            # === å¸¦æ‹¬å·çš„é“¾æ¥ï¼ˆå¸¸è§æ¨å¹¿æ ¼å¼ï¼‰ ===
            (r'\([^\)]*https?://[^\)]+\)', 10),  # (é“¾æ¥)
            
            # === è¡¨æƒ…ç¬¦å·å¯†é›†+æ–‡å­—+é“¾æ¥çš„ç»„åˆ ===
            (r'^[ğŸ˜ŠğŸ˜€â˜•ï¸ğŸ§©ğŸ°ğŸ®ğŸ³ğŸ¯â™Ÿâš¡ï¸ğŸ˜˜ğŸğŸ˜â¤ğŸ’°ğŸ”¥]{2,}.*https?://', 8),  # å¤šä¸ªè¡¨æƒ…å¼€å¤´+é“¾æ¥ - é™ä½æƒé‡
            (r'^[ğŸ˜ŠğŸ˜€â˜•ï¸ğŸ§©ğŸ°ğŸ®ğŸ³ğŸ¯â™Ÿâš¡ï¸ğŸ˜˜ğŸğŸ˜â¤ğŸ’°ğŸ”¥]{3,}[^\n]{0,50}$', 5),  # çº¯è¡¨æƒ…æ¨å¹¿è¡Œ - é™ä½æƒé‡
            
            # === Telegramç”¨æˆ·åå’Œé¢‘é“ï¼ˆæ›´æ™ºèƒ½çš„åˆ¤æ–­ï¼‰ ===
            # t.meé“¾æ¥éœ€è¦åœ¨æ¨å¹¿ä¸Šä¸‹æ–‡ä¸­æ‰ç®—æ¨å¹¿
            (r'^[ğŸ“¢ğŸ“£ğŸ””ğŸ’¬â¤ï¸ğŸ”—ğŸ”âœ‰ï¸ğŸ“®ğŸ˜ğŸ‘Œ].{0,10}t\.me/[a-zA-Z][a-zA-Z0-9_]{4,31}', 9),  # è¡¨æƒ…+t.meé“¾æ¥
            (r'(?:è®¢é˜…|å…³æ³¨|åŠ å…¥|å¤±è”|å¤‡ç”¨).{0,10}t\.me/', 9),  # æ¨å¹¿è¯+t.meé“¾æ¥
            
            # å•ç‹¬çš„@ç”¨æˆ·åä¸è¿‡æ»¤ï¼Œé™¤éåœ¨æ˜æ˜¾çš„æ¨å¹¿ä¸Šä¸‹æ–‡ä¸­
            # æš‚æ—¶ä¸è¿‡æ»¤å•ç‹¬çš„@ç”¨æˆ·åï¼Œé¿å…è¯¯åˆ¤
            
            # === æ¨å¹¿å…³é”®è¯ç»„åˆï¼ˆå¿…é¡»å¸¦é“¾æ¥æˆ–@ï¼‰ ===
            # è®¢é˜…ã€æŠ•ç¨¿ã€å•†åŠ¡ç­‰æ¨å¹¿è¯+@ç”¨æˆ·åï¼ˆéœ€è¦æ›´ç²¾ç¡®çš„åŒ¹é…ï¼‰
            (r'^[ğŸ“¢ğŸ“£ğŸ””ğŸ’¬â¤ï¸ğŸ”—â˜ï¸ğŸ˜âœ‰ï¸ğŸ“®ğŸ“¬ğŸ“­ğŸ“§ğŸ‡²ğŸ‡²ğŸ”¥âœ…ğŸ‘Œ].{0,10}(?:è®¢é˜…|è¨‚é–±|æŠ•ç¨¿|çˆ†æ–™|å•†åŠ¡|å•†å‹™|è”ç³»|è¯ç³»|å¤±è”|å¯¼èˆª|å°æ¥|å¯¹æ¥|å›­åŒº|å¹æ°´|äº¤å‹)[^\n]{0,20}@[a-zA-Z]', 10),  # è¡¨æƒ…+æ¨å¹¿è¯+@
            (r'^[ğŸ“¢ğŸ“£ğŸ””ğŸ’¬â¤ï¸ğŸ”—â˜ï¸ğŸ˜âœ‰ï¸ğŸ“®ğŸ“¬ğŸ“­ğŸ“§].{0,5}(?:å…³æ³¨|é—œæ³¨)[^\n]{0,30}(?:ä¸­å¿ƒ|å¹³å°|é¢‘é“|é »é“)', 10),  # è¡¨æƒ…+å…³æ³¨+ä¸­å¿ƒ/å¹³å°ç­‰
            (r'(?:æ¬¢è¿|æ­¡è¿)(?:æŠ•ç¨¿|çˆ†æ–™|åŠ å…¥|å…³æ³¨)[^\n]{0,5}@', 9),  # æ¬¢è¿æŠ•ç¨¿+@
            (r'(?:å¤±è”|å¤±è¯)(?:å¯¼èˆª|å°èˆª)[^\n]{0,5}@', 10),  # å¤±è”å¯¼èˆª
            (r'^.{0,5}(?:å…³æ³¨|é—œæ³¨)[^\n]{0,30}(?:æ‚¬èµ|æ‡¸è³|åƒç“œ|æ›å…‰|çˆ†æ–™)', 10),  # å…³æ³¨+æ‚¬èµ/åƒç“œç­‰
            (r'(?:å•†åŠ¡|å•†å‹™)(?:å¯¹æ¥|å°æ¥|åˆä½œ)[^\n]{0,5}@', 10),  # å•†åŠ¡å¯¹æ¥
            
            # === ç‰¹æ®Šæ ¼å¼ï¼šğŸ‘Œå¼€å¤´çš„æ¨å¹¿å†…å®¹ï¼ˆä¾‹ï¼šğŸ‘Œè®¢é˜…é¢‘é“ï¼š@xxxï¼‰===
            (r'^ğŸ‘Œ(?:è®¢é˜…|æŠ•ç¨¿|çˆ†æ–™|æµ·å¤–äº¤å‹|å•†åŠ¡|è”ç³»)', 10),  # ğŸ‘Œ+æ¨å¹¿è¯
            (r'^ğŸ‘Œ.{0,10}[:ï¼šï¼›].{0,5}@', 10),  # ğŸ‘Œxxxï¼š@ç”¨æˆ·å
            
            # === é¢‘é“æ¨å¹¿å›ºå®šæ ¼å¼ ===
            # æ›´ç²¾ç¡®çš„åŒ¹é…ï¼šéœ€è¦å¤šä¸ªæ¨å¹¿ç‰¹å¾ç»„åˆ
            (r'^[ğŸ“¢ğŸ“£ğŸ””ğŸ’¬â¤ï¸ğŸ”—ğŸ”âœ‰ï¸ğŸ“®ğŸ˜ğŸ‡²ğŸ‡²ğŸ”¥âœ…ğŸ‘Œ].{0,5}(?:è®¢é˜…|æŠ•ç¨¿|å•†åŠ¡|è”ç³»|å¤±è”|å¯¼èˆª|å¹æ°´ç«™|å›­åŒº|äº¤å‹).{0,5}(?:é¢‘é“|channel|@)', 10),  # è¡¨æƒ…+æ¨å¹¿è¯+é¢‘é“/@
            (r'^[ğŸ“¢ğŸ“£ğŸ””ğŸ’¬â¤ï¸ğŸ”—ğŸ”âœ‰ï¸ğŸ“®ğŸ˜ğŸ‡²ğŸ‡²ğŸ”¥âœ…ğŸ‘Œ].{0,5}(?:è®¢é˜…|æŠ•ç¨¿|å•†åŠ¡|è”ç³»|å¤±è”|å¯¼èˆª|äº¤å‹)[^\n]{0,10}[@]', 10),  # è¡¨æƒ…+æ¨å¹¿è¯+@ç¬¦å·
            
            # === "æœ¬é¢‘é“æ¨è"ç­‰æ˜æ˜¾æ¨å¹¿å¼€å¤´ ===
            (r'æœ¬é¢‘é“(?:æ¨è|æ¨è–¦)', 10),  # "æœ¬é¢‘é“æ¨è"ï¼ˆä¸é™ä½ç½®ï¼‰
            (r'(?:é¢‘é“|é »é“)(?:æ¨è|æ¨è–¦|åˆä½œ)', 10),  # "é¢‘é“æ¨è"ç­‰
            (r'^[ğŸ˜ŠğŸ˜€ğŸ˜‰ğŸ™‚ğŸ˜„ğŸ˜ƒğŸ’¯ğŸ”¥â¤ï¸ğŸ’°*]+æœ¬é¢‘é“', 10),  # è¡¨æƒ…+æœ¬é¢‘é“
            
            # === çº¯è¡¨æƒ…åˆ†éš”çº¿ ===
            (r'^[ğŸ˜ŠğŸ˜€ğŸ˜‰ğŸ™‚ğŸ˜„ğŸ˜ƒğŸ’¯ğŸ”¥â¤ï¸ğŸ’°]{5,}$', 2),  # 5ä¸ªä»¥ä¸Šè¡¨æƒ… - é™ä½æƒé‡
            (r'^[-=_â€”â–â–ªâ–«â—†â—‡â– â–¡â—â—‹â€¢ï½~]{10,}$', 1),  # ç¬¦å·åˆ†éš”çº¿ - æœ€ä½æƒé‡
            
            # === Markdowné“¾æ¥æ ¼å¼ ===
            # æ³¨æ„ï¼šæ–°é—»/æ›å…‰ç±»é“¾æ¥ä¼šè¢«content_protectorsä¿æŠ¤ï¼Œä¸ä¼šè¢«è¿‡æ»¤
            (r'\[[^\]]+\]\(https?://t\.me/[^\)]+\)', 9),  # [æ–‡å­—](t.meé“¾æ¥) - æé«˜åˆ†æ•°ï¼Œé¢‘é“é“¾æ¥
            (r'\[[^\]]+\]\(https?://telegram\.me/[^\)]+\)', 9),  # [æ–‡å­—](telegram.meé“¾æ¥)
            (r'\[[^\]]+\]\(https?://[^\)]+\)', 7),  # [æ–‡å­—](å…¶ä»–é“¾æ¥) - ä¿æŒè¾ƒä½åˆ†æ•°
            (r'\[[è®¢é˜…è¨‚é–±åŠ å…¥å…³æ³¨é—œæ³¨&][^\]]*\]\([^\)]*t\.me[^\)]+\)', 10),  # [è®¢é˜…xxx](t.me/xxx) - æ˜ç¡®çš„æ¨å¹¿
            (r'[ğŸ”ğŸ””ğŸ”—ğŸ“¢]\[[^\]]*\]\(.*t\.me.*\)', 9),  # æ¨å¹¿è¡¨æƒ…[æ–‡å­—](t.meé“¾æ¥)
            # æ–°é—»ç±»é“¾æ¥ç‰¹å¾ï¼ˆä¸ç®—æ¨å¹¿ï¼‰- ä½†è‡ªå¼•ç”¨é™¤å¤–
            (r'\[[ğŸ¥ğŸ“°ğŸ“¸ğŸ¬]\s*(?:æ›å…‰|çˆ†æ–™|æ–°é—»|å¤´æ¡|çƒ­ç‚¹|è§†é¢‘|å›¾ç‰‡)[^\]]*\]\(', -5),  # æ–°é—»é“¾æ¥ï¼Œè´Ÿåˆ†ä¿æŠ¤
            
            # === èµŒåš/å¨±ä¹æ¨å¹¿å…³é”®è¯ï¼ˆå¸¦æ•°å­—æˆ–é“¾æ¥æ›´å¯ä¿¡ï¼‰ ===
            (r'(?:é¦–å……|è¿”æ°´|ä¼˜æƒ |æ³¨å†Œå°±é€|æ—¥å‡ºåƒä¸‡)[^\n]*(?:\d+%|\d+U|https?://)', 10),
            (r'(?:ä½“è‚²|å¨±ä¹|èµŒåœº|åšå½©)[^\n]*(?:ç»¼åˆ|å¹³å°|å®˜ç½‘)[^\n]*(?:@|https?://)', 10),
            (r'(?:å®åŠ›Uç›˜|æ”¾å¿ƒèµ¢|å¤§é¢æ— å¿§|å·¨æ¬¾æ— å¿§)[^\n]*(?:\(|https?://)', 10),
            (r'(?:å…¨ç½‘|ç‹¬å®¶|é¦–å‘)[^\n]*(?:æœ€é«˜|è¿”æ°´|ä¼˜æƒ )[^\n]*\d+', 9),
            (r'USDT[^\n]*(?:åƒä¸‡|å·¨æ¬¾|æ— å¿§)', 9),
        ]
        
        # æ­£æ–‡å†…å®¹ä¿æŠ¤æ¨¡å¼ï¼ˆè¿™äº›å†…å®¹ä¸åº”è¢«åˆ é™¤ï¼‰
        self.content_protectors = [
            # ä¸ªäººæƒ…æ„Ÿè¡¨è¾¾
            r'å¦ˆçš„|è‰|æ¶å¿ƒ|éš¾å—|ä»–å¦ˆ|å‘|å¦ˆé€¼|ç‹—æ—¥|æˆ‘æ“|å§æ§½',
            r'æ°”æ­»|éƒé—·|çƒ¦æ­»|å¿ƒç–¼|å¯æ€œ',
            
            # ä¸ªäººå™è¿°
            r'æˆ‘æƒ³|æˆ‘è§‰å¾—|æˆ‘è®¤ä¸º|æˆ‘ä»¥ä¸º|æˆ‘å°±',
            r'è¿™æ¬¡|ä¸Šæ¬¡|ä¸‹æ¬¡|ç»“æœ',
            
            # ä¿—è¯­æˆè¯­
            r'å¸¸åœ¨æ²³è¾¹èµ°|å“ªæœ‰ä¸æ¹¿é‹',
            
            # æ–°é—»å†…å®¹
            r'æ®æŠ¥é“|æ¶ˆæ¯ç§°|è®°è€…è¡¨ç¤º|è®°è€…è·æ‚‰',
            r'è­¦æ–¹ç§°|æ”¿åºœè¡¨ç¤º|å®˜æ–¹å›åº”|è°ƒæŸ¥æ˜¾ç¤º',
            r'å‘ç”Ÿäº†|å‘ç”Ÿåœ¨|çªå‘äº‹ä»¶',  # æ›´ç²¾ç¡®çš„äº‹ä»¶åŒ¹é…
            
            # æ›å…‰/çˆ†æ–™ç±»å†…å®¹ï¼ˆé‡è¦ä¿æŠ¤ï¼‰
            r'æ›å…‰|çˆ†æ–™|æ­éœ²|ä¸¾æŠ¥|æŠ•è¯‰|æ£€ä¸¾',
            r'éª—å­|éª—åƒéª—å–|è¯ˆéª—|é»‘åº—|é»‘å¿ƒ|æ— è‰¯|åƒåœ¾',
            r'æ­¤äºº|è¿™äºº|è¯¥äºº|è¿™ä¸ªäºº|è¿™å®¶ä¼™',
            r'#ç½‘å‹æ›å…‰|#æ›å…‰|#çˆ†æ–™|#ä¸¾æŠ¥|#æŠ•è¯‰',
            r'ğŸ¥æ›å…‰|ğŸ“°çˆ†æ–™|ğŸ“¸æ›å…‰|ğŸ¬è§†é¢‘'
            
            # å¯»äººå¯äº‹ï¼ˆç‰¹æ®Šä¿æŠ¤ï¼‰
            r'å¤±è¸ª|å¯»æ‰¾|å¯»äºº|è”ç³»å®¶äºº|æŠ¥è­¦',
            r'èº«é«˜\d+|ä½“é‡\d+|å¹´é¾„\d+|å¤±è”',
            
            # ç”¨æˆ·æŠ•ç¨¿æ ‡è®°ï¼ˆé‡è¦ä¿æŠ¤ï¼‰
            r'^#ç½‘å‹æŠ•ç¨¿|^#ç¾¤å‹æŠ•ç¨¿|^#è¯»è€…æŠ•ç¨¿|^#ç²‰ä¸æŠ•ç¨¿',
            r'^#ç”¨æˆ·åˆ†äº«|^#çœŸå®ç»å†|^#äº²èº«ç»å†',
        ]
        
        # åˆå§‹åŒ–å¹¶ç¼–è¯‘æ‰€æœ‰æ­£åˆ™è¡¨è¾¾å¼
        self._compile_patterns()
    
    def _load_trained_patterns(self):
        """åŠ è½½è®­ç»ƒçš„å°¾éƒ¨è¿‡æ»¤æ¨¡å¼"""
        try:
            from app.core.training_config import TrainingDataConfig
            import json
            from pathlib import Path
            
            tail_file = TrainingDataConfig.TAIL_FILTER_SAMPLES_FILE
            if tail_file.exists():
                with open(tail_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ä»æ ·æœ¬ä¸­æå–å°¾éƒ¨æ¨¡å¼
                for sample in data.get('samples', []):
                    tail_part = sample.get('tail_part', '')
                    if tail_part and tail_part.strip():
                        # å°†å°¾éƒ¨å†…å®¹è½¬æ¢ä¸ºç²¾ç¡®åŒ¹é…æ¨¡å¼
                        # ç§»é™¤å¯èƒ½çš„æ¢è¡Œç¬¦å·®å¼‚å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                        pattern_text = re.escape(tail_part.strip())
                        # å…è®¸å‰åæœ‰å¯é€‰çš„ç©ºç™½å­—ç¬¦
                        pattern = f"\\s*{pattern_text}\\s*$"
                        self._trained_tail_patterns.append({
                            'pattern': pattern,
                            'original_text': tail_part,
                            'description': sample.get('description', ''),
                            'source': sample.get('source', '')
                        })
                
                logger.info(f"åŠ è½½äº† {len(self._trained_tail_patterns)} ä¸ªè®­ç»ƒçš„å°¾éƒ¨è¿‡æ»¤æ¨¡å¼")
            else:
                logger.warning(f"å°¾éƒ¨è¿‡æ»¤è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {tail_file}")
                
        except Exception as e:
            logger.error(f"åŠ è½½è®­ç»ƒçš„å°¾éƒ¨è¿‡æ»¤æ¨¡å¼å¤±è´¥: {e}")
    
    def reload_trained_patterns(self):
        """é‡æ–°åŠ è½½è®­ç»ƒæ¨¡å¼ï¼ˆå½“æ–°å¢è®­ç»ƒæ•°æ®æ—¶è°ƒç”¨ï¼‰"""
        self._trained_tail_patterns = []
        self._load_trained_patterns()
        
        # åŒæ—¶é‡æ–°åŠ è½½intelligent_tail_filterçš„è®­ç»ƒæ•°æ®
        try:
            from app.services.intelligent_tail_filter import intelligent_tail_filter
            intelligent_tail_filter._load_training_data(force_reload=True)
            logger.info("å·²é‡æ–°åŠ è½½intelligent_tail_filterè®­ç»ƒæ•°æ®")
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½intelligent_tail_filterå¤±è´¥: {e}")
    
    def _compile_patterns(self):
        """ç¼–è¯‘æ‰€æœ‰æ­£åˆ™è¡¨è¾¾å¼ä»¥æé«˜æ€§èƒ½"""
        # ç¼–è¯‘æ¨å¹¿æ¨¡å¼
        for pattern, score in self.promo_patterns:
            try:
                self._compiled_patterns[pattern] = (re.compile(pattern, re.MULTILINE | re.IGNORECASE), score)
            except Exception as e:
                logger.error(f"ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼å¤±è´¥: {pattern[:50]}... - {e}")
        
        # ç¼–è¯‘ä¿æŠ¤å™¨æ¨¡å¼
        for pattern in self.content_protectors:
            try:
                self._compiled_protectors.append(re.compile(pattern, re.MULTILINE | re.IGNORECASE))
            except Exception as e:
                logger.error(f"ç¼–è¯‘ä¿æŠ¤å™¨æ­£åˆ™å¤±è´¥: {pattern[:50]}... - {e}")
    
    def is_promo_line(self, line: str) -> Tuple[bool, int]:
        """
        åˆ¤æ–­å•è¡Œæ˜¯å¦ä¸ºæ¨å¹¿å†…å®¹
        
        Returns:
            (æ˜¯å¦æ¨å¹¿, ç½®ä¿¡åº¦åˆ†æ•°)
        """
        if not line.strip():
            return False, 0
            
        line_lower = line.lower()
        max_score = 0
        
        # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·æŠ•ç¨¿ç­‰å—ä¿æŠ¤å†…å®¹
        # å¦‚æœä»¥#ç½‘å‹æŠ•ç¨¿ç­‰å¼€å¤´ï¼Œç›´æ¥è¿”å›éæ¨å¹¿
        if re.match(r'^#(ç½‘å‹|ç¾¤å‹|è¯»è€…|ç²‰ä¸|ç”¨æˆ·)æŠ•ç¨¿', line, re.IGNORECASE):
            return False, 0
        if re.match(r'^#(çœŸå®ç»å†|äº²èº«ç»å†|ç”¨æˆ·åˆ†äº«)', line, re.IGNORECASE):
            return False, 0
            
        # ä½¿ç”¨ç¼–è¯‘åçš„æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥æ¨å¹¿ç‰¹å¾
        for pattern_str, (compiled_pattern, score) in self._compiled_patterns.items():
            if compiled_pattern.search(line):
                max_score = max(max_score, score)
        
        # ä½¿ç”¨ç¼–è¯‘åçš„ä¿æŠ¤å™¨æ£€æŸ¥ä¿æŠ¤å†…å®¹
        has_protected_content = False
        for protector_pattern in self._compiled_protectors:
            if protector_pattern.search(line):
                has_protected_content = True
                # å¦‚æœåŒ…å«ä¿æŠ¤å†…å®¹ï¼Œå¤§å¹…é™ä½æ¨å¹¿åˆ†æ•°
                if max_score >= 9:
                    # é«˜åˆ†æ¨å¹¿å†…å®¹å¦‚æœåŒ…å«ä¿æŠ¤è¯ï¼Œå¯èƒ½æ˜¯è¯¯åˆ¤
                    max_score = max(0, max_score - 6)  # é™6åˆ†
                else:
                    max_score = max(0, max_score - 5)  # é™5åˆ†
                break
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŒ…å«æ›å…‰/çˆ†æ–™ç­‰å¼ºä¿æŠ¤è¯ï¼Œå³ä½¿æœ‰é“¾æ¥ä¹Ÿä¸ç®—æ¨å¹¿
        strong_protection_words = r'(æ›å…‰|çˆ†æ–™|æ­éœ²|ä¸¾æŠ¥|éª—å­|é»‘åº—|è¯ˆéª—)'
        if re.search(strong_protection_words, line, re.IGNORECASE):
            # é™¤éæ˜¯æ˜ç¡®çš„æ¨å¹¿é“¾æ¥ï¼ˆå¦‚"è®¢é˜…é¢‘é“"ï¼‰
            if not re.search(r'(è®¢é˜…|å…³æ³¨|åŠ å…¥).*(é¢‘é“|channel|@|t\.me)', line, re.IGNORECASE):
                return False, 0  # å¼ºä¿æŠ¤ï¼Œä¸ç®—æ¨å¹¿
                
        return max_score >= 8, max_score  # æé«˜é˜ˆå€¼ä»7åˆ°8ï¼Œå‡å°‘è¯¯åˆ¤
    
    def is_meaningless_content(self, content: str) -> bool:
        """
        æ£€æµ‹å†…å®¹æ˜¯å¦æ— æ„ä¹‰ï¼ˆçº¯ç¬¦å·ã€è£…é¥°ç¬¦ç­‰ï¼‰
        
        Args:
            content: è¦æ£€æµ‹çš„å†…å®¹
            
        Returns:
            æ˜¯å¦ä¸ºæ— æ„ä¹‰å†…å®¹
        """
        if not content or not content.strip():
            return True
            
        # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦
        clean_content = ''.join(content.split())
        
        # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æ— æ„ä¹‰
        if len(clean_content) < 5:
            # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯ç¬¦å·æˆ–è¡¨æƒ…
            import unicodedata
            meaningful_chars = 0
            for char in clean_content:
                cat = unicodedata.category(char)
                # å­—æ¯(L)ã€æ•°å­—(N)ã€ä¸­æ–‡ç­‰è¢«è®¤ä¸ºæœ‰æ„ä¹‰
                if cat[0] in ('L', 'N'):
                    meaningful_chars += 1
            
            # å¦‚æœæœ‰æ„ä¹‰å­—ç¬¦å°‘äº20%ï¼Œè®¤ä¸ºæ˜¯æ— æ„ä¹‰å†…å®¹
            if meaningful_chars < len(clean_content) * 0.2:
                return True
        
        # æ£€æµ‹å¸¸è§çš„æ— æ„ä¹‰æ¨¡å¼
        meaningless_patterns = [
            r'^[^\w\u4e00-\u9fa5]+$',  # å…¨æ˜¯éå­—æ¯æ•°å­—å’Œéä¸­æ–‡
            r'^[\s\-\=\*\~\.\,\!\?\@\#\$\%\^\&\(\)\[\]\{\}\<\>\|\/\\\_\+]+$',  # å…¨æ˜¯ç¬¦å·
            r'^[\u2500-\u257F\u2580-\u259F\u25A0-\u25FF]+$',  # åˆ¶è¡¨ç¬¦å’Œæ–¹å—
            r'^[\u2600-\u26FF\u2700-\u27BF]+$',  # å„ç§ç¬¦å·å’Œè£…é¥°
            r'^(?:[\u0020-\u002F\u003A-\u0040\u005B-\u0060\u007B-\u007E])+$',  # ASCIIç¬¦å·
        ]
        
        for pattern in meaningless_patterns:
            if re.match(pattern, clean_content):
                logger.debug(f"æ£€æµ‹åˆ°æ— æ„ä¹‰å†…å®¹ï¼ˆåŒ¹é…æ¨¡å¼ {pattern[:30]}...ï¼‰")
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤å­—ç¬¦
        if len(set(clean_content)) <= 2 and len(clean_content) > 5:
            # åªæœ‰1-2ç§å­—ç¬¦ä¸”é•¿åº¦è¶…è¿‡5ï¼Œå¯èƒ½æ˜¯è£…é¥°çº¿
            return True
        
        # è®¡ç®—æœ‰æ„ä¹‰è¯æ±‡çš„æ¯”ä¾‹
        import jieba
        words = list(jieba.cut(content))
        meaningful_words = [w for w in words if len(w.strip()) > 0 and not re.match(r'^[^\w\u4e00-\u9fa5]+$', w)]
        
        # å¦‚æœæœ‰æ„ä¹‰è¯æ±‡å¤ªå°‘ï¼Œå¯èƒ½æ˜¯æ— æ„ä¹‰å†…å®¹
        if len(meaningful_words) < 2 and len(content) > 10:
            return True
            
        return False
    
    def remove_all_markdown_links(self, content: str, channel_id: str = None) -> str:
        """
        ç§»é™¤æ‰€æœ‰Markdownæ ¼å¼çš„é“¾æ¥ï¼Œæ™ºèƒ½å¤„ç†æ ‡ç­¾
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            channel_id: é¢‘é“IDï¼ˆç”¨äºåˆ¤æ–­æ ‡ç­¾æ˜¯å¦ä¸é¢‘é“ç›¸å…³ï¼‰
            
        Returns:
            è¿‡æ»¤åçš„å†…å®¹
        """
        if not content:
            return content
        
        import re
        
        # è·å–é¢‘é“åç§°ï¼ˆç”¨äºåˆ¤æ–­æ ‡ç­¾ç›¸å…³æ€§ï¼‰
        channel_name = None
        if channel_id:
            # æå–é¢‘é“å…³é”®è¯
            if isinstance(channel_id, str):
                if channel_id.startswith('@'):
                    channel_name = channel_id[1:].lower()
                elif channel_id.startswith('-100'):
                    # ä½¿ç”¨å·²çŸ¥æ˜ å°„
                    known_channels = {
                        '-1001153220419': 'dny185',
                        '-1001875033283': 'dubai0',
                    }
                    channel_name = known_channels.get(channel_id, '').lower()
                else:
                    channel_name = channel_id.lower()
        
        # Markdowné“¾æ¥æ­£åˆ™
        markdown_pattern = r'\[([^\]]*)\]\(([^\)]+)\)'
        
        lines = content.split('\n')
        filtered_lines = []
        
        for line in lines:
            if not re.search(markdown_pattern, line):
                # æ²¡æœ‰Markdowné“¾æ¥ï¼Œç›´æ¥ä¿ç•™
                filtered_lines.append(line)
                continue
            
            original_line = line
            
            # å¤„ç†æ¯ä¸ªMarkdowné“¾æ¥
            def replace_link(match):
                link_text = match.group(1)  # [æ–‡å­—]éƒ¨åˆ†
                link_url = match.group(2)   # (é“¾æ¥)éƒ¨åˆ†
                
                # åˆ¤æ–­æ˜¯å¦åº”è¯¥å®Œå…¨ç§»é™¤
                should_remove_completely = False
                
                # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«é¢‘é“ç›¸å…³æ ‡ç­¾
                if channel_name and link_text:
                    # æ£€æŸ¥é“¾æ¥æ–‡å­—ä¸­æ˜¯å¦åŒ…å«é¢‘é“å
                    if channel_name in link_text.lower():
                        should_remove_completely = True
                        logger.debug(f"æ£€æµ‹åˆ°é¢‘é“ç›¸å…³æ ‡ç­¾: {link_text}")
                
                # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨å¹¿å…³é”®è¯
                promo_keywords = ['è®¢é˜…', 'è®¢é–±', 'å…³æ³¨', 'é—œæ³¨', 'åŠ å…¥', 
                                 'æŠ•ç¨¿', 'å•†åŠ¡', 'å•†å‹™', 'è”ç³»', 'è¯ç¹«',
                                 'é¢‘é“', 'é »é“', 'channel', 'group', 'å¤±è”', 
                                 'å¯¼èˆª', 'å‚™ç”¨', 'å®˜æ–¹']
                if link_text:
                    for keyword in promo_keywords:
                        if keyword in link_text.lower():
                            should_remove_completely = True
                            logger.debug(f"æ£€æµ‹åˆ°æ¨å¹¿å…³é”®è¯ '{keyword}': {link_text}")
                            break
                
                # 3. æ£€æŸ¥æ˜¯å¦æ˜¯çº¯emojiæˆ–ç¬¦å·
                if link_text and re.match(r'^[^\w\u4e00-\u9fa5]+$', link_text):
                    should_remove_completely = True
                    logger.debug(f"æ£€æµ‹åˆ°çº¯ç¬¦å·é“¾æ¥: {link_text}")
                
                # 4. æ£€æŸ¥é“¾æ¥æ˜¯å¦æŒ‡å‘t.meï¼ˆé«˜æ¦‚ç‡æ¨å¹¿ï¼‰
                if 't.me' in link_url.lower() or 'telegram' in link_url.lower():
                    # Telegramé“¾æ¥å‡ ä¹éƒ½æ˜¯æ¨å¹¿ï¼Œç›´æ¥ç§»é™¤
                    should_remove_completely = True
                    logger.debug(f"æ£€æµ‹åˆ°Telegramé“¾æ¥: {link_url[:30]}")
                
                # è¿”å›å¤„ç†ç»“æœ
                if should_remove_completely:
                    return ''  # å®Œå…¨ç§»é™¤
                else:
                    # å¯¹äºéTelegramé“¾æ¥ï¼Œå¯ä»¥ä¿ç•™æ–‡å­—éƒ¨åˆ†
                    return link_text.strip() if link_text else ''
            
            # æ›¿æ¢æ‰€æœ‰Markdowné“¾æ¥
            processed_line = re.sub(markdown_pattern, replace_link, line)
            
            # æ¸…ç†å¤šä½™ç©ºæ ¼ã€æ ‡ç‚¹å’Œåˆ†éš”ç¬¦
            processed_line = re.sub(r'\s+', ' ', processed_line).strip()
            processed_line = re.sub(r'^[:ï¼š]\s*', '', processed_line)  # ç§»é™¤è¡Œé¦–çš„å†’å·
            processed_line = re.sub(r'^\|\s*|\s*\|$', '', processed_line)  # ç§»é™¤è¡Œé¦–è¡Œå°¾çš„ |
            processed_line = re.sub(r'\|\s*\|', '|', processed_line)  # åˆå¹¶å¤šä¸ª |
            
            # å¦‚æœè¡Œé¦–æ˜¯emoji+æ–‡å­—+å†’å·ä½†åé¢æ²¡æœ‰å®è´¨å†…å®¹ï¼Œåˆ é™¤æ•´è¡Œ
            # ä¾‹å¦‚: "ğŸ¥æŸ¬åŸ”å¯¨äº‹ä»¶ï¼š" (é“¾æ¥è¢«ç§»é™¤å)
            if re.match(r'^[^a-zA-Z]*[^:ï¼š]*[:ï¼š]\s*$', processed_line) and len(processed_line) < 30:
                logger.info(f"åˆ é™¤åªå«æ ‡é¢˜çš„è¡Œ: '{original_line[:50]}...'")
                continue
            
            # å¦‚æœæ˜¯å¼•å¯¼æ€§æ–‡å­—+å†’å·ä½†åé¢æ²¡æœ‰å†…å®¹ï¼Œåˆ é™¤æ•´è¡Œ
            # ä¾‹å¦‚: "æŸ¥çœ‹è¯¦æƒ…ï¼š" "è®¢é˜…é¢‘é“ï¼š" (é“¾æ¥è¢«ç§»é™¤å)
            guide_words = ['æŸ¥çœ‹è¯¦æƒ…', 'è®¢é˜…é¢‘é“', 'è®¢é˜…æˆ‘ä»¬', 'å…³æ³¨æˆ‘ä»¬', 'æ›´å¤šä¿¡æ¯', 
                          'æŸ¥çœ‹æ›´å¤š', 'ç‚¹å‡»æŸ¥çœ‹', 'äº†è§£æ›´å¤š', 'å•†åŠ¡åˆä½œ', 'æŠ•ç¨¿çˆ†æ–™']
            for word in guide_words:
                if processed_line.startswith(word) and re.match(f'^{re.escape(word)}[:ï¼š]?\\s*$', processed_line):
                    logger.info(f"åˆ é™¤åªå«å¼•å¯¼è¯çš„è¡Œ: '{original_line[:50]}...'")
                    processed_line = ''
                    break
            
            if not processed_line:
                continue
            
            # å¦‚æœåªå‰©ä¸‹åˆ†éš”ç¬¦æˆ–å¾ˆå°‘çš„å†…å®¹ï¼Œè·³è¿‡è¯¥è¡Œ
            if processed_line in ['|', '||', ''] or len(processed_line.strip('| ')) < 3:
                logger.info(f"åˆ é™¤åªå«åˆ†éš”ç¬¦çš„è¡Œ: '{original_line[:50]}...'")
                continue
            
            # è®°å½•å¤„ç†æ•ˆæœ
            if processed_line != original_line.strip():
                logger.info(f"å¤„ç†Markdowné“¾æ¥: '{original_line[:50]}...' -> '{processed_line[:50] if processed_line else '(å·²åˆ é™¤)'}'")
            
            # å¦‚æœå¤„ç†åè¿˜æœ‰å†…å®¹ï¼Œä¿ç•™è¯¥è¡Œ
            if processed_line:
                filtered_lines.append(processed_line)
        
        # ç»„åˆç»“æœ
        result = '\n'.join(filtered_lines)
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        result = re.sub(r'\n{3,}', '\n\n', result).strip()
        
        if len(result) < len(content):
            logger.info(f"ç§»é™¤Markdowné“¾æ¥: {len(content)} -> {len(result)} å­—ç¬¦")
        
        return result
    
    def _smart_rule_filter(self, content: str) -> str:
        """
        æ™ºèƒ½è§„åˆ™è¿‡æ»¤ï¼Œå¯»æ‰¾æ˜ç¡®çš„æ¨å¹¿è¾¹ç•Œ
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            è¿‡æ»¤åçš„å†…å®¹
        """
        lines = content.split('\n')
        if len(lines) < 3:
            return content
        
        # æ˜ç¡®çš„åˆ†éš”æ ‡å¿—
        strong_separators = [
            r'^[-=_â€”â–]{10,}$',  # é•¿åˆ†éš”çº¿
            r'^[ğŸ“¢ğŸ“£ğŸ””ğŸ’¬â¤ï¸ğŸ”—]{2,}.*$',  # å¤šä¸ªæ¨å¹¿è¡¨æƒ…
            r'^[-=\*]{3,}\s*$',  # çŸ­åˆ†éš”çº¿
        ]
        
        # æ¨å¹¿å†…å®¹çš„å¼ºç‰¹å¾
        strong_promo = [
            r'\[.*\]\(https?://.*\)',  # Markdowné“¾æ¥æ ¼å¼
            r'(?:è®¢é˜…|é—œæ³¨|æŠ•ç¨¿|å•†åŠ¡|è”ç³»).*(?:@|t\.me/)',  # æ¨å¹¿è¯+é“¾æ¥
            r'https?://(?!(?:t\.me|telegram\.me))',  # éTelegramé“¾æ¥
            r'^\s*(?:é¢‘é“|é »é“|channel).*(?:@|t\.me/)',  # é¢‘é“æ¨å¹¿
        ]
        
        # ä»åå‘å‰æŸ¥æ‰¾æœ€æ˜ç¡®çš„åˆ†éš”ç‚¹
        best_separator_index = -1
        
        for i in range(len(lines) - 1, max(0, len(lines) - 20), -1):
            line = lines[i].strip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¼ºåˆ†éš”ç¬¦
            is_strong_separator = any(re.match(p, line) for p in strong_separators)
            
            if is_strong_separator:
                # éªŒè¯åˆ†éš”ç¬¦åé¢ç¡®å®æœ‰æ¨å¹¿å†…å®¹
                has_strong_promo = False
                promo_lines = 0
                
                for j in range(i + 1, min(i + 10, len(lines))):
                    if any(re.search(p, lines[j], re.IGNORECASE) for p in strong_promo):
                        has_strong_promo = True
                        promo_lines += 1
                
                # å¦‚æœåé¢æœ‰è‡³å°‘2è¡Œæ¨å¹¿å†…å®¹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„åˆ†éš”ç‚¹
                if has_strong_promo and promo_lines >= 2:
                    best_separator_index = i
                    break
        
        # å¦‚æœæ‰¾åˆ°äº†æ˜ç¡®çš„åˆ†éš”ç‚¹ï¼Œè¿‡æ»¤æ‰åˆ†éš”ç¬¦åŠä¹‹åçš„å†…å®¹
        if best_separator_index != -1:
            result = '\n'.join(lines[:best_separator_index])
            # æ¸…ç†å°¾éƒ¨ç©ºè¡Œ
            while result.endswith('\n\n'):
                result = result[:-1]
            return result.strip()
        
        return content
    
    def _apply_semantic_tail_filter(self, content: str, has_media: bool = False) -> str:
        """
        åº”ç”¨è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤ - åŸºäºè¯­ä¹‰åˆ†æå’Œè®­ç»ƒæ ·æœ¬
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            has_media: æ˜¯å¦æœ‰åª’ä½“æ–‡ä»¶
            
        Returns:
            è¿‡æ»¤åçš„å†…å®¹
        """
        if not content:
            return content
        
        try:
            from app.services.semantic_tail_filter import semantic_tail_filter
            
            logger.info(f"ğŸ¯ å¼€å§‹è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤ - è¾“å…¥å†…å®¹é•¿åº¦: {len(content)}, åŒ…å«åª’ä½“: {has_media}")
            filtered_content, was_filtered, removed_tail, analysis = semantic_tail_filter.filter_message(content, has_media)
            
            logger.info(f"ğŸ“‹ è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤ç»“æœ: æ˜¯å¦è¿‡æ»¤={was_filtered}, è¾“å‡ºé•¿åº¦={len(filtered_content)}")
            
            if was_filtered:
                logger.info(f"âœ… è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤æˆåŠŸ: {len(content)} -> {len(filtered_content)} å­—ç¬¦")
                if removed_tail:
                    logger.debug(f"ğŸ—‘ï¸ ç§»é™¤çš„å°¾éƒ¨å†…å®¹: {removed_tail[:100]}...")
                    logger.debug(f"ğŸ—‘ï¸ ç§»é™¤çš„å°¾éƒ¨å®Œæ•´å†…å®¹: {removed_tail}")
                if analysis:
                    logger.debug(f"ğŸ“Š åˆ†æè¯¦æƒ…: {analysis}")
                    if analysis.get('similarity', 0) > 0:
                        logger.debug(f"ğŸ” è®­ç»ƒæ ·æœ¬åŒ¹é…ç›¸ä¼¼åº¦: {analysis['similarity']:.2f}")
                return filtered_content
            else:
                logger.debug(f"âŒ è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤æœªç”Ÿæ•ˆï¼Œä¿ç•™åŸå§‹å†…å®¹")
            
            return content
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹: {e}")
            return content
    
    def filter_promotional_content(self, content: str, channel_id: str = None, has_media: bool = False) -> str:
        """
        æ™ºèƒ½è¿‡æ»¤æ¨å¹¿å†…å®¹ - ä¼˜åŒ–ç‰ˆæœ¬
        ä¼˜å…ˆä½¿ç”¨è®­ç»ƒæ•°æ®ï¼Œç„¶åä½¿ç”¨è§„åˆ™ï¼Œä¿æŠ¤æ­£æ–‡å†…å®¹
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            channel_id: é¢‘é“IDï¼ˆç”¨äºAIå°¾éƒ¨è¿‡æ»¤å’Œè‡ªå¼•ç”¨æ£€æµ‹ï¼‰
            has_media: æ˜¯å¦æœ‰åª’ä½“æ–‡ä»¶ï¼ˆå›¾ç‰‡ã€è§†é¢‘ç­‰ï¼‰
        """
        if not content:
            return content
        
        # ä¿å­˜åŸå§‹å†…å®¹
        original_content = content
        
        # 0. é¦–å…ˆç§»é™¤æ‰€æœ‰Markdowné“¾æ¥ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        content = self.remove_all_markdown_links(content, channel_id)
        if content != original_content:
            logger.info(f"ç§»é™¤Markdowné“¾æ¥: {len(original_content)} -> {len(content)}")
        
        # 1. åº”ç”¨è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤ï¼ˆä¸»è¦è¿‡æ»¤æ–¹æ³•ï¼‰
        semantic_filtered = self._apply_semantic_tail_filter(content, has_media)
        if semantic_filtered != content:
            logger.info(f"è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤æˆåŠŸ: {len(content)} -> {len(semantic_filtered)} å­—ç¬¦")
            # è¯­ä¹‰è¿‡æ»¤æˆåŠŸåï¼Œç›´æ¥è¿”å›ç»“æœï¼Œä¸å†è¿›è¡Œæ¿€è¿›çš„è§„åˆ™è¿‡æ»¤
            # è¿™é¿å…äº†å¯¹æ­£å¸¸å†…å®¹çš„è¯¯åˆ¤
            return semantic_filtered
        
        # å¦‚æœè¯­ä¹‰è¿‡æ»¤æ²¡æœ‰ç”Ÿæ•ˆï¼Œç›´æ¥è¿”å›åŸå§‹å†…å®¹
        # ä¸å†ä½¿ç”¨å…¶ä»–è¿‡æ»¤ç­–ç•¥ï¼Œé¿å…æ··ä¹±å’Œè¿‡åº¦è¿‡æ»¤
        return content
    
    
    def is_commercial_ad(self, content: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºå•†ä¸šå¹¿å‘Š"""
        if not content:
            return False
            
        lines = content.split('\n')
        commercial_indicators = 0
        
        # å…³é”®å•†ä¸šæŒ‡æ ‡
        commercial_patterns = [
            r'(è¥ä¸šæ—¶é—´|ç‡Ÿæ¥­æ™‚é–“|è¥ä¸šä¸­|ç‡Ÿæ¥­ä¸­)',
            r'(åº—é“ºåœ°å€|åº—é‹ªåœ°å€|é—¨åº—åœ°å€|é–€åº—åœ°å€)',
            r'(ç»è¥é¡¹ç›®|ç¶“ç‡Ÿé …ç›®|ä¸»è¥|ä¸»ç‡Ÿ)',
            r'(ä¼˜æƒ |å„ªæƒ |æŠ˜æ‰£|æ‰“æŠ˜|ç‰¹ä»·|ç‰¹åƒ¹)',
            r'(å¾®ä¿¡[:ï¼š]|WeChat[:ï¼š])',
            r'(ç”µè¯[:ï¼š]|é›»è©±[:ï¼š]|æ‰‹æœº[:ï¼š]|æ‰‹æ©Ÿ[:ï¼š])',
            r'(æ¥å•|æ¥å–®|ä¸‹å•|ä¸‹å–®|è®¢è´­|è¨‚è³¼)',
            r'(ä»·æ ¼|åƒ¹æ ¼|æ”¶è´¹|æ”¶è²»|è´¹ç”¨|è²»ç”¨)',
        ]
        
        for line in lines:
            for pattern in commercial_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    commercial_indicators += 1
                    break
        
        # å¦‚æœæœ‰4ä¸ªæˆ–ä»¥ä¸Šå•†ä¸šæŒ‡æ ‡ï¼Œåˆ¤å®šä¸ºå•†ä¸šå¹¿å‘Šï¼ˆä»3æé«˜åˆ°4ï¼Œå‡å°‘è¯¯åˆ¤ï¼‰
        return commercial_indicators >= 4
    
    def is_high_risk_ad(self, content: str) -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºé«˜é£é™©å¹¿å‘Šï¼ˆèµŒåšã€è‰²æƒ…ã€è¯ˆéª—ç­‰ï¼‰
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            
        Returns:
            æ˜¯å¦ä¸ºé«˜é£é™©å¹¿å‘Š
        """
        if not content:
            return False
        
        # é«˜é£é™©å¹¿å‘Šå…³é”®è¯æ¨¡å¼
        HIGH_RISK_PATTERNS = [
            # èµŒåšç›¸å…³
            r'[Yy]3.*(?:å¨±ä¹|å¨›æ¨‚|å›½é™…|åœ‹éš›|YLC|ylc)',
            r'(?:USDT|æ³°è¾¾å¸|æ³°é”å¹£|è™šæ‹Ÿå¸|è™›æ“¬å¹£).*(?:å¨±ä¹åŸ|å¨›æ¨‚åŸ|å¹³å°)',
            r'(?:åšå½©|èµŒåœº|è³­å ´|æ£‹ç‰Œ|ä½“è‚²|é«”è‚²).*(?:å¹³å°|å®˜ç½‘|å®˜ç¶²)',
            r'(?:é¦–å……|é¦–å­˜|é¦–å†²).*(?:è¿”æ°´|ä¼˜æƒ |å„ªæƒ )',
            r'(?:æ—¥å‡º|æ—¥å…¥|æ—¥èµš|æ—¥è³º).*[0-9]+.*[uUä¸‡è¬åƒ]',
            r'(?:å®åŠ›|å¯¦åŠ›).*(?:Uç›˜|Uç›¤|USDT)',
            r'(?:åƒä¸‡|åƒè¬|å·¨æ¬¾).*(?:æ— å¿§|ç„¡æ†‚)',
            r'(?:PG|pg).*(?:å¹¸è¿|å¹¸é‹|æ³¨å•|æ³¨å–®)',
            r'(?:ç™¾å®¶ä¹|ç™¾å®¶æ¨‚|è½®ç›˜|è¼ªç›¤|è½¬è¿é‡‘|è½‰é‹é‡‘)',
            r'å…¨ç½‘ç¦åˆ©.*ä¸šç•Œé¾™å¤´',
            r'ç”µå­.*(?:ä¸“æŸé‡‘|å°ˆæé‡‘|äºæŸ|è™§æ).*æœ€é«˜',
            
            # è‰²æƒ…ç›¸å…³
            r'(?:ä¸Šçº¿|ä¸Šç·š).*(?:ç¦åˆ©|å…«å¤§)',
            r'(?:æ°¸ä¹…|å…è´¹|å…è²»).*(?:é€|é¢†å–|é ˜å–)',
            r'(?:å¹¸è¿|å¹¸é‹).*(?:å•|å–®).*(?:å¥–|ç)',
            r'(?:ä¸Šé—¨|ä¸Šé–€).*(?:æœåŠ¡|æœå‹™).*(?:é¢œå€¼|é¡å€¼|èº«æ)',
            
            # è¯ˆéª—ç›¸å…³
            r'(?:ä¸€ä¸ªæœˆ|ä¸€å€‹æœˆ).*(?:å¥”é©°|å¥”é¦³|å®é©¬|å¯¶é¦¬|æå¥”é©°|æå¯¶é¦¬)',
            r'(?:ä¸‰ä¸ªæœˆ|ä¸‰å€‹æœˆ).*(?:å¥—æˆ¿|æˆ¿å­|ä¸€å¥—æˆ¿)',
            r'(?:æ±½è½¦|æ±½è»Š).*(?:è¿åœ|é•åœ).*(?:æ‹ç…§|ä¸€å¼ |ä¸€å¼µ).*[0-9]+',
            r'(?:æƒ³åŠŸæˆåå°±|èƒ†å­å¤§|è†½å­å¤§).*(?:ç°è‰²|çœ‹æˆ‘|ç…®å¶|ç…®è‘‰)',
            r'(?:ç©ºé—²|ç©ºé–’).*(?:å“¥ä»¬|å“¥å€‘).*(?:å¹²ç‚¹äº‹|å¹¹é»äº‹).*(?:å®é©¬|å¯¶é¦¬)',
            
            # å…¶ä»–é«˜é£é™©è¯æ±‡
            r'åŒ¿åç§’ç™»|æ—¥å‡ºäº¿U|å®˜æ–¹ç›´è¥|å®˜æ–¹ç›´ç‡Ÿ',
            r'Y3YLC|y3ylc',  # ç‰¹å®šèµŒåšç½‘ç«™
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é«˜é£é™©æ¨¡å¼
        for pattern in HIGH_RISK_PATTERNS:
            if re.search(pattern, content, re.IGNORECASE):
                logger.info(f"æ£€æµ‹åˆ°é«˜é£é™©å¹¿å‘Šå…³é”®è¯: {pattern[:30]}...")
                return True
                
        return False
    
    
    async def filter_message(self, content: str, channel_id: str = None, message_obj: Any = None, media_files: List[str] = None) -> Tuple[bool, str, str, dict]:
        """
        è¿‡æ»¤æ¶ˆæ¯å†…å®¹ - ä½¿ç”¨ç»Ÿä¸€è¿‡æ»¤å¼•æ“
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            channel_id: é¢‘é“IDï¼ˆç”¨äºAIè¿‡æ»¤ï¼‰
            message_obj: Telegramæ¶ˆæ¯å¯¹è±¡ï¼ˆç”¨äºç»“æ„åŒ–æ£€æµ‹ï¼‰
            media_files: åª’ä½“æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç”¨äºOCRå¤„ç†ï¼‰
        
        Returns:
            (æ˜¯å¦å¹¿å‘Š, è¿‡æ»¤åå†…å®¹, è¿‡æ»¤åŸå› , OCRç»“æœ)
        """
        if not content:
            content = ""
        
        # ä½¿ç”¨ç»Ÿä¸€è¿‡æ»¤å¼•æ“
        try:
            from app.services.unified_filter_engine import unified_filter_engine
            is_ad, filtered_content, filter_reason = await unified_filter_engine.detect_advertisement(
                content, channel_id, message_obj, media_files
            )
            
            # ç»Ÿä¸€è¿‡æ»¤å¼•æ“å·²ç»åŒ…å«äº†è¯­ä¹‰å°¾éƒ¨è¿‡æ»¤ï¼Œæ— éœ€å†æ¬¡è¿›è¡Œæ¨å¹¿è¿‡æ»¤
            # è¿™é¿å…äº†å¯¹å·²ç»è¢«è¯­ä¹‰è¿‡æ»¤ä¿æŠ¤çš„æ­£å¸¸å†…å®¹è¿›è¡ŒäºŒæ¬¡è¿‡æ»¤
            
            # OCRç»“æœå¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
            ocr_result = await self._process_ocr_if_needed(media_files, filtered_content, is_ad)
            
            return is_ad, filtered_content, filter_reason, ocr_result
            
        except Exception as e:
            logger.error(f"ç»Ÿä¸€è¿‡æ»¤å¼•æ“è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•: {e}")
            # é™çº§åˆ°åŸå§‹æ–¹æ³•
            return await self._original_filter_message(content, channel_id, message_obj, media_files)
    
    async def _process_ocr_if_needed(self, media_files, filtered_content, is_ad):
        """å¤„ç†OCRç»“æœ"""
        ocr_result = {}
        if media_files and not is_ad:
            # TODO: å®ç°OCRå¤„ç†
            pass
        return ocr_result
    
    async def _original_filter_message(self, content: str, channel_id: str = None, message_obj: Any = None, media_files: List[str] = None) -> Tuple[bool, str, str, dict]:
        """
        åŸå§‹çš„è¿‡æ»¤æ¶ˆæ¯æ–¹æ³•ï¼ˆä½œä¸ºé™çº§æ–¹æ¡ˆï¼‰
        """
        if not content:
            content = ""
        
        # è®°å½•åˆå§‹å†…å®¹é•¿åº¦
        original_len = len(content)
        filtered_content = content
        is_ad = False
        reasons = []
        ocr_result = {}
        
        # 1. OCRå›¾ç‰‡æ–‡å­—æå–å’Œå¹¿å‘Šæ£€æµ‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if media_files:
            try:
                from app.services.ocr_service import ocr_service
                
                # å¤„ç†å›¾ç‰‡ç±»å‹çš„åª’ä½“æ–‡ä»¶
                image_files = []
                for media_file in media_files:
                    if media_file and any(media_file.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']):
                        image_files.append(media_file)
                
                if image_files:
                    logger.info(f"å¼€å§‹OCRå¤„ç† {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
                    
                    # æ‰¹é‡å¤„ç†å›¾ç‰‡
                    ocr_results = await ocr_service.batch_extract_content(image_files)
                    
                    # åˆå¹¶æ‰€æœ‰OCRæå–çš„æ–‡å­—
                    all_ocr_texts = []
                    all_qr_codes = []
                    total_ad_score = 0
                    ocr_ad_indicators = []
                    
                    for file_path, result in ocr_results.items():
                        if result.get('error'):
                            logger.warning(f"OCRå¤„ç†å¤±è´¥: {file_path} - {result['error']}")
                            continue
                            
                        texts = result.get('texts', [])
                        qr_codes = result.get('qr_codes', [])
                        ad_score = result.get('ad_score', 0)
                        ad_indicators = result.get('ad_indicators', [])
                        
                        all_ocr_texts.extend(texts)
                        all_qr_codes.extend(qr_codes)
                        total_ad_score = max(total_ad_score, ad_score)  # å–æœ€é«˜åˆ†æ•°
                        ocr_ad_indicators.extend(ad_indicators)
                    
                    # å°†OCRæ–‡å­—åˆå¹¶åˆ°åŸå§‹å†…å®¹ä¸­è¿›è¡Œç»¼åˆæ£€æµ‹
                    if all_ocr_texts:
                        ocr_text = ' '.join(all_ocr_texts)
                        # å°†OCRæ–‡å­—æ·»åŠ åˆ°åŸå§‹å†…å®¹åé¢ï¼Œç”¨æ¢è¡Œç¬¦åˆ†éš”
                        if filtered_content.strip():
                            filtered_content = f"{filtered_content}\n\n[å›¾ç‰‡æ–‡å­—å†…å®¹]\n{ocr_text}"
                        else:
                            filtered_content = f"[å›¾ç‰‡æ–‡å­—å†…å®¹]\n{ocr_text}"
                        
                        logger.info(f"OCRæå–æ–‡å­— {len(all_ocr_texts)} æ¡ï¼Œåˆå¹¶åˆ°æ¶ˆæ¯å†…å®¹ä¸­")
                    
                    # OCRå¹¿å‘Šæ£€æµ‹
                    if total_ad_score >= 30:  # 30åˆ†ä»¥ä¸Šè®¤ä¸ºæ˜¯å¹¿å‘Š
                        is_ad = True
                        reasons.append(f"å›¾ç‰‡å¹¿å‘Šå†…å®¹(åˆ†æ•°:{total_ad_score:.0f})")
                        logger.info(f"OCRæ£€æµ‹åˆ°å›¾ç‰‡å¹¿å‘Šï¼Œåˆ†æ•°: {total_ad_score}")
                    
                    # ä¿å­˜OCRç»“æœ
                    ocr_result = {
                        'texts': all_ocr_texts,
                        'qr_codes': all_qr_codes,
                        'ad_score': total_ad_score,
                        'ad_indicators': ocr_ad_indicators,
                        'processed_files': len(image_files)
                    }
                    
            except Exception as e:
                logger.error(f"OCRå¤„ç†å¤±è´¥: {e}")
        
        # 2. æ™ºèƒ½å°¾éƒ¨è¿‡æ»¤ï¼ˆç§»é™¤é¢‘é“æ ‡è¯†ï¼Œä¸ç®—å¹¿å‘Šï¼‰
        try:
            from app.services.smart_tail_filter import smart_tail_filter
            clean_content, has_tail_ad, ad_part = smart_tail_filter.filter_tail_ads(
                filtered_content,
                channel_id=channel_id  # ä¼ é€’é¢‘é“IDç”¨äºAIæ¨¡å¼åŒ¹é…
            )
            if has_tail_ad:
                filtered_content = clean_content
                # æ³¨æ„ï¼šå°¾éƒ¨è¿‡æ»¤æ˜¯ç§»é™¤åŸé¢‘é“æ ‡è¯†ï¼Œä¸ç®—å¹¿å‘Šï¼Œæ‰€ä»¥ä¸è®¾ç½® is_ad = True
                # is_ad = True  # ç§»é™¤è¿™è¡Œ
                reasons.append("å°¾éƒ¨è¿‡æ»¤")  # æ”¹ä¸º"å°¾éƒ¨è¿‡æ»¤"è€Œä¸æ˜¯"å°¾éƒ¨å¹¿å‘Š"
                logger.info(f"è¿‡æ»¤äº†å°¾éƒ¨é¢‘é“æ ‡è¯†ï¼Œç§»é™¤ {len(ad_part)} å­—ç¬¦")
        except Exception as e:
            logger.error(f"å°¾éƒ¨è¿‡æ»¤å¤±è´¥: {e}")
        
        # 3. æ¶ˆæ¯ç»“æ„åˆ†æï¼ˆæ ¼å¼åŒ–æ¨å¹¿æ£€æµ‹ï¼‰- æ–°å¢åŠŸèƒ½
        # åªå¯¹åˆå¹¶åçš„å†…å®¹è¿›è¡Œç»“æ„åˆ†æï¼Œé¿å…é‡å¤æ£€æµ‹
        if filtered_content and not is_ad:  # åªæœ‰è¿˜ä¸æ˜¯å¹¿å‘Šæ—¶æ‰æ£€æµ‹
            try:
                is_structural_promo, structure_scores = message_structure_analyzer.analyze(filtered_content)
                if is_structural_promo:
                    is_ad = True
                    # è¯¦ç»†çš„ç»“æ„å¼‚å¸¸è¯´æ˜
                    structure_details = []
                    if structure_scores.get('emoji_density', 0) > 0.15:
                        structure_details.append(f"è¡¨æƒ…å¯†åº¦{structure_scores['emoji_density']:.1%}")
                    if structure_scores.get('link_density', 0) > 2.0:
                        structure_details.append(f"é“¾æ¥å¯†åº¦{structure_scores['link_density']:.1f}/100å­—")
                    if structure_scores.get('structure_abnormality', 0) > 0.6:
                        structure_details.append(f"ç»“æ„å¼‚å¸¸{structure_scores['structure_abnormality']:.1%}")
                    
                    detail_str = ",".join(structure_details) if structure_details else f"ç»¼åˆå¾—åˆ†{structure_scores.get('total_score', 0):.2f}"
                    reasons.append(f"æ ¼å¼åŒ–æ¨å¹¿({detail_str})")
                    logger.info(f"æ£€æµ‹åˆ°æ ¼å¼åŒ–æ¨å¹¿æ¶ˆæ¯: {detail_str}")
                    
                    # å¦‚æœæ£€æµ‹åˆ°æ ¼å¼åŒ–æ¨å¹¿ï¼Œå¯ä»¥é€‰æ‹©æ¸…ç©ºå†…å®¹æˆ–è¿›è¡Œæ¨å¹¿è¿‡æ»¤
                    if structure_scores.get('total_score', 0) > 0.8:  # é«˜ç½®ä¿¡åº¦æ—¶æ¸…ç©º
                        filtered_content = ""
                    else:  # å¦åˆ™è¿›è¡Œæ¨å¹¿å†…å®¹è¿‡æ»¤
                        filtered_content = self.filter_promotional_content(filtered_content, channel_id)
            except Exception as e:
                logger.error(f"æ¶ˆæ¯ç»“æ„åˆ†æå¤±è´¥: {e}")
        
        # 4. ç»“æ„åŒ–å¹¿å‘Šæ£€æµ‹ï¼ˆæ£€æµ‹æŒ‰é’®å’Œå®ä½“ä¸­çš„å¹¿å‘Šï¼‰- ä¿ç•™åŸæœ‰åŠŸèƒ½
        if message_obj and not is_ad:  # åªæœ‰è¿˜ä¸æ˜¯å¹¿å‘Šæ—¶æ‰æ£€æµ‹
            try:
                from app.services.structural_ad_detector import structural_detector
                structural_result = await structural_detector.detect_structural_ads(message_obj)
                if structural_result['has_structural_ad']:
                    is_ad = True
                    reasons.append(f"ç»“æ„åŒ–å¹¿å‘Š({structural_result['ad_type']})")
                    # å¦‚æœæœ‰éœ€è¦æ¸…ç†çš„æ–‡æœ¬å®ä½“ï¼Œæ›´æ–°å†…å®¹
                    if structural_result.get('clean_text'):
                        filtered_content = structural_result['clean_text']
                    logger.info(f"æ£€æµ‹åˆ°ç»“æ„åŒ–å¹¿å‘Š: {structural_result['ad_type']}")
            except Exception as e:
                logger.error(f"ç»“æ„åŒ–å¹¿å‘Šæ£€æµ‹å¤±è´¥: {e}")
        
        # 5. AIå¹¿å‘Šæ£€æµ‹ï¼ˆå¯¹åˆå¹¶åçš„å†…å®¹è¿›è¡Œæ£€æµ‹ï¼‰
        if self.ai_filter and self.ai_filter.initialized and filtered_content:
            is_ad_by_ai, ai_confidence = self.ai_filter.is_advertisement(filtered_content)
            if is_ad_by_ai and ai_confidence > 0.85:  # æé«˜é˜ˆå€¼ä»0.8åˆ°0.85
                is_ad = True
                reasons.append(f"AIæ£€æµ‹(ç½®ä¿¡åº¦:{ai_confidence:.2f})")
                logger.info(f"AIæ£€æµ‹åˆ°å¹¿å‘Šå†…å®¹ï¼Œç½®ä¿¡åº¦: {ai_confidence:.2f}")
                # å¦‚æœæ•´æ¡æ¶ˆæ¯éƒ½æ˜¯å¹¿å‘Šï¼Œæ¸…ç©ºå†…å®¹
                if ai_confidence > 0.95:  # æé«˜é˜ˆå€¼ä»0.9åˆ°0.95
                    filtered_content = ""
        
        # 6. å•†ä¸šå¹¿å‘Šæ£€æµ‹
        if filtered_content:
            is_commercial = self.is_commercial_ad(filtered_content)
            if is_commercial:
                is_ad = True
                reasons.append("å•†ä¸šå¹¿å‘Š")
                # è¿›è¡Œæ¨å¹¿å†…å®¹è¿‡æ»¤
                filtered_content = self.filter_promotional_content(filtered_content, channel_id)
        
        # 7. é«˜é£é™©å¹¿å‘Šæ£€æµ‹ï¼ˆèµŒåšã€è‰²æƒ…ã€è¯ˆéª—ç­‰ï¼‰
        if content:  # æ£€æŸ¥åŸå§‹å†…å®¹è€Œä¸æ˜¯è¿‡æ»¤åçš„å†…å®¹
            is_high_risk = self.is_high_risk_ad(content)
            if is_high_risk:
                is_ad = True
                if "é«˜é£é™©å¹¿å‘Š" not in reasons:
                    reasons.append("é«˜é£é™©å¹¿å‘Š")
                # é«˜é£é™©å¹¿å‘Šåº”è¯¥æ¸…ç©ºå†…å®¹
                filtered_content = ""
                logger.warning(f"æ£€æµ‹åˆ°é«˜é£é™©å¹¿å‘Šï¼Œå†…å®¹å·²æ¸…ç©º")
        
        # 8. æ¨å¹¿å†…å®¹è¿‡æ»¤ï¼ˆæœ€åçš„ä¿é™©ï¼‰
        if filtered_content:
            final_filtered = self.filter_promotional_content(filtered_content, channel_id)
            if final_filtered != filtered_content:
                filtered_content = final_filtered
                if not is_ad:
                    is_ad = True
                    reasons.append("æ¨å¹¿å†…å®¹")
        
        # 9. æ¸…ç†OCRæ·»åŠ çš„æ ‡è®°ï¼ˆå¦‚æœä¸æ˜¯å¹¿å‘Šï¼Œç§»é™¤OCRæ ‡è®°ï¼‰
        if not is_ad and "[å›¾ç‰‡æ–‡å­—å†…å®¹]" in filtered_content:
            # å¦‚æœä¸æ˜¯å¹¿å‘Šï¼Œæ¢å¤åŸå§‹å†…å®¹ï¼ˆç§»é™¤OCRæ–‡å­—ï¼‰
            filtered_content = content
        elif is_ad and "[å›¾ç‰‡æ–‡å­—å†…å®¹]" in filtered_content:
            # å¦‚æœæ˜¯å¹¿å‘Šï¼Œç§»é™¤OCRæ ‡è®°ä½†ä¿ç•™åŸå§‹å†…å®¹
            lines = filtered_content.split('\n')
            clean_lines = []
            skip_ocr = False
            for line in lines:
                if "[å›¾ç‰‡æ–‡å­—å†…å®¹]" in line:
                    skip_ocr = True
                    continue
                if not skip_ocr:
                    clean_lines.append(line)
            filtered_content = '\n'.join(clean_lines)
        
        # æ£€æŸ¥æ˜¯å¦æ•´æ¡æ¶ˆæ¯éƒ½è¢«è¿‡æ»¤äº†
        if not filtered_content.strip() and content.strip():
            is_ad = True
            if "æ•´æ¡æ¶ˆæ¯éƒ½æ˜¯å¹¿å‘Š" not in reasons:
                reasons.append("æ•´æ¡æ¶ˆæ¯éƒ½æ˜¯å¹¿å‘Š")
        
        # ç”Ÿæˆè¿‡æ»¤åŸå› è¯´æ˜
        filter_reason = " | ".join(reasons) if reasons else ""
        
        # è®°å½•è¿‡æ»¤æ•ˆæœ
        if original_len != len(filtered_content):
            logger.info(f"å†…å®¹è¿‡æ»¤: {original_len} -> {len(filtered_content)} å­—ç¬¦ (å‡å°‘ {original_len - len(filtered_content)})")
        
        return is_ad, filtered_content, filter_reason, ocr_result
    
    def filter_message_sync(self, content: str, channel_id: str = None, message_obj: Any = None) -> Tuple[bool, str, str]:
        """
        åŒæ­¥ç‰ˆæœ¬çš„æ¶ˆæ¯è¿‡æ»¤æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
        ä½¿ç”¨ç»Ÿä¸€è¿‡æ»¤å¼•æ“ï¼Œç¡®ä¿AIæ£€æµ‹å’Œå°¾éƒ¨è¿‡æ»¤éƒ½ç”Ÿæ•ˆ
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            channel_id: é¢‘é“ID
            message_obj: Telegramæ¶ˆæ¯å¯¹è±¡
            
        Returns:
            (æ˜¯å¦å¹¿å‘Š, è¿‡æ»¤åå†…å®¹, è¿‡æ»¤åŸå› )
        """
        if not content:
            return False, content, ""
        
        # ä½¿ç”¨ç»Ÿä¸€è¿‡æ»¤å¼•æ“
        try:
            from app.services.unified_filter_engine import unified_filter_engine
            is_ad, filtered_content, filter_reason = unified_filter_engine.detect_advertisement_sync(
                content, channel_id, message_obj
            )
            
            # å¦‚æœç»Ÿä¸€å¼•æ“æ²¡æœ‰æ£€æµ‹åˆ°ï¼Œå†ç”¨æœ¬åœ°çš„æ¨å¹¿å†…å®¹è¿‡æ»¤
            if not is_ad and filtered_content:
                final_filtered = self.filter_promotional_content(filtered_content, channel_id)
                if final_filtered != filtered_content:
                    filtered_content = final_filtered
                    is_ad = True
                    filter_reason = "æ¨å¹¿å†…å®¹"
            
            return is_ad, filtered_content, filter_reason
            
        except Exception as e:
            logger.error(f"ç»Ÿä¸€è¿‡æ»¤å¼•æ“è°ƒç”¨å¤±è´¥ï¼Œé™çº§åˆ°åŸºæœ¬è¿‡æ»¤: {e}")
            # é™çº§åˆ°åŸºæœ¬è¿‡æ»¤
            return self._basic_filter(content, channel_id)
    
    def _basic_filter(self, content: str, channel_id: str = None) -> Tuple[bool, str, str]:
        """
        åŸºæœ¬è¿‡æ»¤ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        """
        if not content:
            return False, content, ""
        
        filtered_content = content
        is_ad = False
        reasons = []
        
        # æ¨å¹¿å†…å®¹è¿‡æ»¤
        final_filtered = self.filter_promotional_content(filtered_content, channel_id)
        if final_filtered != filtered_content:
            filtered_content = final_filtered
            is_ad = True
            reasons.append("æ¨å¹¿å†…å®¹")
        
        # é«˜é£é™©å¹¿å‘Šæ£€æµ‹
        if self.is_high_risk_ad(content):
            is_ad = True
            filtered_content = ""
            reasons.append("é«˜é£é™©å¹¿å‘Š")
        
        filter_reason = " | ".join(reasons) if reasons else ""
        return is_ad, filtered_content, filter_reason
    
    def check_ad_keywords(self, content: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥å¹¿å‘Šå…³é”®è¯ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        """
        # ç®€å•æ£€æŸ¥ä¸€äº›æ˜æ˜¾çš„å¹¿å‘Šå…³é”®è¯
        ad_keywords = [
            'èµŒåœº', 'èµŒåš', 'å¨±ä¹åŸ', 'çœŸäºº', 'ç™¾å®¶ä¹',
            'è¿”æ°´', 'é¦–å……', 'ä¼˜æƒ ', 'æ³¨å†Œå°±é€',
            'æ—¥å‡ºåƒä¸‡', 'å…¨ç½‘ç‹¬å®¶'
        ]
        
        if not content:
            return False, ""
            
        content_lower = content.lower()
        for keyword in ad_keywords:
            if keyword in content_lower:
                return True, f"åŒ…å«å¹¿å‘Šå…³é”®è¯: {keyword}"
                
        return False, ""
    
    def smart_filter_tail_promo(self, content: str) -> str:
        """
        æ™ºèƒ½è¿‡æ»¤å°¾éƒ¨æ¨å¹¿ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        """
        return self.filter_promotional_content(content)
    
    async def is_pure_advertisement_ai(self, content: str) -> bool:
        """
        ä½¿ç”¨AIåˆ¤æ–­æ˜¯å¦ä¸ºå¹¿å‘Šå†…å®¹
        """
        if not content:
            return False
        
        try:
            # å°è¯•ä½¿ç”¨AIå¹¿å‘Šæ£€æµ‹å™¨
            from app.services.ad_detector import ad_detector
            
            if ad_detector.initialized and len(ad_detector.ad_embeddings) > 0:
                # ä½¿ç”¨çº¯AIæ£€æµ‹
                is_ad, confidence = ad_detector.is_advertisement_ai(content)
                if confidence > 0.8:  # é«˜ç½®ä¿¡åº¦æ—¶ç›´æ¥è¿”å›ç»“æœ
                    logger.debug(f"AIå¹¿å‘Šæ£€æµ‹: {'æ˜¯' if is_ad else 'å¦'}, ç½®ä¿¡åº¦: {confidence:.2f}")
                    return is_ad
                elif is_ad and confidence > 0.7:  # ä¸­ç­‰ç½®ä¿¡åº¦çš„å¹¿å‘Šä¹Ÿè®¤ä¸ºæ˜¯å¹¿å‘Š
                    return True
        except Exception as e:
            logger.error(f"AIå¹¿å‘Šæ£€æµ‹å¤±è´¥: {e}")
        
        # AIæ£€æµ‹å¤±è´¥æˆ–ç½®ä¿¡åº¦ä¸è¶³ï¼Œå›é€€åˆ°è§„åˆ™æ£€æµ‹
        return self.is_pure_advertisement(content)
    
    def is_pure_advertisement(self, content: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦çº¯å¹¿å‘Šå†…å®¹ï¼ˆåŸºäºè§„åˆ™çš„ä¼ ç»Ÿæ–¹æ³•ï¼‰
        """
        if not content:
            return False
            
        # è¿‡æ»¤åå¦‚æœå‡ ä¹æ²¡æœ‰å‰©ä½™å†…å®¹ï¼Œè¯´æ˜æ˜¯çº¯å¹¿å‘Š
        filtered = self.filter_promotional_content(content)
        
        # å¦‚æœè¿‡æ»¤åå†…å®¹ä¸ºç©ºæˆ–è€…å‰©ä½™å†…å®¹å¤ªå°‘
        if not filtered.strip():
            return True
            
        # å¦‚æœè¿‡æ»¤æ‰äº†80%ä»¥ä¸Šçš„å†…å®¹ï¼Œè®¤ä¸ºæ˜¯å¹¿å‘Š
        if len(filtered) < len(content) * 0.2:
            return True
            
        return False
    
    def add_channel_signature(self, content: str, channel_name: str) -> str:
        """
        æ·»åŠ é¢‘é“ç­¾åï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        """
        if not content:
            return content
            
        # æ·»åŠ é¢‘é“æ ‡è¯†
        signature = f"\n\nã€æ¥æºï¼š{channel_name}ã€‘"
        return content + signature

# åˆ›å»ºå…¨å±€å®ä¾‹
content_filter = ContentFilter()