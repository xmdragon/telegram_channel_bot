"""
æ¶ˆæ¯å»é‡æœåŠ¡
ä½¿ç”¨å¤šç§ç®—æ³•æ™ºèƒ½è¯†åˆ«å’Œå»é™¤ç›¸ä¼¼çš„é‡å¤æ¶ˆæ¯
"""
import hashlib
import re
import logging
from typing import Tuple, Optional, List
from datetime import datetime, timedelta
from difflib import SequenceMatcher
import jieba
from sqlalchemy import select, and_
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import AsyncSessionLocal, Message

logger = logging.getLogger(__name__)

class MessageDeduplicator:
    """æ¶ˆæ¯å»é‡å™¨"""
    
    def __init__(self):
        # ç›¸ä¼¼åº¦é˜ˆå€¼
        self.similarity_threshold = 0.85  # 85%ç›¸ä¼¼åº¦
        self.time_window_minutes = 30  # 30åˆ†é’Ÿæ—¶é—´çª—å£
        
        # éœ€è¦è¿‡æ»¤çš„å¸¸è§å¹¿å‘Šæ ‡ç­¾å’Œé¢‘é“æ ‡è®°
        self.common_tags = [
            r'#\w+',  # æ ‡ç­¾
            r'@\w+',  # ç”¨æˆ·å/é¢‘é“å
            r'https?://[^\s]+',  # é“¾æ¥
            r't\.me/[^\s]+',  # Telegramé“¾æ¥
            r'(?:^|\s)è®¢é˜….{0,20}(?:$|\s)',  # è®¢é˜…ç›¸å…³æ–‡å­—
            r'(?:^|\s)æŠ•ç¨¿.{0,20}(?:$|\s)',  # æŠ•ç¨¿ç›¸å…³æ–‡å­—
            r'(?:^|\s)è”ç³».{0,20}(?:$|\s)',  # è”ç³»æ–¹å¼
            r'ğŸ“¢|ğŸ“£|ğŸ“¡|ğŸ|ğŸ’°|ğŸ”¥|â¤|ğŸ˜Š|ğŸ˜|ğŸ‘‡',  # å¸¸è§è¡¨æƒ…
        ]
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.tag_patterns = [re.compile(pattern) for pattern in self.common_tags]
        
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤æ ‡ç­¾ã€é“¾æ¥ç­‰å¹²æ‰°å› ç´ """
        if not text:
            return ""
        
        cleaned = text
        
        # ç§»é™¤æ‰€æœ‰æ ‡ç­¾å’Œé“¾æ¥
        for pattern in self.tag_patterns:
            cleaned = pattern.sub(' ', cleaned)
        
        # å»é™¤å¤šä½™ç©ºç™½
        cleaned = ' '.join(cleaned.split())
        
        return cleaned.strip()
    
    def _extract_core_content(self, text: str) -> str:
        """æå–æ ¸å¿ƒå†…å®¹ï¼ˆä¸»è¦æ˜¯æ–°é—»å†…å®¹éƒ¨åˆ†ï¼‰"""
        if not text:
            return ""
        
        # æŒ‰è¡Œåˆ†å‰²
        lines = text.split('\n')
        
        # æ‰¾åˆ°ä¸»è¦å†…å®¹ï¼ˆé€šå¸¸æ˜¯æœ€é•¿çš„æ®µè½ï¼‰
        main_content = []
        for line in lines:
            line = line.strip()
            if len(line) > 50:  # è¶…è¿‡50ä¸ªå­—ç¬¦çš„è¡Œå¯èƒ½æ˜¯ä¸»è¦å†…å®¹
                main_content.append(line)
        
        # å¦‚æœæ²¡æœ‰é•¿æ®µè½ï¼Œä½¿ç”¨å‰å‡ è¡Œ
        if not main_content:
            main_content = [line.strip() for line in lines[:5] if line.strip()]
        
        return '\n'.join(main_content)
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        if not text1 or not text2:
            return 0.0
        
        # æ¸…ç†æ–‡æœ¬
        clean_text1 = self._clean_text(text1)
        clean_text2 = self._clean_text(text2)
        
        # å¦‚æœæ¸…ç†åçš„æ–‡æœ¬å¤ªçŸ­ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹
        if len(clean_text1) < 20 or len(clean_text2) < 20:
            clean_text1 = self._extract_core_content(text1)
            clean_text2 = self._extract_core_content(text2)
            clean_text1 = self._clean_text(clean_text1)
            clean_text2 = self._clean_text(clean_text2)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        return SequenceMatcher(None, clean_text1, clean_text2).ratio()
    
    def _calculate_hash_similarity(self, text1: str, text2: str) -> float:
        """ä½¿ç”¨åˆ†è¯å’Œå“ˆå¸Œè®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå¯¹ä¸­æ–‡æ›´å‹å¥½ï¼‰"""
        if not text1 or not text2:
            return 0.0
        
        # æå–æ ¸å¿ƒå†…å®¹
        core1 = self._extract_core_content(text1)
        core2 = self._extract_core_content(text2)
        
        # åˆ†è¯
        words1 = set(jieba.cut(self._clean_text(core1)))
        words2 = set(jieba.cut(self._clean_text(core2)))
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        words1 = {w for w in words1 if len(w) > 1}
        words2 = {w for w in words2 if len(w) > 1}
        
        if not words1 or not words2:
            return 0.0
        
        # è®¡ç®—Jaccardç›¸ä¼¼åº¦
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0
    
    async def is_duplicate(self, content: str, source_channel: str, 
                          message_time: datetime, db: AsyncSession) -> Tuple[bool, Optional[int]]:
        """
        æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦ä¸ºé‡å¤æ¶ˆæ¯
        è¿”å›: (æ˜¯å¦é‡å¤, åŸå§‹æ¶ˆæ¯ID)
        """
        try:
            # è®¾ç½®æ—¶é—´çª—å£
            time_start = message_time - timedelta(minutes=self.time_window_minutes)
            time_end = message_time + timedelta(minutes=self.time_window_minutes)
            
            # æŸ¥è¯¢æ—¶é—´çª—å£å†…çš„å…¶ä»–æ¶ˆæ¯
            result = await db.execute(
                select(Message).where(
                    and_(
                        Message.created_at >= time_start,
                        Message.created_at <= time_end,
                        Message.source_channel != source_channel  # ä¸åŒé¢‘é“
                    )
                ).order_by(Message.created_at.desc())
            )
            recent_messages = result.scalars().all()
            
            # æ£€æŸ¥ç›¸ä¼¼åº¦
            for msg in recent_messages:
                if not msg.content:
                    continue
                
                # è®¡ç®—å¤šç§ç›¸ä¼¼åº¦
                text_similarity = self._calculate_similarity(content, msg.content)
                hash_similarity = self._calculate_hash_similarity(content, msg.content)
                
                # å–æœ€é«˜ç›¸ä¼¼åº¦
                max_similarity = max(text_similarity, hash_similarity)
                
                logger.debug(f"ç›¸ä¼¼åº¦æ£€æŸ¥: {max_similarity:.2f} (æ–‡æœ¬: {text_similarity:.2f}, å“ˆå¸Œ: {hash_similarity:.2f})")
                
                if max_similarity >= self.similarity_threshold:
                    logger.info(f"å‘ç°é‡å¤æ¶ˆæ¯ï¼Œç›¸ä¼¼åº¦: {max_similarity:.2f}")
                    return True, msg.id
            
            return False, None
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥é‡å¤æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return False, None
    
    async def find_similar_messages(self, content: str, source_channel: str,
                                   message_time: datetime, db: AsyncSession,
                                   limit: int = 5) -> List[dict]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼çš„æ¶ˆæ¯
        è¿”å›ç›¸ä¼¼æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦ä¿¡æ¯
        """
        similar_messages = []
        
        try:
            # æ‰©å¤§æ—¶é—´çª—å£ç”¨äºåˆ†æ
            time_start = message_time - timedelta(hours=2)
            time_end = message_time + timedelta(hours=2)
            
            # æŸ¥è¯¢æ—¶é—´çª—å£å†…çš„æ¶ˆæ¯
            result = await db.execute(
                select(Message).where(
                    and_(
                        Message.created_at >= time_start,
                        Message.created_at <= time_end,
                        Message.source_channel != source_channel
                    )
                ).order_by(Message.created_at.desc())
            )
            messages = result.scalars().all()
            
            # è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åº
            for msg in messages:
                if not msg.content:
                    continue
                
                text_similarity = self._calculate_similarity(content, msg.content)
                hash_similarity = self._calculate_hash_similarity(content, msg.content)
                max_similarity = max(text_similarity, hash_similarity)
                
                if max_similarity >= 0.5:  # 50%ä»¥ä¸Šçš„ç›¸ä¼¼åº¦æ‰è®°å½•
                    similar_messages.append({
                        'message_id': msg.id,
                        'channel': msg.source_channel,
                        'content': msg.content[:100] + '...' if len(msg.content) > 100 else msg.content,
                        'similarity': max_similarity,
                        'created_at': msg.created_at
                    })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            similar_messages.sort(key=lambda x: x['similarity'], reverse=True)
            
            return similar_messages[:limit]
            
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾ç›¸ä¼¼æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return []

# å…¨å±€æ¶ˆæ¯å»é‡å™¨å®ä¾‹
message_deduplicator = MessageDeduplicator()