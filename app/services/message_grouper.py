"""
æ¶ˆæ¯ç»„åˆå¤„ç†å™¨ - å¤„ç†Telegramçš„æ¶ˆæ¯ç»„åˆåŠŸèƒ½
"""
import logging
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from sqlalchemy import select
from app.core.database import AsyncSessionLocal, Message

logger = logging.getLogger(__name__)

class MessageGrouper:
    """æ¶ˆæ¯ç»„åˆå¤„ç†å™¨"""
    
    def __init__(self):
        self.pending_groups: Dict[str, List[Dict]] = {}  # å¾…å¤„ç†çš„æ¶ˆæ¯ç»„
        self.group_timers: Dict[str, asyncio.Task] = {}  # ç»„åˆè¶…æ—¶å®šæ—¶å™¨
        self.group_timeout = 10  # æ¶ˆæ¯ç»„åˆè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- ç»Ÿä¸€ä½¿ç”¨10ç§’
        self.telegram_messages: Dict[str, Any] = {}  # ä¿å­˜åŸå§‹Telegramæ¶ˆæ¯å¯¹è±¡ï¼Œç”¨äºå¼‚æ­¥ä¸‹è½½
    
    async def process_message(self, message, channel_id: str, media_info: Optional[Dict] = None, filtered_content: Optional[str] = None, is_ad: bool = False, is_batch: bool = False) -> Optional[Dict]:
        """
        å¤„ç†æ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä¸å…¶ä»–æ¶ˆæ¯ç»„åˆ
        è¿”å›å®Œæ•´çš„ç»„åˆæ¶ˆæ¯æˆ–Noneï¼ˆå¦‚æœæ¶ˆæ¯è¿˜åœ¨ç­‰å¾…ç»„åˆï¼‰
        
        Args:
            is_batch: æ˜¯å¦ä¸ºæ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆå¦‚å†å²æ¶ˆæ¯é‡‡é›†ï¼‰ï¼Œæ‰¹é‡æ¨¡å¼ä¸‹ä¼šç«‹å³å¤„ç†å®Œæ•´ä¸ªç»„
        """
        try:
            # æå–æ¶ˆæ¯åŸºæœ¬ä¿¡æ¯
            message_data = {
                'message_id': message.id,
                'content': message.text or message.raw_text or "",
                'filtered_content': filtered_content,
                'is_ad': is_ad,
                'media_info': media_info,
                'date': message.date or datetime.now(),
                'grouped_id': str(getattr(message, 'grouped_id', None)) if getattr(message, 'grouped_id', None) else None
            }
            
            # å¦‚æœæ²¡æœ‰grouped_idï¼Œè¯´æ˜æ˜¯ç‹¬ç«‹æ¶ˆæ¯
            if not message_data['grouped_id']:
                return await self._create_single_message(message_data, channel_id)
            
            # æœ‰grouped_idï¼Œéœ€è¦å¤„ç†æ¶ˆæ¯ç»„åˆ
            if is_batch:
                # æ‰¹é‡æ¨¡å¼ï¼Œä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æˆ–ç«‹å³å¤„ç†
                return await self._handle_grouped_message_batch(message_data, channel_id)
            else:
                # å®æ—¶æ¨¡å¼ï¼Œä½¿ç”¨æ­£å¸¸çš„è¶…æ—¶æœºåˆ¶
                return await self._handle_grouped_message(message_data, channel_id)
            
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯ç»„åˆæ—¶å‡ºé”™: {e}")
            # å‡ºé”™æ—¶è¿”å›å•ç‹¬æ¶ˆæ¯
            return await self._create_single_message(message_data if 'message_data' in locals() else {
                'message_id': message.id,
                'content': message.text or "",
                'media_info': media_info,
                'date': message.date or datetime.now(),
                'grouped_id': None
            }, channel_id)
    
    async def _create_single_message(self, message_data: Dict, channel_id: str) -> Dict:
        """åˆ›å»ºå•ç‹¬æ¶ˆæ¯"""
        # å¦‚æœæœ‰åª’ä½“ä¿¡æ¯ï¼Œä¿å­˜æœ¬åœ°æ–‡ä»¶è·¯å¾„
        media_url = None
        if message_data.get('media_info'):
            media_url = message_data['media_info']['file_path']
        
        return {
            'message_id': message_data['message_id'],
            'content': message_data['content'],
            'media_type': message_data['media_info']['media_type'] if message_data.get('media_info') else None,
            'media_url': media_url,
            'grouped_id': str(message_data.get('grouped_id')) if message_data.get('grouped_id') else None,
            'is_combined': False,
            'combined_messages': None,
            'media_group': None,
            'date': message_data['date']
        }
    
    async def _handle_grouped_message_batch(self, message_data: Dict, channel_id: str) -> Optional[Dict]:
        """æ‰¹é‡æ¨¡å¼ä¸‹å¤„ç†ç»„åˆæ¶ˆæ¯ï¼ˆç”¨äºå†å²æ¶ˆæ¯é‡‡é›†ï¼‰"""
        grouped_id = str(message_data['grouped_id']) if message_data.get('grouped_id') else None
        if not grouped_id:
            return await self._create_single_message(message_data, channel_id)
            
        group_key = f"{channel_id}_{grouped_id}"
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªæ¶ˆæ¯ç»„
        existing_combined = await self._get_existing_combined_message(channel_id, grouped_id)
        if existing_combined:
            logger.debug(f"æ¶ˆæ¯ç»„ {grouped_id} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
            return None
        
        # å°†æ¶ˆæ¯æ·»åŠ åˆ°å¾…å¤„ç†ç»„
        if group_key not in self.pending_groups:
            self.pending_groups[group_key] = []
            # æ‰¹é‡æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨ç»Ÿä¸€çš„è¶…æ—¶æ—¶é—´
            asyncio.create_task(self._process_batch_group_after_timeout(group_key, channel_id, self.group_timeout))
        
        self.pending_groups[group_key].append(message_data)
        logger.debug(f"æ‰¹é‡æ¨¡å¼ï¼šæ¶ˆæ¯ç»„ {grouped_id} å½“å‰æœ‰ {len(self.pending_groups[group_key])} æ¡æ¶ˆæ¯")
        
        # æ‰¹é‡æ¨¡å¼ä¸‹è¿”å›Noneï¼Œç­‰å¾…è¶…æ—¶åå¤„ç†
        return None
    
    async def _process_batch_group_after_timeout(self, group_key: str, channel_id: str, timeout: float):
        """æ‰¹é‡æ¨¡å¼ä¸‹çš„è¶…æ—¶å¤„ç†"""
        try:
            await asyncio.sleep(timeout)
            
            if group_key not in self.pending_groups:
                return
            
            messages = self.pending_groups[group_key]
            if not messages:
                return
            
            logger.info(f"æ‰¹é‡å¤„ç†æ¶ˆæ¯ç»„ {group_key}ï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯")
            
            # åˆ›å»ºç»„åˆæ¶ˆæ¯
            combined_message = await self._create_combined_message(messages, channel_id)
            
            # ä¿å­˜ç»„åˆæ¶ˆæ¯åˆ°æ•°æ®åº“
            await self._save_combined_message(combined_message, channel_id)
            
            # æ¸…ç†
            del self.pending_groups[group_key]
                
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†æ¶ˆæ¯ç»„ {group_key} æ—¶å‡ºé”™: {e}")
    
    async def _handle_grouped_message(self, message_data: Dict, channel_id: str) -> Optional[Dict]:
        """å¤„ç†ç»„åˆæ¶ˆæ¯"""
        grouped_id = str(message_data['grouped_id']) if message_data.get('grouped_id') else None
        if not grouped_id:
            return await self._create_single_message(message_data, channel_id)
            
        group_key = f"{channel_id}_{grouped_id}"
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªæ¶ˆæ¯ç»„
        existing_combined = await self._get_existing_combined_message(channel_id, grouped_id)
        if existing_combined:
            logger.info(f"æ¶ˆæ¯ç»„ {grouped_id} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
            return None
        
        # æ£€æŸ¥è¿™æ¡æ¶ˆæ¯æ˜¯å¦å·²ç»è¢«ä½œä¸ºå•ç‹¬æ¶ˆæ¯ä¿å­˜è¿‡
        existing_single = await self._get_existing_single_message(channel_id, message_data['message_id'])
        if existing_single:
            logger.info(f"æ¶ˆæ¯ {message_data['message_id']} å·²ä½œä¸ºå•ç‹¬æ¶ˆæ¯å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
            return None
        
        # å°†æ¶ˆæ¯æ·»åŠ åˆ°å¾…å¤„ç†ç»„
        if group_key not in self.pending_groups:
            self.pending_groups[group_key] = []
        
        self.pending_groups[group_key].append(message_data)
        
        # å–æ¶ˆä¹‹å‰çš„å®šæ—¶å™¨
        if group_key in self.group_timers:
            self.group_timers[group_key].cancel()
        
        # è®¾ç½®æ–°çš„å®šæ—¶å™¨
        self.group_timers[group_key] = asyncio.create_task(
            self._process_group_after_timeout(group_key, channel_id)
        )
        
        logger.info(f"æ¶ˆæ¯ç»„ {grouped_id} å½“å‰æœ‰ {len(self.pending_groups[group_key])} æ¡æ¶ˆæ¯")
        
        # æš‚æ—¶è¿”å›Noneï¼Œç­‰å¾…è¶…æ—¶åå¤„ç†
        return None
    
    async def _process_group_after_timeout(self, group_key: str, channel_id: str):
        """è¶…æ—¶åå¤„ç†æ¶ˆæ¯ç»„"""
        try:
            await asyncio.sleep(self.group_timeout)
            
            if group_key not in self.pending_groups:
                return
            
            messages = self.pending_groups[group_key]
            if not messages:
                return
            
            logger.info(f"å¤„ç†æ¶ˆæ¯ç»„ {group_key}ï¼Œå…± {len(messages)} æ¡æ¶ˆæ¯")
            
            # åˆ›å»ºç»„åˆæ¶ˆæ¯
            combined_message = await self._create_combined_message(messages, channel_id)
            
            # ä¿å­˜ç»„åˆæ¶ˆæ¯åˆ°æ•°æ®åº“
            await self._save_combined_message(combined_message, channel_id)
            
            # æ¸…ç†
            del self.pending_groups[group_key]
            if group_key in self.group_timers:
                del self.group_timers[group_key]
                
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯ç»„è¶…æ—¶æ—¶å‡ºé”™: {e}")
            # æ¸…ç†èµ„æº
            if group_key in self.pending_groups:
                del self.pending_groups[group_key]
            if group_key in self.group_timers:
                del self.group_timers[group_key]
    
    async def _create_combined_message(self, messages: List[Dict], channel_id: str) -> Dict:
        """åˆ›å»ºç»„åˆæ¶ˆæ¯"""
        # æŒ‰æ—¶é—´æ’åº
        messages.sort(key=lambda x: x['date'])
        
        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨è¿‡æ»¤åçš„å†…å®¹ï¼‰
        all_texts = []
        all_filtered_texts = []
        is_ad = False
        
        for msg in messages:
            content = msg.get('content') or ''
            filtered_content = msg.get('filtered_content')
            
            # å§‹ç»ˆä¿å­˜åŸå§‹å†…å®¹
            if content.strip():
                all_texts.append(content)
            
            # å¦‚æœæœ‰è¿‡æ»¤åçš„å†…å®¹ï¼Œä½¿ç”¨è¿‡æ»¤åçš„ï¼›å¦åˆ™ä½¿ç”¨åŸå§‹å†…å®¹
            if filtered_content and filtered_content.strip():
                all_filtered_texts.append(filtered_content)
            elif content.strip():
                all_filtered_texts.append(content)
            
            # å¦‚æœç»„å†…ä»»ä½•ä¸€æ¡æ¶ˆæ¯è¢«åˆ¤å®šä¸ºå¹¿å‘Šï¼Œæ•´ç»„éƒ½æ ‡è®°ä¸ºå¹¿å‘Š
            if msg.get('is_ad'):
                is_ad = True
                logger.info(f"ğŸš« æ¶ˆæ¯ç»„ä¸­æ£€æµ‹åˆ°å¹¿å‘Šï¼Œæ•´ç»„æ ‡è®°ä¸ºå¹¿å‘Š")
        
        combined_content = '\n'.join(all_texts) if all_texts else ""
        combined_filtered_content = '\n'.join(all_filtered_texts) if all_filtered_texts else ""
        
        # æå–æ‰€æœ‰åª’ä½“ä¿¡æ¯
        media_group = []
        media_types = set()
        
        for msg in messages:
            if msg.get('media_info'):
                media_info = msg['media_info']
                media_group.append({
                    'message_id': msg['message_id'],
                    'media_type': media_info['media_type'],
                    'file_path': media_info.get('file_path'),  # å¯èƒ½ä¸ºNoneï¼ˆä¸‹è½½å¤±è´¥ï¼‰
                    'file_size': media_info.get('file_size'),
                    'mime_type': media_info.get('mime_type'),
                    'download_failed': media_info.get('download_failed', False),
                    'error': media_info.get('error')
                })
                # åªæœ‰æˆåŠŸä¸‹è½½çš„åª’ä½“æ‰è®¡å…¥ç±»å‹ç»Ÿè®¡
                if not media_info.get('download_failed'):
                    media_types.add(media_info['media_type'])
        
        # ç¡®å®šä¸»è¦åª’ä½“ç±»å‹
        if len(media_types) == 1:
            main_media_type = list(media_types)[0]
        elif 'photo' in media_types:
            main_media_type = 'photo'
        elif 'video' in media_types:
            main_media_type = 'video'
        else:
            main_media_type = 'mixed'
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¶ˆæ¯çš„ä¿¡æ¯ä½œä¸ºä¸»æ¶ˆæ¯
        first_message = messages[0]
        
        # ä¸ºç»„åˆæ¶ˆæ¯ä¿å­˜ä¸»åª’ä½“æ–‡ä»¶è·¯å¾„
        main_media_url = None
        if media_group:
            main_media_url = media_group[0]['file_path']
        
        return {
            'message_id': first_message['message_id'],
            'content': combined_content,
            'filtered_content': combined_filtered_content,
            'is_ad': is_ad,
            'media_type': main_media_type if media_group else None,
            'media_url': main_media_url,
            'grouped_id': str(first_message['grouped_id']) if first_message.get('grouped_id') else None,
            'is_combined': True,
            'combined_messages': [
                {
                    'message_id': msg['message_id'],
                    'content': msg['content'],
                    'media_info': msg.get('media_info')
                }
                for msg in messages
            ],
            'media_group': media_group if media_group else None,
            'date': first_message['date']
        }
    
    async def _save_combined_message(self, combined_message: Dict, channel_id: str):
        """ä¿å­˜ç»„åˆæ¶ˆæ¯åˆ°æ•°æ®åº“"""
        try:
            # è¿™é‡Œåªåˆ›å»ºæ¶ˆæ¯æ•°æ®ï¼Œå®é™…ä¿å­˜ç”±è°ƒç”¨æ–¹å¤„ç†
            # å› ä¸ºéœ€è¦é…åˆç°æœ‰çš„è¿‡æ»¤å’Œå®¡æ ¸æµç¨‹
            
            # è§¦å‘ç»„åˆæ¶ˆæ¯å¤„ç†äº‹ä»¶
            await self._trigger_combined_message_event(combined_message, channel_id)
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»„åˆæ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def _trigger_combined_message_event(self, combined_message: Dict, channel_id: str):
        """è§¦å‘ç»„åˆæ¶ˆæ¯å¤„ç†äº‹ä»¶"""
        try:
            # å¯¼å…¥å¹¶è°ƒç”¨æ¶ˆæ¯å¤„ç†å™¨
            from app.services.message_processor import MessageProcessor
            import json
            from datetime import datetime
            
            processor = MessageProcessor()
            
            # ä½¿ç”¨å·²ç»è¿‡æ»¤çš„å†…å®¹ï¼ˆåœ¨åˆ›å»ºç»„åˆæ¶ˆæ¯æ—¶å·²ç»å¤„ç†ï¼‰
            is_ad = combined_message.get('is_ad', False)
            filtered_content = combined_message.get('filtered_content', combined_message['content'])
            
            # é¦–å…ˆåˆ é™¤å·²ç»å•ç‹¬ä¿å­˜çš„ç»„å†…æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            await self._cleanup_individual_messages(channel_id, combined_message)
            
            # å¤„ç†JSONåºåˆ—åŒ– - æ¸…ç†åŒ…å«datetimeçš„å¯¹è±¡
            def serialize_for_json(obj):
                """é€’å½’å¤„ç†å¯¹è±¡ï¼Œå°†datetimeè½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                if isinstance(obj, datetime):
                    return obj.isoformat()
                elif isinstance(obj, dict):
                    return {k: serialize_for_json(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [serialize_for_json(item) for item in obj]
                else:
                    return obj
            
            # æ¸…ç†combined_messageså’Œmedia_groupä¸­çš„datetimeå¯¹è±¡
            clean_combined_messages = serialize_for_json(combined_message.get('combined_messages'))
            clean_media_group = serialize_for_json(combined_message.get('media_group'))
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            async with AsyncSessionLocal() as db:
                db_message = Message(
                    source_channel=channel_id,
                    message_id=combined_message['message_id'],
                    content=combined_message['content'],
                    media_type=combined_message['media_type'],
                    media_url=combined_message['media_url'],
                    grouped_id=str(combined_message['grouped_id']) if combined_message.get('grouped_id') else None,
                    is_combined=combined_message['is_combined'],
                    combined_messages=clean_combined_messages,
                    media_group=clean_media_group,
                    is_ad=is_ad,
                    filtered_content=filtered_content,
                    created_at=datetime.now()  # ä½¿ç”¨å½“å‰æ—¶é—´ï¼Œé¿å…æ—¶åŒºé—®é¢˜
                )
                db.add(db_message)
                await db.commit()
                await db.refresh(db_message)
                
                logger.info(f"ç»„åˆæ¶ˆæ¯å·²ä¿å­˜: ID={db_message.id}, grouped_id={combined_message['grouped_id']}, åŒ…å« {len(combined_message.get('combined_messages', []))} æ¡æ¶ˆæ¯")
                
                # åª’ä½“å·²ç»åŒæ­¥ä¸‹è½½å®Œæˆï¼Œæ— éœ€é¢å¤–å¤„ç†
                
                # è½¬å‘åˆ°å®¡æ ¸ç¾¤ï¼ˆå»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¼•ç”¨ï¼‰
                try:
                    from app.telegram.bot import telegram_bot
                    if telegram_bot and hasattr(telegram_bot, 'forward_to_review'):
                        await telegram_bot.forward_to_review(db_message)
                        
                    # å¹¿æ’­æ–°æ¶ˆæ¯åˆ°WebSocketå®¢æˆ·ç«¯
                    if telegram_bot and hasattr(telegram_bot, '_broadcast_new_message'):
                        await telegram_bot._broadcast_new_message(db_message)
                        
                except ImportError:
                    logger.warning("æ— æ³•å¯¼å…¥telegram_botï¼Œè·³è¿‡è½¬å‘åˆ°å®¡æ ¸ç¾¤å’ŒWebSocketå¹¿æ’­")
                
        except Exception as e:
            logger.error(f"è§¦å‘ç»„åˆæ¶ˆæ¯äº‹ä»¶æ—¶å‡ºé”™: {e}")
    
    async def _get_existing_combined_message(self, channel_id: str, grouped_id: str) -> Optional[Message]:
        """æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç»„åˆæ¶ˆæ¯"""
        try:
            async with AsyncSessionLocal() as db:
                result = await db.execute(
                    select(Message).where(
                        Message.source_channel == channel_id,
                        Message.grouped_id == grouped_id,
                        Message.is_combined == True
                    )
                )
                return result.scalar_one_or_none()
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç°æœ‰ç»„åˆæ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return None
    
    async def _get_existing_single_message(self, channel_id: str, message_id: int) -> Optional[Message]:
        """æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å•ç‹¬æ¶ˆæ¯"""
        try:
            async with AsyncSessionLocal() as db:
                result = await db.execute(
                    select(Message).where(
                        Message.source_channel == channel_id,
                        Message.message_id == message_id
                    )
                )
                return result.scalar_one_or_none()
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç°æœ‰å•ç‹¬æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return None
    
    async def _cleanup_individual_messages(self, channel_id: str, combined_message: Dict):
        """æ¸…ç†å·²ç»è¢«ç»„åˆçš„å•ç‹¬æ¶ˆæ¯"""
        try:
            if not combined_message.get('combined_messages'):
                return
            
            async with AsyncSessionLocal() as db:
                # è·å–æ‰€æœ‰ç›¸å…³çš„å•ç‹¬æ¶ˆæ¯ID
                message_ids = [msg['message_id'] for msg in combined_message['combined_messages']]
                
                # æŸ¥æ‰¾å¹¶åˆ é™¤è¿™äº›å•ç‹¬æ¶ˆæ¯
                result = await db.execute(
                    select(Message).where(
                        Message.source_channel == channel_id,
                        Message.message_id.in_(message_ids),
                        Message.is_combined == False  # åªåˆ é™¤å•ç‹¬æ¶ˆæ¯ï¼Œä¸åˆ é™¤ç»„åˆæ¶ˆæ¯
                    )
                )
                
                messages_to_delete = result.scalars().all()
                
                if messages_to_delete:
                    for msg in messages_to_delete:
                        logger.info(f"åˆ é™¤å·²è¢«ç»„åˆçš„å•ç‹¬æ¶ˆæ¯: ID={msg.id}, message_id={msg.message_id}")
                        await db.delete(msg)
                    
                    await db.commit()
                    logger.info(f"å·²æ¸…ç† {len(messages_to_delete)} æ¡è¢«ç»„åˆçš„å•ç‹¬æ¶ˆæ¯")
                
        except Exception as e:
            logger.error(f"æ¸…ç†å•ç‹¬æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    async def cleanup_expired_groups(self):
        """æ¸…ç†è¿‡æœŸçš„æ¶ˆæ¯ç»„"""
        try:
            expired_keys = []
            current_time = datetime.now()
            
            for group_key, messages in self.pending_groups.items():
                if not messages:
                    expired_keys.append(group_key)
                    continue
                
                # æ£€æŸ¥æœ€æ—§æ¶ˆæ¯çš„æ—¶é—´
                oldest_time = min(msg['date'] for msg in messages)
                if current_time - oldest_time > timedelta(minutes=5):  # 5åˆ†é’Ÿè¶…æ—¶
                    expired_keys.append(group_key)
            
            for key in expired_keys:
                if key in self.pending_groups:
                    del self.pending_groups[key]
                if key in self.group_timers:
                    self.group_timers[key].cancel()
                    del self.group_timers[key]
                    
            if expired_keys:
                logger.info(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸæ¶ˆæ¯ç»„")
                
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸæ¶ˆæ¯ç»„æ—¶å‡ºé”™: {e}")

# å…¨å±€æ¶ˆæ¯ç»„åˆå™¨å®ä¾‹
message_grouper = MessageGrouper()