"""
æ··åˆæ™ºèƒ½åˆ¤æ–­çš„å°¾éƒ¨è¿‡æ»¤å™¨
ç»“åˆè¯­ä¹‰ã€ç»“æ„ã€ä½ç½®å’Œç›¸å…³æ€§å¤šä¸ªç»´åº¦è¿›è¡Œç»¼åˆåˆ¤æ–­
"""

import re
import logging
from typing import Dict, Tuple, Optional, List

from app.services.semantic_tail_filter import SemanticTailFilter
from app.services.intelligent_tail_filter import intelligent_tail_filter

logger = logging.getLogger(__name__)


class HybridTailFilter:
    """æ··åˆæ™ºèƒ½åˆ¤æ–­çš„å°¾éƒ¨è¿‡æ»¤å™¨"""
    
    def __init__(self):
        self.semantic_filter = SemanticTailFilter()
        self.structural_filter = intelligent_tail_filter
        self.threshold = 0.6  # ç»¼åˆå¾—åˆ†é˜ˆå€¼
        self.max_tail_ratio = 0.5  # å°¾éƒ¨æœ€å¤§å æ¯”ï¼ˆæé«˜åˆ°50%ï¼‰
        self.min_tail_length = 20  # æœ€å°å°¾éƒ¨é•¿åº¦
    
    def filter_message(self, content: str) -> Tuple[str, bool, Optional[str]]:
        """
        ç»¼åˆå¤šç»´åº¦åˆ¤æ–­å¹¶è¿‡æ»¤æ¶ˆæ¯å°¾éƒ¨
        
        Args:
            content: å®Œæ•´æ¶ˆæ¯å†…å®¹
            
        Returns:
            (è¿‡æ»¤åå†…å®¹, æ˜¯å¦æœ‰å°¾éƒ¨, å°¾éƒ¨å†…å®¹)
        """
        if not content or len(content) < 30:  # é™ä½æœ€å°é•¿åº¦è¦æ±‚
            return content, False, None
        
        lines = content.split('\n')
        if len(lines) < 2:
            return content, False, None
        
        best_score = 0
        best_split = len(lines)
        best_tail = None
        
        # ç­–ç•¥1ï¼šå…ˆæŸ¥æ‰¾æ˜æ˜¾çš„åˆ†éš”ç¬¦
        separator_line = self._find_separator_line(lines)
        if separator_line != -1:
            tail_candidate = '\n'.join(lines[separator_line:])
            if len(tail_candidate) >= self.min_tail_length:
                scores = self.calculate_scores(tail_candidate, content, separator_line, lines)
                final_score = self.weighted_score(scores)
                logger.debug(f"åˆ†éš”ç¬¦ä½ç½® {separator_line}, å¾—åˆ†: {final_score:.3f}")
                
                if final_score > self.threshold:
                    best_score = final_score
                    best_split = separator_line
                    best_tail = tail_candidate
        
        # ç­–ç•¥2ï¼šæ™ºèƒ½æ‰«æï¼ˆä»åå‘å‰ï¼‰
        scan_start = len(lines) - 1
        scan_end = max(0, len(lines) - 15)  # æœ€å¤šæ‰«æ15è¡Œ
        
        for i in range(scan_start, scan_end, -1):
            tail_candidate = '\n'.join(lines[i:])
            
            # è·³è¿‡å¤ªçŸ­çš„å†…å®¹
            if len(tail_candidate) < self.min_tail_length:
                continue
            
            # å¿«é€Ÿé¢„æ£€ï¼šå¦‚æœæ²¡æœ‰ä»»ä½•æ¨å¹¿ç‰¹å¾ï¼Œè·³è¿‡
            if not self._has_promo_features(tail_candidate):
                continue
            
            # è®¡ç®—å››ä¸ªç»´åº¦çš„å¾—åˆ†
            scores = self.calculate_scores(tail_candidate, content, i, lines)
            
            # ç»¼åˆå¾—åˆ†
            final_score = self.weighted_score(scores)
            
            logger.debug(f"ä½ç½® {i}/{len(lines)}, ç»¼åˆå¾—åˆ†: {final_score:.3f}, "
                        f"è¯­ä¹‰: {scores.get('semantic', 0):.2f}, "
                        f"ç»“æ„: {scores.get('structural', 0):.2f}, "
                        f"ä½ç½®: {scores.get('position', 0):.2f}, "
                        f"ç›¸å…³æ€§: {scores.get('relevance', 0):.2f}")
            
            if final_score > best_score and final_score > self.threshold:
                best_score = final_score
                best_split = i
                best_tail = tail_candidate
                
                # å¦‚æœå¾—åˆ†å¾ˆé«˜ï¼Œæå‰ç»“æŸ
                if final_score > 0.85:
                    logger.debug(f"æ‰¾åˆ°é«˜ç½®ä¿¡åº¦å°¾éƒ¨ï¼Œå¾—åˆ†: {final_score:.3f}")
                    break
        
        # å®‰å…¨æ£€æŸ¥ï¼šå°¾éƒ¨ä¸èƒ½è¶…è¿‡å…¨æ–‡çš„æŒ‡å®šæ¯”ä¾‹
        if best_tail:
            tail_ratio = len(best_tail) / len(content)
            if tail_ratio > self.max_tail_ratio:
                logger.debug(f"å°¾éƒ¨å æ¯”è¿‡å¤§: {tail_ratio:.2%}ï¼Œå–æ¶ˆè¿‡æ»¤")
                return content, False, None
            
            clean_content = '\n'.join(lines[:best_split]).rstrip()
            
            # ç¡®ä¿å‰©ä½™å†…å®¹æœ‰æ„ä¹‰
            if len(clean_content) < 30:  # é™ä½æœ€å°å‰©ä½™å†…å®¹è¦æ±‚
                logger.debug(f"è¿‡æ»¤åå†…å®¹å¤ªçŸ­: {len(clean_content)} å­—ç¬¦")
                return content, False, None
            
            logger.info(f"æˆåŠŸè¿‡æ»¤å°¾éƒ¨ï¼Œå¾—åˆ†: {best_score:.3f}, "
                       f"ç§»é™¤ {len(best_tail)} å­—ç¬¦")
            return clean_content, True, best_tail
        
        return content, False, None
    
    def calculate_scores(self, tail: str, full_content: str, position: int, lines: List[str]) -> Dict[str, float]:
        """
        è®¡ç®—å››ä¸ªç»´åº¦çš„å¾—åˆ†
        
        Args:
            tail: å°¾éƒ¨å€™é€‰å†…å®¹
            full_content: å®Œæ•´å†…å®¹
            position: å°¾éƒ¨èµ·å§‹ä½ç½®ï¼ˆè¡Œå·ï¼‰
            lines: æ‰€æœ‰è¡Œçš„åˆ—è¡¨
            
        Returns:
            å„ç»´åº¦å¾—åˆ†å­—å…¸
        """
        scores = {}
        
        # 1. è¯­ä¹‰å¾—åˆ†ï¼ˆ0-1ï¼‰
        scores['semantic'] = self.semantic_filter.calculate_semantic_score(tail, full_content)
        
        # 2. ç»“æ„å¾—åˆ†ï¼ˆ0-1ï¼‰
        structural_features = self.structural_filter.feature_extractor.extract_features(tail)
        scores['structural'] = self.structural_filter._calculate_feature_score(structural_features)
        
        # 3. ä½ç½®å¾—åˆ†ï¼ˆ0-1ï¼‰- è¶Šé åè¶Šå¯èƒ½æ˜¯å°¾éƒ¨
        # ä½¿ç”¨éçº¿æ€§å‡½æ•°ï¼Œè®©é åçš„ä½ç½®å¾—åˆ†æ›´é«˜
        relative_position = (len(lines) - position) / min(15, len(lines))
        scores['position'] = min(1.0, relative_position ** 0.7)  # å¹³æ–¹æ ¹å‡½æ•°ï¼Œä½¿å¾—åˆ†å¸ƒæ›´å¹³æ»‘
        
        # 4. ç›¸å…³æ€§å¾—åˆ†ï¼ˆ0-1ï¼‰- ä¸æ­£æ–‡ç›¸å…³æ€§è¶Šä½è¶Šå¯èƒ½æ˜¯å°¾éƒ¨
        relevance = self.semantic_filter.calculate_relevance(tail, full_content)
        scores['relevance'] = 1 - relevance
        
        return scores
    
    def weighted_score(self, scores: Dict[str, float]) -> float:
        """
        è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†
        
        Args:
            scores: å„ç»´åº¦å¾—åˆ†
            
        Returns:
            ç»¼åˆå¾—åˆ†ï¼ˆ0-1ï¼‰
        """
        # åŠ¨æ€æƒé‡ï¼šæ ¹æ®å„ç»´åº¦çš„å¾—åˆ†æƒ…å†µè°ƒæ•´æƒé‡
        semantic_score = scores.get('semantic', 0)
        structural_score = scores.get('structural', 0)
        
        # å¦‚æœè¯­ä¹‰å¾—åˆ†å¾ˆé«˜ï¼Œå¢åŠ å…¶æƒé‡
        if semantic_score > 0.7:
            weights = {
                'semantic': 0.45,     # è¯­ä¹‰å¾ˆå¼ºæ—¶æƒé‡æ›´é«˜
                'structural': 0.20,
                'relevance': 0.25,
                'position': 0.10
            }
        # å¦‚æœç»“æ„å¾—åˆ†å¾ˆé«˜ï¼Œå¹³è¡¡æƒé‡
        elif structural_score > 0.7:
            weights = {
                'semantic': 0.30,
                'structural': 0.35,   # ç»“æ„ç‰¹å¾æ˜æ˜¾
                'relevance': 0.20,
                'position': 0.15
            }
        # é»˜è®¤æƒé‡
        else:
            weights = {
                'semantic': 0.35,     # è¯­ä¹‰æœ€é‡è¦
                'structural': 0.25,   # ç»“æ„ç‰¹å¾
                'relevance': 0.25,    # ç›¸å…³æ€§
                'position': 0.15      # ä½ç½®
            }
        
        total = sum(scores.get(key, 0) * weight for key, weight in weights.items())
        return min(1.0, total)  # ç¡®ä¿ä¸è¶…è¿‡1
    
    def _find_separator_line(self, lines: List[str]) -> int:
        """
        æŸ¥æ‰¾æ˜æ˜¾çš„åˆ†éš”ç¬¦è¡Œ
        
        Args:
            lines: æ–‡æœ¬è¡Œåˆ—è¡¨
            
        Returns:
            åˆ†éš”ç¬¦æ‰€åœ¨è¡Œå·ï¼Œæœªæ‰¾åˆ°è¿”å›-1
        """
        separator_patterns = [
            r'^[-=*#_~â€”]{3,}$',  # å¸¸è§åˆ†éš”ç¬¦
            r'^[â”€â”â•]+$',  # ä¸­æ–‡åˆ†éš”çº¿
            r'^\s*[ğŸ“£ğŸ””ğŸ˜ğŸ‘ŒğŸ’¬ğŸ”—ğŸ“¢]{3,}\s*$',  # emojiåˆ†éš”
            r'^\.{3,}$',  # çœç•¥å·åˆ†éš”
        ]
        
        # ä»åå‘å‰æŸ¥æ‰¾ï¼Œä½†ä¸æŸ¥æ‰¾æœ€å20%çš„å†…å®¹ï¼ˆé¿å…æ‰¾åˆ°åº•éƒ¨è£…é¥°ï¼‰
        search_end = max(len(lines) // 2, len(lines) - 20)
        
        for i in range(len(lines) - 1, search_end, -1):
            line = lines[i].strip()
            for pattern in separator_patterns:
                if re.match(pattern, line):
                    logger.debug(f"æ‰¾åˆ°åˆ†éš”ç¬¦åœ¨ç¬¬ {i} è¡Œ: {line[:30]}")
                    return i
        
        return -1
    
    def _has_promo_features(self, text: str) -> bool:
        """
        å¿«é€Ÿæ£€æŸ¥æ˜¯å¦åŒ…å«æ¨å¹¿ç‰¹å¾
        
        Args:
            text: å¾…æ£€æŸ¥æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ…å«æ¨å¹¿ç‰¹å¾
        """
        # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬çš„æ¨å¹¿å…ƒç´ 
        promo_indicators = [
            '@',  # Telegramç”¨æˆ·å
            't.me/',  # Telegramé“¾æ¥
            'http',  # ç½‘å€
            'è®¢é˜…', 'åŠ å…¥', 'æŠ•ç¨¿', 'è”ç³»',  # å¸¸è§æ¨å¹¿è¯
            'é¢‘é“', 'ç¾¤ç»„', 'å®¢æœ', 'å•†åŠ¡',  # é¢‘é“ç›¸å…³
            'ğŸ””', 'ğŸ“£', 'â˜ï¸', 'ğŸ’¬'  # å¸¸è§æ¨å¹¿emoji
        ]
        
        return any(indicator in text for indicator in promo_indicators)
    
    def get_filter_stats(self) -> Dict:
        """è·å–è¿‡æ»¤å™¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'threshold': self.threshold,
            'max_tail_ratio': self.max_tail_ratio,
            'min_tail_length': self.min_tail_length,
            'structural_samples': self.structural_filter.get_statistics()['total_samples'],
            'learned_keywords': self.structural_filter.get_statistics()['learned_keywords']
        }
        return stats


# åˆ›å»ºå…¨å±€å®ä¾‹
hybrid_tail_filter = HybridTailFilter()