#!/usr/bin/env python3
"""
æ‰¹é‡é‡æ–°å¤„ç†æœªå®¡æ ¸æ¶ˆæ¯
ä½¿ç”¨è®­ç»ƒå¥½çš„å°¾éƒ¨è¿‡æ»¤å’Œå¹¿å‘Šæ£€æµ‹æ¨¡å‹
"""
import asyncio
import sys
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Tuple, List, Dict, Any

from sqlalchemy import select, and_, or_, func
from app.core.database import AsyncSessionLocal, Message
from app.services.content_filter import ContentFilter
from app.services.ad_detector import AdDetector
from app.core.training_config import TrainingDataConfig
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MessageReprocessor:
    """æ¶ˆæ¯æ‰¹é‡é‡å¤„ç†å™¨"""
    
    def __init__(self):
        self.content_filter = ContentFilter()
        self.ad_detector = AdDetector()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'tail_filtered': 0,
            'ad_detected': 0,
            'both_filtered': 0,
            'unchanged': 0,
            'errors': 0,
            'total_chars_removed': 0,
            'processing_time': 0
        }
        
        # è¯¦ç»†è®°å½•
        self.details = []
        self.error_messages = []
        
    async def process_message(self, message: Message) -> Dict[str, Any]:
        """å¤„ç†å•æ¡æ¶ˆæ¯"""
        start_time = time.time()
        result = {
            'id': message.id,
            'channel_id': message.source_channel,
            'original_length': len(message.content or ''),
            'filtered_length': 0,
            'tail_filtered': False,
            'chars_removed': 0,
            'is_ad': False,
            'ad_confidence': 0.0,
            'error': None,
            'processing_time': 0
        }
        
        try:
            if not message.content:
                result['error'] = 'æ¶ˆæ¯å†…å®¹ä¸ºç©º'
                return result
            
            original_content = message.content
            original_length = len(original_content)
            
            # 1. åº”ç”¨å°¾éƒ¨è¿‡æ»¤ï¼ˆè¿‡æ»¤é¢‘é“æ¨å¹¿ä¿¡æ¯ï¼‰
            filtered_content = self.content_filter.filter_promotional_content(
                original_content, 
                channel_id=str(message.source_channel) if message.source_channel else None
            )
            
            # æ£€æŸ¥æ˜¯å¦è¿›è¡Œäº†å°¾éƒ¨è¿‡æ»¤
            tail_filtered = len(filtered_content) < original_length
            chars_removed = original_length - len(filtered_content)
            
            result['tail_filtered'] = tail_filtered
            result['chars_removed'] = chars_removed
            
            # 2. å¹¿å‘Šæ£€æµ‹ï¼ˆä½¿ç”¨è¿‡æ»¤åçš„å†…å®¹ï¼‰
            is_ad, confidence = self.ad_detector.is_advertisement_ai(filtered_content)
            result['is_ad'] = is_ad
            result['ad_confidence'] = confidence
            
            # 3. æ›´æ–°æ¶ˆæ¯
            message.filtered_content = filtered_content
            message.is_ad = is_ad
            
            result['filtered_length'] = len(filtered_content)
            
            # æ›´æ–°ç»Ÿè®¡
            if tail_filtered:
                self.stats['tail_filtered'] += 1
                self.stats['total_chars_removed'] += chars_removed
            if is_ad:
                self.stats['ad_detected'] += 1
            if tail_filtered and is_ad:
                self.stats['both_filtered'] += 1
            if not tail_filtered and not is_ad:
                self.stats['unchanged'] += 1
                
        except Exception as e:
            result['error'] = str(e)
            self.stats['errors'] += 1
            self.error_messages.append({
                'message_id': message.id,
                'error': str(e)
            })
            logger.error(f"å¤„ç†æ¶ˆæ¯ {message.id} æ—¶å‡ºé”™: {e}")
            
        result['processing_time'] = time.time() - start_time
        self.stats['processing_time'] += result['processing_time']
        
        return result
    
    async def process_batch(self, db, messages: List[Message], batch_num: int, total_batches: int):
        """å¤„ç†ä¸€æ‰¹æ¶ˆæ¯"""
        print(f"\nå¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(messages)} æ¡æ¶ˆæ¯)...")
        
        batch_start = time.time()
        batch_results = []
        
        for i, message in enumerate(messages):
            # æ˜¾ç¤ºè¿›åº¦
            if i % 10 == 0:
                progress = i * 100 / len(messages)
                elapsed = time.time() - batch_start
                speed = i / elapsed if elapsed > 0 else 0
                print(f"  è¿›åº¦: {i}/{len(messages)} ({progress:.1f}%) - é€Ÿåº¦: {speed:.1f} æ¡/ç§’", end='\r')
            
            result = await self.process_message(message)
            batch_results.append(result)
            self.details.append(result)
            self.stats['total_processed'] += 1
            
            # å¯é€‰ï¼šæ·»åŠ å°å»¶è¿Ÿæ¨¡æ‹Ÿå®æ—¶å¤„ç†
            # await asyncio.sleep(0.01)
        
        # æäº¤æ•°æ®åº“æ›´æ”¹
        try:
            await db.commit()
            print(f"\n  âœ“ æ‰¹æ¬¡ {batch_num} å®Œæˆ - è€—æ—¶: {time.time() - batch_start:.2f}ç§’")
        except Exception as e:
            logger.error(f"æäº¤æ‰¹æ¬¡ {batch_num} æ—¶å‡ºé”™: {e}")
            await db.rollback()
            print(f"\n  âœ— æ‰¹æ¬¡ {batch_num} æäº¤å¤±è´¥: {e}")
        
        return batch_results
    
    async def run(self, batch_size: int = 100, limit: int = None):
        """æ‰§è¡Œæ‰¹é‡å¤„ç†"""
        print("=" * 70)
        print("æ‰¹é‡é‡æ–°å¤„ç†æœªå®¡æ ¸æ¶ˆæ¯")
        print("=" * 70)
        
        overall_start = time.time()
        
        async with AsyncSessionLocal() as db:
            # æŸ¥è¯¢å¾…å¤„ç†æ¶ˆæ¯æ€»æ•°
            total_query = select(func.count(Message.id)).where(
                and_(
                    Message.status == 'pending',
                    Message.content.isnot(None),
                    Message.content != ''
                )
            )
            total_count = await db.scalar(total_query)
            
            print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
            print(f"  â€¢ å¾…å¤„ç†æ¶ˆæ¯æ€»æ•°: {total_count}")
            
            if limit:
                actual_limit = min(limit, total_count)
                print(f"  â€¢ æœ¬æ¬¡å¤„ç†æ•°é‡: {actual_limit} (é™åˆ¶)")
            else:
                actual_limit = total_count
                print(f"  â€¢ æœ¬æ¬¡å¤„ç†æ•°é‡: {actual_limit}")
            
            if actual_limit == 0:
                print("\næ²¡æœ‰éœ€è¦å¤„ç†çš„æ¶ˆæ¯")
                return
            
            # æŸ¥è¯¢å¾…å¤„ç†æ¶ˆæ¯
            query = select(Message).where(
                and_(
                    Message.status == 'pending',
                    Message.content.isnot(None),
                    Message.content != ''
                )
            ).order_by(Message.id)
            
            if limit:
                query = query.limit(limit)
            
            result = await db.execute(query)
            all_messages = result.scalars().all()
            
            # åˆ†æ‰¹å¤„ç†
            total_batches = (len(all_messages) + batch_size - 1) // batch_size
            print(f"  â€¢ æ‰¹æ¬¡å¤§å°: {batch_size}")
            print(f"  â€¢ æ€»æ‰¹æ¬¡æ•°: {total_batches}")
            print("\nå¼€å§‹å¤„ç†...")
            print("-" * 70)
            
            for batch_num in range(total_batches):
                start_idx = batch_num * batch_size
                end_idx = min(start_idx + batch_size, len(all_messages))
                batch_messages = all_messages[start_idx:end_idx]
                
                await self.process_batch(db, batch_messages, batch_num + 1, total_batches)
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - overall_start
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(total_time)
    
    def generate_report(self, total_time: float):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("å¤„ç†æŠ¥å‘Š")
        print("=" * 70)
        
        if self.stats['total_processed'] == 0:
            print("æ²¡æœ‰å¤„ç†ä»»ä½•æ¶ˆæ¯")
            return
        
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  â€¢ æ€»å¤„ç†æ¶ˆæ¯æ•°: {self.stats['total_processed']:,}")
        print(f"  â€¢ å¤„ç†æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"  â€¢ å¹³å‡å¤„ç†é€Ÿåº¦: {self.stats['total_processed']/total_time:.1f} æ¡/ç§’")
        print(f"  â€¢ å¹³å‡å•æ¡è€—æ—¶: {self.stats['processing_time']/self.stats['total_processed']*1000:.2f} æ¯«ç§’")
        
        print(f"\nğŸ¯ è¿‡æ»¤æ•ˆæœ:")
        tail_pct = self.stats['tail_filtered'] * 100 / self.stats['total_processed']
        ad_pct = self.stats['ad_detected'] * 100 / self.stats['total_processed']
        both_pct = self.stats['both_filtered'] * 100 / self.stats['total_processed']
        unchanged_pct = self.stats['unchanged'] * 100 / self.stats['total_processed']
        
        print(f"  â€¢ å°¾éƒ¨è¿‡æ»¤: {self.stats['tail_filtered']:,} æ¡ ({tail_pct:.1f}%)")
        if self.stats['tail_filtered'] > 0:
            avg_removed = self.stats['total_chars_removed'] / self.stats['tail_filtered']
            print(f"    - å¹³å‡ç§»é™¤å­—ç¬¦: {avg_removed:.0f}")
            print(f"    - æ€»ç§»é™¤å­—ç¬¦: {self.stats['total_chars_removed']:,}")
        
        print(f"  â€¢ å¹¿å‘Šæ£€æµ‹: {self.stats['ad_detected']:,} æ¡ ({ad_pct:.1f}%)")
        print(f"  â€¢ åŒé‡è¿‡æ»¤: {self.stats['both_filtered']:,} æ¡ ({both_pct:.1f}%)")
        print(f"  â€¢ å†…å®¹æœªå˜: {self.stats['unchanged']:,} æ¡ ({unchanged_pct:.1f}%)")
        
        if self.stats['errors'] > 0:
            print(f"\nâš ï¸ é”™è¯¯ç»Ÿè®¡:")
            print(f"  â€¢ å¤„ç†é”™è¯¯: {self.stats['errors']} æ¡")
            if len(self.error_messages) > 0:
                print(f"  â€¢ é”™è¯¯ç¤ºä¾‹:")
                for err in self.error_messages[:5]:
                    print(f"    - æ¶ˆæ¯ {err['message_id']}: {err['error']}")
        
        # æ˜¾ç¤ºä¸€äº›å¤„ç†ç¤ºä¾‹
        print(f"\nğŸ“ å¤„ç†ç¤ºä¾‹:")
        examples = [d for d in self.details if d['tail_filtered'] or d['is_ad']][:5]
        for i, example in enumerate(examples, 1):
            print(f"\n  ç¤ºä¾‹ {i} - æ¶ˆæ¯ID: {example['id']}")
            print(f"    â€¢ åŸå§‹é•¿åº¦: {example['original_length']} å­—ç¬¦")
            print(f"    â€¢ è¿‡æ»¤åé•¿åº¦: {example['filtered_length']} å­—ç¬¦")
            if example['tail_filtered']:
                print(f"    â€¢ å°¾éƒ¨è¿‡æ»¤: ç§»é™¤ {example['chars_removed']} å­—ç¬¦")
            if example['is_ad']:
                print(f"    â€¢ å¹¿å‘Šæ£€æµ‹: æ˜¯ (ç½®ä¿¡åº¦: {example['ad_confidence']:.2f})")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = Path(f"data/reprocess_report_{timestamp}.json")
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'total_time': total_time,
            'stats': self.stats,
            'errors': self.error_messages[:50],  # ä¿å­˜å‰50ä¸ªé”™è¯¯
            'examples': examples[:20]  # ä¿å­˜å‰20ä¸ªç¤ºä¾‹
        }
        
        try:
            report_file.parent.mkdir(exist_ok=True)
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        except Exception as e:
            print(f"\nâš ï¸ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
        
        print("\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print("=" * 70)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡é‡æ–°å¤„ç†æœªå®¡æ ¸æ¶ˆæ¯')
    parser.add_argument('--batch-size', type=int, default=100, help='æ¯æ‰¹å¤„ç†çš„æ¶ˆæ¯æ•°é‡ï¼ˆé»˜è®¤100ï¼‰')
    parser.add_argument('--limit', type=int, help='é™åˆ¶å¤„ç†çš„æ€»æ¶ˆæ¯æ•°')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œåªå¤„ç†10æ¡æ¶ˆæ¯')
    
    args = parser.parse_args()
    
    if args.test:
        args.limit = 10
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†10æ¡æ¶ˆæ¯\n")
    
    processor = MessageReprocessor()
    await processor.run(batch_size=args.batch_size, limit=args.limit)


if __name__ == '__main__':
    asyncio.run(main())