#!/usr/bin/env python3
"""
è®­ç»ƒAIè¿‡æ»¤å™¨
ä»æ•°æ®åº“ä¸­æå–æ•°æ®å¹¶è®­ç»ƒæ™ºèƒ½è¿‡æ»¤æ¨¡å‹
"""
import asyncio
import logging
from sqlalchemy import select, and_, func
from app.core.database import AsyncSessionLocal, Message, Channel
from app.services.ai_filter import ai_filter
from collections import defaultdict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def train_channel_tails():
    """è®­ç»ƒé¢‘é“çš„å°¾éƒ¨æ¨¡å¼ - åŸºäºæ•´ä½“æ•°æ®æ™ºèƒ½é‡‡æ ·"""
    async with AsyncSessionLocal() as db:
        # è·å–æ‰€æœ‰æ¶ˆæ¯ï¼ŒæŒ‰é¢‘é“åˆ†ç»„
        result = await db.execute(
            select(Message).where(
                Message.source_channel.isnot(None)
            ).order_by(Message.created_at.desc()).limit(1000)  # ä»æ•´ä½“æ•°æ®æ± é‡‡æ ·
        )
        all_messages = result.scalars().all()
        
        # æŒ‰é¢‘é“åˆ†ç»„æ¶ˆæ¯
        channel_messages = defaultdict(list)
        for msg in all_messages:
            if msg.source_channel:
                channel_messages[msg.source_channel].append(msg)
        
        logger.info(f"ä» {len(channel_messages)} ä¸ªé¢‘é“æ”¶é›†åˆ° {len(all_messages)} æ¡æ¶ˆæ¯")
        
        # æ™ºèƒ½é‡‡æ · - ä¸å†è¦æ±‚æ¯ä¸ªé¢‘é“å›ºå®šæ•°é‡
        learned_channels = 0
        skipped_channels = 0
        
        for channel_id, messages in channel_messages.items():
            # è·å–é¢‘é“ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            channel_result = await db.execute(
                select(Channel).where(Channel.channel_id == channel_id)
            )
            channel = channel_result.scalar_one_or_none()
            channel_name = channel.channel_name if channel else f"é¢‘é“{channel_id}"
            
            # ä¸å†å¼ºåˆ¶è¦æ±‚æœ€å°‘æ¶ˆæ¯æ•°ï¼Œè®©AIè¿‡æ»¤å™¨è‡ªå·±åˆ¤æ–­
            if len(messages) < 3:
                logger.info(f"{channel_name} æ ·æœ¬å¤ªå°‘ï¼ˆ{len(messages)}æ¡ï¼‰ï¼Œè·³è¿‡")
                skipped_channels += 1
                continue
            
            # æå–æ¶ˆæ¯å†…å®¹
            contents = []
            for msg in messages:
                # ä¼˜å…ˆä½¿ç”¨åŸå§‹å†…å®¹æ¥å­¦ä¹ å®Œæ•´çš„å°¾éƒ¨æ¨¡å¼
                content = msg.content or msg.filtered_content
                if content:
                    contents.append(content)
            
            if contents:
                logger.info(f"åˆ†æ {channel_name} çš„æ¶ˆæ¯æ¨¡å¼ï¼ˆ{len(contents)}æ¡ï¼‰...")
                success = await ai_filter.learn_channel_pattern(channel_id, contents)
                if success:
                    learned_channels += 1
                    logger.info(f"âœ… {channel_name} å‘ç°å°¾éƒ¨æ¨¡å¼å¹¶å­¦ä¹ æˆåŠŸ")
                else:
                    skipped_channels += 1
                    logger.info(f"â„¹ï¸ {channel_name} æœªå‘ç°å›ºå®šå°¾éƒ¨æ¨¡å¼ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
        
        # è¾“å‡ºç»Ÿè®¡
        logger.info(f"\nğŸ“Š å°¾éƒ¨æ¨¡å¼å­¦ä¹ ç»Ÿè®¡:")
        logger.info(f"  - æ€»é¢‘é“æ•°: {len(channel_messages)}")
        logger.info(f"  - å‘ç°å°¾éƒ¨æ¨¡å¼: {learned_channels} ä¸ªé¢‘é“")
        logger.info(f"  - æ— å°¾éƒ¨æ¨¡å¼: {skipped_channels} ä¸ªé¢‘é“")
        if len(channel_messages) > 0:
            success_rate = learned_channels/len(channel_messages)*100
            logger.info(f"  - æ£€å‡ºç‡: {success_rate:.1f}%ï¼ˆä¸æ˜¯æ‰€æœ‰é¢‘é“éƒ½æœ‰å°¾éƒ¨ï¼‰")

async def train_ad_classifier():
    """è®­ç»ƒå¹¿å‘Šåˆ†ç±»å™¨"""
    async with AsyncSessionLocal() as db:
        # è·å–æ ‡è®°ä¸ºå¹¿å‘Šçš„æ¶ˆæ¯
        ad_result = await db.execute(
            select(Message).where(
                Message.is_ad == True
            ).limit(500)
        )
        ad_messages = ad_result.scalars().all()
        
        # è·å–æ­£å¸¸æ¶ˆæ¯ï¼ˆå·²æ‰¹å‡†çš„ï¼‰
        normal_result = await db.execute(
            select(Message).where(
                and_(
                    Message.is_ad == False,
                    Message.status == 'approved'
                )
            ).limit(500)
        )
        normal_messages = normal_result.scalars().all()
        
        logger.info(f"å‡†å¤‡è®­ç»ƒæ•°æ®: {len(ad_messages)} ä¸ªå¹¿å‘Šæ ·æœ¬, {len(normal_messages)} ä¸ªæ­£å¸¸æ ·æœ¬")
        
        # æå–å†…å®¹
        ad_samples = []
        for msg in ad_messages:
            content = msg.content or msg.filtered_content
            if content:
                ad_samples.append(content)
        
        normal_samples = []
        for msg in normal_messages:
            content = msg.filtered_content or msg.content
            if content:
                normal_samples.append(content)
        
        if ad_samples or normal_samples:
            logger.info("å¼€å§‹è®­ç»ƒå¹¿å‘Šåˆ†ç±»å™¨...")
            await ai_filter.train_ad_classifier(ad_samples, normal_samples)
            logger.info("âœ… å¹¿å‘Šåˆ†ç±»å™¨è®­ç»ƒå®Œæˆ")
        else:
            logger.warning("æ²¡æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ ·æœ¬")

async def test_ai_filter():
    """æµ‹è¯•AIè¿‡æ»¤å™¨æ•ˆæœ"""
    # æµ‹è¯•å¹¿å‘Šæ£€æµ‹
    test_ads = [
        "ğŸ° æœ€æ–°ä¼˜æƒ  é¦–å­˜100é€100 ğŸ’°",
        "è¥ä¸šæ—¶é—´ï¼š10:00-22:00 å¾®ä¿¡ï¼šxxx123",
        "è¿™æ˜¯ä¸€æ¡æ­£å¸¸çš„æ–°é—»å†…å®¹ï¼Œæ²¡æœ‰å¹¿å‘Š"
    ]
    
    logger.info("\n=== æµ‹è¯•å¹¿å‘Šæ£€æµ‹ ===")
    for text in test_ads:
        is_ad, confidence = ai_filter.is_advertisement(text)
        logger.info(f"æ–‡æœ¬: {text[:30]}...")
        logger.info(f"  -> æ˜¯å¦å¹¿å‘Š: {is_ad}, ç½®ä¿¡åº¦: {confidence:.2f}")
    
    # æµ‹è¯•å°¾éƒ¨è¿‡æ»¤
    if ai_filter.channel_patterns:
        logger.info("\n=== æµ‹è¯•å°¾éƒ¨è¿‡æ»¤ ===")
        channel_id = list(ai_filter.channel_patterns.keys())[0]
        test_content = """
é‡è¦æ–°é—»å†…å®¹æ­£æ–‡éƒ¨åˆ†
è¿™æ˜¯æ–°é—»çš„è¯¦ç»†æè¿°

è®¢é˜…é¢‘é“ @channel123
å•†åŠ¡åˆä½œ @business456
æ›´å¤šç²¾å½©å†…å®¹è¯·å…³æ³¨
"""
        filtered = ai_filter.filter_channel_tail(channel_id, test_content)
        logger.info(f"åŸå§‹é•¿åº¦: {len(test_content)}, è¿‡æ»¤å: {len(filtered)}")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹è®­ç»ƒAIè¿‡æ»¤å™¨...")
    
    # ç­‰å¾…AIè¿‡æ»¤å™¨åˆå§‹åŒ–
    await asyncio.sleep(2)
    
    if not ai_filter.initialized:
        logger.error("AIè¿‡æ»¤å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…")
        return
    
    # è®­ç»ƒé¢‘é“å°¾éƒ¨æ¨¡å¼
    logger.info("\nğŸ“š æ­¥éª¤1: å­¦ä¹ é¢‘é“å°¾éƒ¨æ¨¡å¼")
    await train_channel_tails()
    
    # è®­ç»ƒå¹¿å‘Šåˆ†ç±»å™¨
    logger.info("\nğŸ¯ æ­¥éª¤2: è®­ç»ƒå¹¿å‘Šåˆ†ç±»å™¨")
    await train_ad_classifier()
    
    # ä¿å­˜æ¨¡å‹
    logger.info("\nğŸ’¾ æ­¥éª¤3: ä¿å­˜è®­ç»ƒç»“æœ")
    ai_filter.save_patterns("data/ai_filter_patterns.json")
    
    # æµ‹è¯•æ•ˆæœ
    logger.info("\nğŸ§ª æ­¥éª¤4: æµ‹è¯•AIè¿‡æ»¤å™¨")
    await test_ai_filter()
    
    logger.info("\nâœ… AIè¿‡æ»¤å™¨è®­ç»ƒå®Œæˆï¼")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    logger.info(f"\nğŸ“Š æ•´ä½“è®­ç»ƒç»Ÿè®¡:")
    logger.info(f"  - è¯†åˆ«åˆ°å°¾éƒ¨æ¨¡å¼çš„é¢‘é“: {len(ai_filter.channel_patterns)} ä¸ª")
    logger.info(f"  - å¹¿å‘Šæ ·æœ¬: {len(ai_filter.ad_embeddings)} ä¸ª")
    logger.info(f"  - æ­£å¸¸æ ·æœ¬: {len(ai_filter.normal_embeddings)} ä¸ª")
    logger.info(f"\nğŸ’¡ è¯´æ˜: ä¸æ˜¯æ‰€æœ‰é¢‘é“éƒ½æœ‰å›ºå®šå°¾éƒ¨ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡")

if __name__ == "__main__":
    asyncio.run(main())