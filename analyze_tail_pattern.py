#!/usr/bin/env python3
"""
åˆ†æå°¾éƒ¨æ¨¡å¼çš„ç›¸ä¼¼åº¦
"""
import asyncio
import logging
from app.services.ai_filter import ai_filter
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def analyze_tail_similarity():
    """åˆ†æå°¾éƒ¨ç›¸ä¼¼åº¦"""
    
    # åŠ è½½AIæ¨¡å¼
    ai_filter.load_patterns("data/ai_filter_patterns.json")
    
    channel_id = "-1002495270592"  # @yyds518899
    
    # æ¶ˆæ¯ #4315 çš„å°¾éƒ¨
    new_tail = """ğŸ‘äºšå¤ªæ–°é—»é¢‘é“ğŸ‘ https://t.me/yyds518899

ğŸ”äºšå¤ªè‰²æƒ…åƒç“œ ğŸ” ï¼šhttps://t.me/saisaissssss168168

ä¾¿æ°‘æœåŠ¡ä¸­æ–‡åŒ… https://t.me/setlanguage/classic-zh-cn"""

    # ä¹‹å‰å­¦ä¹ çš„å…¸å‹å°¾éƒ¨ï¼ˆä»è®­ç»ƒæ•°æ®ä¸­ï¼‰
    typical_tails = [
        """ğŸ”¥ç¾å›½åäººå–èœğŸ”¥ https://t.me/mgqp0
ğŸ”¥æŠ¥åå…¥ç¾¤ï¼š @yydsxiaomei
ğŸ”¥ å…è´¹æŠ¥åè·‘åˆ†æ‹…ä¿ğŸ‘‡ğŸ‘‡""",
        """ğŸ”¥è²å¾‹å®¾æ‹›è˜å’¨è¯¢ğŸ”¥  @a5161899
ğŸ”¥æŠ¥åå…¥ç¾¤ï¼š @yydsxiaomei
ğŸ”¥ç¾å›½åäººå–èœ https://t.me/mgqp0
ğŸ”¥ å…è´¹æŠ¥åè·‘åˆ†æ‹…ä¿ğŸ‘‡ğŸ‘‡""",
        """ğŸ”¥äºšå¤ªæ–°é—»é¢‘é“ğŸ”¥ https://t.me/yyds518899
ğŸ”¥è²å¾‹å®¾æ‹›è˜å’¨è¯¢ğŸ”¥  @a5161899
ğŸ”¥æŠ¥åå…¥ç¾¤ï¼š @yydsxiaomei
ğŸ”¥ å…è´¹æŠ¥åè·‘åˆ†æ‹…ä¿ğŸ‘‡ğŸ‘‡"""
    ]
    
    logger.info("=" * 60)
    logger.info("ğŸ” åˆ†æå°¾éƒ¨ç›¸ä¼¼åº¦")
    logger.info("=" * 60)
    
    # è®¡ç®—æ–°å°¾éƒ¨çš„åµŒå…¥
    new_embedding = ai_filter.model.encode([new_tail])[0]
    
    # è·å–å·²å­¦ä¹ çš„æ¨¡å¼
    if channel_id in ai_filter.channel_patterns:
        pattern = ai_filter.channel_patterns[channel_id]
        centroid = pattern['centroid']
        
        # è®¡ç®—ä¸ä¸­å¿ƒçš„ç›¸ä¼¼åº¦
        from sklearn.metrics.pairwise import cosine_similarity
        similarity = cosine_similarity(
            new_embedding.reshape(1, -1),
            centroid.reshape(1, -1)
        )[0][0]
        
        logger.info(f"\nğŸ“Š ä¸å­¦ä¹ æ¨¡å¼çš„ç›¸ä¼¼åº¦: {similarity:.3f}")
        logger.info(f"   é˜ˆå€¼: {pattern['threshold']}")
        logger.info(f"   æ˜¯å¦åŒ¹é…: {'âœ…' if similarity >= pattern['threshold'] else 'âŒ'}")
        
        # åˆ†æå…¸å‹å°¾éƒ¨
        logger.info(f"\nğŸ” ä¸å…¸å‹å°¾éƒ¨çš„ç›¸ä¼¼åº¦å¯¹æ¯”:")
        for i, tail in enumerate(typical_tails, 1):
            tail_embedding = ai_filter.model.encode([tail])[0]
            tail_similarity = cosine_similarity(
                tail_embedding.reshape(1, -1),
                centroid.reshape(1, -1)
            )[0][0]
            logger.info(f"\nå…¸å‹å°¾éƒ¨ {i} ç›¸ä¼¼åº¦: {tail_similarity:.3f}")
            logger.info(f"å†…å®¹é¢„è§ˆ: {tail[:50]}...")
        
        # åˆ†æå·®å¼‚
        logger.info(f"\nğŸ“ å°¾éƒ¨å†…å®¹å·®å¼‚åˆ†æ:")
        logger.info(f"\næ–°å°¾éƒ¨ç‰¹å¾:")
        logger.info(f"  - åŒ…å«é¢‘é“é“¾æ¥: {'âœ…' if 't.me' in new_tail else 'âŒ'}")
        logger.info(f"  - åŒ…å«'æŠ¥åå…¥ç¾¤': {'âœ…' if 'æŠ¥åå…¥ç¾¤' in new_tail else 'âŒ'}")
        logger.info(f"  - åŒ…å«'è·‘åˆ†æ‹…ä¿': {'âœ…' if 'è·‘åˆ†æ‹…ä¿' in new_tail else 'âŒ'}")
        logger.info(f"  - åŒ…å«emojiç«ç„°: {'âœ…' if 'ğŸ”¥' in new_tail else 'âŒ'}")
        logger.info(f"  - åŒ…å«'äºšå¤ª': {'âœ…' if 'äºšå¤ª' in new_tail else 'âŒ'}")
        
        logger.info(f"\nå…¸å‹å°¾éƒ¨ç‰¹å¾:")
        logger.info(f"  - åŒ…å«é¢‘é“é“¾æ¥: âœ…")
        logger.info(f"  - åŒ…å«'æŠ¥åå…¥ç¾¤': âœ…")
        logger.info(f"  - åŒ…å«'è·‘åˆ†æ‹…ä¿': âœ…")
        logger.info(f"  - åŒ…å«emojiç«ç„°: âœ…")
        
        # å»ºè®®
        logger.info(f"\nğŸ’¡ é—®é¢˜åˆ†æ:")
        logger.info(f"  æ–°å°¾éƒ¨ä½¿ç”¨äº†ä¸åŒçš„æ ¼å¼å’Œå†…å®¹ï¼š")
        logger.info(f"  1. ä½¿ç”¨ğŸ‘è€Œä¸æ˜¯ğŸ”¥ä½œä¸ºemoji")
        logger.info(f"  2. æ²¡æœ‰'æŠ¥åå…¥ç¾¤'å’Œ'è·‘åˆ†æ‹…ä¿'ç­‰å…³é”®è¯")
        logger.info(f"  3. æ·»åŠ äº†æ–°çš„é¢‘é“ï¼ˆè‰²æƒ…åƒç“œï¼‰å’ŒæœåŠ¡ï¼ˆä¸­æ–‡åŒ…ï¼‰")
        logger.info(f"  4. æ ¼å¼ç»“æ„ä¸åŒï¼Œè¡Œæ•°å’Œå†…å®¹éƒ½æœ‰å˜åŒ–")
        
        logger.info(f"\nğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        logger.info(f"  1. éœ€è¦é‡æ–°è®­ç»ƒï¼ŒåŒ…å«æ–°æ ¼å¼çš„å°¾éƒ¨æ ·æœ¬")
        logger.info(f"  2. æˆ–è€…æ‰‹åŠ¨æ·»åŠ è¿™ç§æ–°æ ¼å¼åˆ°è®­ç»ƒæ•°æ®")
        logger.info(f"  3. é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä½†å¯èƒ½è¯¯åˆ¤ï¼‰")

asyncio.run(analyze_tail_similarity())