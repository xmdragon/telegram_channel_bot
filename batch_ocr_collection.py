#!/usr/bin/env python3
"""
æ‰¹é‡OCRæ ·æœ¬æ”¶é›†è„šæœ¬
å¯¹ç°æœ‰çš„åª’ä½“æ–‡ä»¶è¿›è¡ŒOCRè¯†åˆ«å¹¶æ”¶é›†æ ·æœ¬
"""
import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from app.services.ocr_service import ocr_service
from app.services.ocr_sample_manager import ocr_sample_manager
from app.core.training_config import TrainingDataConfig

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BatchOCRCollector:
    """æ‰¹é‡OCRæ ·æœ¬æ”¶é›†å™¨"""
    
    def __init__(self):
        self.processed_count = 0
        self.success_count = 0
        self.error_count = 0
        self.sample_count = 0
        self.start_time = None
        
    async def collect_from_existing_media(self, limit: int = None) -> Dict[str, Any]:
        """ä»ç°æœ‰åª’ä½“æ–‡ä»¶æ”¶é›†OCRæ ·æœ¬"""
        try:
            self.start_time = time.time()
            logger.info("ğŸš€ å¼€å§‹æ‰¹é‡OCRæ ·æœ¬æ”¶é›†...")
            
            # è¯»å–åª’ä½“å…ƒæ•°æ®
            media_metadata_file = TrainingDataConfig.AD_MEDIA_METADATA_FILE
            media_dir = Path("data/ad_training_data")
            
            if not media_metadata_file.exists():
                logger.error("åª’ä½“å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
                return {"success": False, "error": "åª’ä½“å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨"}
            
            data = json.load(open(media_metadata_file, 'r', encoding='utf-8'))
            media_files = data.get("media_files", {})
            
            # ç­›é€‰å›¾ç‰‡æ–‡ä»¶
            image_files = []
            for file_hash, info in media_files.items():
                if info.get("type") == "image":
                    file_path = media_dir / info["path"]
                    if file_path.exists():
                        image_files.append({
                            "hash": file_hash,
                            "path": str(file_path),
                            "info": info
                        })
            
            # åº”ç”¨é™åˆ¶
            if limit:
                image_files = image_files[:limit]
            
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶å¾…å¤„ç†")
            
            # æ‰¹é‡å¤„ç†
            await self._process_files(image_files)
            
            # ç”ŸæˆæŠ¥å‘Š
            elapsed_time = time.time() - self.start_time
            
            report = {
                "success": True,
                "processed_count": self.processed_count,
                "success_count": self.success_count,
                "error_count": self.error_count,
                "sample_count": self.sample_count,
                "elapsed_time": f"{elapsed_time:.2f}ç§’",
                "average_time": f"{elapsed_time/max(self.processed_count, 1):.2f}ç§’/æ–‡ä»¶" if self.processed_count > 0 else "N/A"
            }
            
            logger.info("âœ… æ‰¹é‡OCRæ”¶é›†å®Œæˆ!")
            logger.info(f"ğŸ“ˆ å¤„ç†ç»Ÿè®¡: {self.processed_count}ä¸ªæ–‡ä»¶, {self.success_count}ä¸ªæˆåŠŸ, {self.error_count}ä¸ªå¤±è´¥")
            logger.info(f"ğŸ“¦ æ”¶é›†æ ·æœ¬: {self.sample_count}ä¸ª")
            logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {elapsed_time:.2f}ç§’")
            
            return report
            
        except Exception as e:
            logger.error(f"æ‰¹é‡OCRæ”¶é›†å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _process_files(self, image_files: List[Dict]) -> None:
        """å¤„ç†æ–‡ä»¶åˆ—è¡¨"""
        
        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜è¿‡è½½
        batch_size = 5
        for i in range(0, len(image_files), batch_size):
            batch = image_files[i:i+batch_size]
            
            logger.info(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(image_files)-1)//batch_size + 1} ({len(batch)}ä¸ªæ–‡ä»¶)")
            
            # å¹¶è¡Œå¤„ç†å½“å‰æ‰¹æ¬¡
            tasks = []
            for file_item in batch:
                task = self._process_single_file(file_item)
                tasks.append(task)
            
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # æ‰¹æ¬¡é—´çŸ­æš‚ä¼‘æ¯
            if i + batch_size < len(image_files):
                await asyncio.sleep(0.5)
    
    async def _process_single_file(self, file_item: Dict) -> None:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            self.processed_count += 1
            file_hash = file_item["hash"]
            file_path = file_item["path"] 
            file_info = file_item["info"]
            
            logger.info(f"ğŸ” [{self.processed_count}] å¤„ç†: {Path(file_path).name}")
            
            # æ‰§è¡ŒOCRè¯†åˆ«
            ocr_result = await ocr_service.extract_image_content(file_path)
            
            if not ocr_result:
                logger.warning(f"âŒ OCRè¯†åˆ«å¤±è´¥: {file_path}")
                self.error_count += 1
                return
            
            # æå–OCRä¿¡æ¯
            texts = ocr_result.get('texts', [])
            qr_codes = []
            for qr in ocr_result.get('qr_codes', []):
                if isinstance(qr, dict):
                    qr_codes.append(qr.get('data', ''))
                else:
                    qr_codes.append(str(qr))
            
            ad_score = ocr_result.get('ad_score', 0)
            is_ad = file_info.get('is_ad', False)
            keywords_detected = ocr_result.get('ad_indicators', [])
            
            # ä¿å­˜æ ·æœ¬
            sample_saved = await ocr_sample_manager.save_sample(
                image_hash=file_hash,
                image_path=file_path,
                ocr_texts=texts,
                qr_codes=qr_codes,
                ad_score=ad_score,
                is_ad=is_ad,
                keywords_detected=keywords_detected,
                auto_rejected=False,  # ç°æœ‰æ–‡ä»¶ä¸æ˜¯è‡ªåŠ¨æ‹’ç»çš„
                rejection_reason="",
                message_id=file_info.get('message_ids', [None])[0],
                source_channel=file_info.get('channel_id')
            )
            
            if sample_saved:
                self.success_count += 1
                self.sample_count += 1
                
                # è®°å½•è¯†åˆ«ç»“æœ
                text_info = f"è¯†åˆ«{len(texts)}æ¡æ–‡å­—" if texts else "æ— æ–‡å­—"
                qr_info = f", {len(qr_codes)}ä¸ªäºŒç»´ç " if qr_codes else ""
                score_info = f", å¹¿å‘Šåˆ†æ•°{ad_score:.1f}"
                
                logger.info(f"âœ… [{self.processed_count}] æˆåŠŸ: {text_info}{qr_info}{score_info}")
                
                # å¦‚æœæœ‰è¯†åˆ«åˆ°å†…å®¹ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
                if texts or qr_codes:
                    if texts:
                        logger.info(f"   ğŸ“ æ–‡å­—: {', '.join(texts[:3])}{'...' if len(texts) > 3 else ''}")
                    if qr_codes:
                        logger.info(f"   ğŸ”— äºŒç»´ç : {', '.join(qr_codes[:2])}{'...' if len(qr_codes) > 2 else ''}")
            else:
                logger.warning(f"âŒ æ ·æœ¬ä¿å­˜å¤±è´¥: {file_path}")
                self.error_count += 1
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            self.error_count += 1

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡OCRæ ·æœ¬æ”¶é›†')
    parser.add_argument('--limit', type=int, help='é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡')
    parser.add_argument('--learn', action='store_true', help='å¤„ç†å®Œæˆåè¿è¡Œå­¦ä¹ åŠŸèƒ½')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ”¶é›†å™¨
    collector = BatchOCRCollector()
    
    # å¼€å§‹æ”¶é›†
    result = await collector.collect_from_existing_media(limit=args.limit)
    
    if result["success"]:
        print("\n" + "="*60)
        print("ğŸ“‹ æ‰¹é‡OCRæ”¶é›†æŠ¥å‘Š")
        print("="*60)
        print(f"âœ… å¤„ç†å®Œæˆ: {result['processed_count']} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“¦ æˆåŠŸæ”¶é›†: {result['sample_count']} ä¸ªæ ·æœ¬")
        print(f"âŒ å¤„ç†å¤±è´¥: {result['error_count']} ä¸ªæ–‡ä»¶")
        print(f"â±ï¸  æ€»ç”¨æ—¶: {result['elapsed_time']}")
        print(f"âš¡ å¹³å‡é€Ÿåº¦: {result['average_time']}")
        
        # è·å–æœ€æ–°ç»Ÿè®¡ä¿¡æ¯
        stats = await ocr_sample_manager.get_statistics()
        print(f"\nğŸ“Š æ ·æœ¬åº“ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {stats.get('total_samples', 0)}")
        print(f"   å¹¿å‘Šæ ·æœ¬: {stats.get('ad_samples', 0)}")
        print(f"   éå¹¿å‘Šæ ·æœ¬: {stats.get('non_ad_samples', 0)}")
        print(f"   é«˜åˆ†æ ·æœ¬(â‰¥50): {stats.get('high_score_samples', 0)}")
        
        # å¦‚æœæŒ‡å®šäº†å­¦ä¹ å‚æ•°ï¼Œè¿è¡Œå­¦ä¹ åŠŸèƒ½
        if args.learn and stats.get('ad_samples', 0) >= 10:
            print("\nğŸ§  å¼€å§‹å­¦ä¹ è¿‡ç¨‹...")
            learn_result = await ocr_sample_manager.learn_from_samples()
            if learn_result.get('success'):
                new_keywords = learn_result.get('new_keywords', [])
                if new_keywords:
                    print(f"âœ… å­¦ä¹ å®Œæˆï¼Œå‘ç° {len(new_keywords)} ä¸ªæ–°å…³é”®è¯:")
                    for keyword in new_keywords[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                        print(f"   - {keyword}")
                    if len(new_keywords) > 10:
                        print(f"   ... è¿˜æœ‰ {len(new_keywords) - 10} ä¸ª")
                else:
                    print("âœ… å­¦ä¹ å®Œæˆï¼Œæœªå‘ç°æ–°çš„å…³é”®è¯æ¨¡å¼")
            else:
                print(f"âŒ å­¦ä¹ å¤±è´¥: {learn_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
        
        print("="*60)
    else:
        print(f"âŒ æ‰¹é‡æ”¶é›†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

if __name__ == "__main__":
    asyncio.run(main())